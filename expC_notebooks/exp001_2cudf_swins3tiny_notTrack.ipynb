{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline\n","- create target_df (distance in tracking_df is lower than threshold=3)\n","https://www.kaggle.com/code/stgkrtua/nfl-creatatraindataset-targetdf\n","- create dataset save frames in target_df\n","https://www.kaggle.com/code/stgkrtua/nfl-createdataset-saveframes\n","- check saved images\n","https://www.kaggle.com/code/stgkrtua/nfl-checkdataset-plotsavedimage"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-19T12:15:11.586666Z","iopub.status.busy":"2023-01-19T12:15:11.585912Z","iopub.status.idle":"2023-01-19T12:15:13.779848Z","shell.execute_reply":"2023-01-19T12:15:13.778792Z","shell.execute_reply.started":"2023-01-19T12:15:11.586576Z"},"trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from sklearn.model_selection import GroupKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_auc_score\n","\n","import cudf\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.783214Z","iopub.status.busy":"2023-01-19T12:15:13.782224Z","iopub.status.idle":"2023-01-19T12:15:13.801082Z","shell.execute_reply":"2023-01-19T12:15:13.800004Z","shell.execute_reply.started":"2023-01-19T12:15:13.783176Z"},"trusted":true},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"model_name\" : \"swin_s3_tiny_224\",\n","        \"out_features\" : 20,\n","        \"inp_channels\": 3*2,\n","        \"num_img_feature\" : 5,\n","        \"pretrained\" : True,\n","        \n","        \"roll_sum_window_size\" : 10,\n","        \"features\" : ['x_position_1', 'y_position_1', 'x_position_2', 'y_position_2', \n","                      'speed_1', 'distance_1', 'direction_1', 'orientation_1','acceleration_1', 'sa_1', \n","                      'speed_2', 'distance_2', 'direction_2', 'orientation_2', 'acceleration_2', 'sa_2',\n","                    #   'speed_diff', 'distance_diff', 'direction_diff', 'orientation_diff','acceleration_diff', 'sa_diff', # diff-feature\n","                      'players_dis', 'is_ground'],\n","\n","        # learning config\n","        \"n_epoch\" : 5,\n","        \"n_folds\": 3,\n","        # \"train_folds\" : [0,1,2],\n","        \"train_folds\" : [0],\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 1000,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 32,\n","        \"num_workers\" : 2,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"TRAIN_VIDEO_NUM\" : 100,\n","        \"VALID_VIDEO_NUM\" : 10,\n","        \"sample_num\" : -1, \n","\n","        \"EXP_CATEGORY\" : \"exps_cudf\",\n","        \"EXP_NAME\" : \"expC001_2_notTrack_swins3tiny\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_CATEGORY\"] = \"DEBUG\"\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 2\n","    CFG[\"sample_num\"] = 1000\n","    CFG[\"batch_size\"] = 32\n","    CFG[\"train_folds\"] : [0,1]\n","\n","\n","CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","CFG[\"SAVED_CONTACT_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"Saved_contact_frames.csv\")\n","CFG[\"CONTACT_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"contact_images\")\n","CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.802877Z","iopub.status.busy":"2023-01-19T12:15:13.802383Z","iopub.status.idle":"2023-01-19T12:15:24.348525Z","shell.execute_reply":"2023-01-19T12:15:24.34747Z","shell.execute_reply.started":"2023-01-19T12:15:13.802838Z"},"trusted":true},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"])\n","\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{"_kg_hide-input":true},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.352268Z","iopub.status.busy":"2023-01-19T12:15:24.35167Z","iopub.status.idle":"2023-01-19T12:15:24.3647Z","shell.execute_reply":"2023-01-19T12:15:24.363754Z","shell.execute_reply.started":"2023-01-19T12:15:24.352219Z"},"trusted":true},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best, auc_score):\n","    if CFG[\"kaggle\"]:\n","        wandb.log({\"loss avg\":{f\"train/fold{fold}\": train_loss_avg,\n","                                f\"valid/fold{fold}\": valid_loss_avg}}, step=epoch)\n","        wandb.log({\"Metircs\" : {f\"score/fold{fold}\":score,\n","                                f\"score threshold/fold{fold}\":threshold,\n","                                f\"tn/fold{fold}\":tn_best,\n","                                f\"fp/fold{fold}\":fp_best,\n","                                f\"fn/fold{fold}\":fn_best,\n","                                f\"tp/fold{fold}\":tp_best,\n","                                f\"auc/fold{fold}\":auc_score,\n","                               }}, step=epoch)\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} auc\", auc_score, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.366999Z","iopub.status.busy":"2023-01-19T12:15:24.366307Z","iopub.status.idle":"2023-01-19T12:15:24.418709Z","shell.execute_reply":"2023-01-19T12:15:24.417791Z","shell.execute_reply.started":"2023-01-19T12:15:24.366946Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.425285Z","iopub.status.busy":"2023-01-19T12:15:24.423016Z","iopub.status.idle":"2023-01-19T12:15:24.437655Z","shell.execute_reply":"2023-01-19T12:15:24.436601Z","shell.execute_reply.started":"2023-01-19T12:15:24.425246Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset Functions"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def add_feature_cols(df_, FEATURE_COLS,remove_col_list):\n","    additional_cols = list(df_.columns)\n","    additional_cols = [col for col in additional_cols if not col in remove_col_list]\n","    FEATURE_COLS.extend(additional_cols)\n","    return FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## target df func"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def create_trackmerged_ftr(target_df, FEATURE_COLS,\n","                           diff_cols = ['x_position', 'y_position', 'speed', 'distance',\n","                                        'direction', 'orientation', 'acceleration', 'sa']):\n","    # players distance features\n","    target_df[\"players_dis\"] = np.sqrt((target_df[\"x_position_1\"] - target_df[\"x_position_2\"])**2 \n","                                       + (target_df[\"y_position_1\"] - target_df[\"y_position_2\"])**2)\n","    # GがNanになる。これは0にする\n","    target_df[\"players_dis\"] = target_df[\"players_dis\"].fillna(0)\n","    FEATURE_COLS.append(\"players_dis\")\n","    \n","    # players distance sum(in shift range time : default(-6~6 frames not step))\n","    players_distance_sum = 0\n","    for idx in range(-6,6,1):\n","        players_distance_sum += np.sqrt((target_df[f\"x_position_shift{idx}_1\"] - target_df[f\"x_position_shift{idx}_2\"])**2 \n","                                       + (target_df[f\"y_position_shift{idx}_1\"] - target_df[f\"y_position_shift{idx}_2\"])**2)\n","    target_df[\"players_distance_sum\"] = players_distance_sum\n","    # GがNanになる。これは0にする\n","    target_df[\"players_distance_sum\"] = target_df[\"players_distance_sum\"].fillna(0)\n","    FEATURE_COLS.append(\"players_distance_sum\")\n","\n","    # players each axis distance sum(in shift range time : default(-6~6 frames not step))\n","    for axis in [\"x\", \"y\"]:\n","        axis_distance_1 = 0\n","        axis_distance_2 = 0\n","        for idx in range(-6, 5, 1):\n","            axis_distance_1 += abs(target_df[f\"{axis}_position_shift{idx}_1\"] - target_df[f\"{axis}_position_shift{idx+1}_1\"])\n","            axis_distance_2 += abs(target_df[f\"{axis}_position_shift{idx}_2\"] - target_df[f\"{axis}_position_shift{idx+1}_2\"])\n","        target_df[f\"{axis}_move_distance_1\"] = axis_distance_1\n","        target_df[f\"{axis}_move_distance_2\"] = axis_distance_2\n","        FEATURE_COLS.extend([f\"{axis}_move_distance_1\", f\"{axis}_move_distance_2\"])\n","    \n","    # players difference ftr (in each step)\n","    for col in diff_cols:\n","        colname = f\"{col}_diff\"\n","        target_df[colname] = abs(target_df[f\"{col}_1\"] - target_df[f\"{col}_2\"])\n","        FEATURE_COLS.append(colname)\n","    \n","    return target_df, FEATURE_COLS"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def create_roll_ftr(target_df, FEATURE_COLS,\n","                    roll_cols = ['players_dis', 'x_position_diff', 'y_position_diff', \n","                                  'speed_diff', 'distance_diff','direction_diff',\n","                                  'orientation_diff', 'acceleration_diff', 'sa_diff']):\n","    print(\"original length\", len(target_df))\n","    key_cols = [\"game_play\", \"nfl_player_id_1\", \"nfl_player_id_2\"]\n","    roll_df = target_df[roll_cols+key_cols].copy()\n","    roll_df[\"key\"] = roll_df[\"game_play\"] + \"_\" + roll_df[\"nfl_player_id_1\"].astype(\"str\") + \"_\" + roll_df[\"nfl_player_id_2\"].astype(\"str\")\n","\n","    group_roll_df = roll_df.groupby(\"key\").rolling(CFG[\"roll_sum_window_size\"])[roll_cols].sum().fillna(-999).sort_index()\n","    for col in roll_cols:\n","        group_roll_df = group_roll_df.rename(columns={col:col+\"_rollsum\"})\n","        FEATURE_COLS.append(col+\"_rollsum\")\n","\n","    if not torch.cuda.is_available():\n","        target_df = pd.concat([target_df, group_roll_df], axis=1).sort_index()\n","    else:\n","        target_df = cudf.concat([target_df, group_roll_df], axis=1).sort_index()\n","    print(\"after length\", len(target_df))\n","    return target_df, FEATURE_COLS"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def create_helmetmerged_ftr(target_df, FEATURE_COLS):\n","    # helmet center distance feature\n","    for view in [\"Endzone\", \"Sideline\"]:\n","        for p_id in [\"1\", \"2\"]: \n","            # get helmet center\n","            col_name = f\"{view[0]}_Wcenter_{p_id}\"\n","            pos_col, size_col =  f\"{view[0]}_left_{p_id}\", f\"{view[0]}_width_{p_id}\"\n","            target_df[col_name] = target_df[pos_col] + (target_df[size_col]//2)\n","            col_name = f\"{view[0]}_Hcenter_{p_id}\"\n","            pos_col, size_col =  f\"{view[0]}_top_{p_id}\", f\"{view[0]}_height_{p_id}\"\n","            target_df[col_name] = target_df[pos_col] + (target_df[size_col]//2)\n","        \n","        # helmet center distance\n","        target_df[f\"{view[0]}_helmet_dis\"] = np.sqrt((target_df[f\"{view[0]}_Wcenter_1\"] - target_df[f\"{view[0]}_Wcenter_2\"])**2 \n","                                             + (target_df[f\"{view[0]}_Hcenter_1\"] - target_df[f\"{view[0]}_Hcenter_2\"])**2)\n","        # GがNanになるので0にしておく\n","        target_df[f\"{view[0]}_helmet_dis\"] = target_df[f\"{view[0]}_helmet_dis\"].fillna(0)\n","        FEATURE_COLS.append(f\"{view[0]}_helmet_dis\")\n","    \n","    # helmet cols fillna(0) after get helmet distance \n","    helmet_cols = ['E_left_1', 'E_width_1', 'E_top_1', 'E_height_1',\n","                   'E_left_2', 'E_width_2', 'E_top_2', 'E_height_2', \n","                   'S_left_1','S_width_1', 'S_top_1', 'S_height_1', \n","                   'S_left_2', 'S_width_2', 'S_top_2', 'S_height_2']\n","    target_df[helmet_cols] = target_df[helmet_cols].fillna(0)\n","\n","    return target_df, FEATURE_COLS"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def get_categorical_ftr(target_df, FEATURE_COLS):\n","    target_df[\"is_ground\"] = (target_df[\"nfl_player_id_2\"] == \"G\").astype(np.int64)\n","    target_df[\"players_dis\"].mask((target_df[\"is_ground\"]==1), 0, inplace=True)\n","    \n","    target_df[\"nfl_player_id_2\"] = target_df[\"nfl_player_id_2\"].replace(\"G\", \"99999\").astype(np.int64) # when inference this is after cnn pred\n","    target_df[\"is_helmet\"] = 1 - ((target_df[\"E_width_1\"]==0) & (target_df[\"E_width_2\"]==0)\n","                                  & (target_df[\"S_width_1\"]==0) & (target_df[\"S_width_2\"]==0)).astype(np.int64)\n","    \n","    # set team \n","    target_df[\"team_1\"] = (target_df[\"team_1\"] == \"home\").astype(np.int64)\n","    target_df[\"team_2\"] = (target_df[\"team_2\"] == \"home\").astype(np.int64)\n","    \n","    FEATURE_COLS.extend([\"is_ground\", \"is_helmet\"])\n","    return target_df, FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## tracking df func"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def get_tracking_shift(tracking_df, shift_cols=[\"x_position\",\"y_position\"], shift_nums=range(-6,6,1)):\n","    # get shift key\n","    tracking_df[\"game_player\"] = tracking_df[\"game_play\"].str.cat(tracking_df['nfl_player_id'].astype(str), sep='_')\n","    tracking_df[\"frame_add\"] = (tracking_df['step']/10*59.94+5*59.94).astype('int')+5000 #全部0以上の方が並べやすい\n","    tracking_df[\"frame_key\"] = tracking_df[\"frame_add\"].astype(str).str.zfill(5)\n","    tracking_df[\"shift_key\"] = tracking_df[\"game_player\"].str.cat(tracking_df[\"frame_key\"].astype(str), sep='_')\n","    tracking_df = tracking_df.sort_values(\"shift_key\").reset_index(drop=True)\n","    SHIFT_COLS = []\n","    for col in shift_cols:\n","        for num in shift_nums:\n","            colname = f\"{col}_shift{num}\"\n","            tracking_df[colname] = tracking_df[col].shift(num)\n","            SHIFT_COLS.append(colname)\n","    tracking_df = tracking_df.drop([\"game_player\", \"frame_add\",\"frame_key\", \"shift_key\"], axis=1)\n","    return tracking_df, SHIFT_COLS"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def target_merge_tracking(target_df, tracking_df, FEATURE_COLS, SHIFT_COLS,\n","                          TRACKING_COLS = [\"game_play\", \"nfl_player_id\", \"step\", \n","                                           \"x_position\", \"y_position\", \"datetime\",\n","                                           \"speed\",\"distance\",\"direction\",\"orientation\",\n","                                           \"acceleration\",\"sa\", \"team\", \"jersey_number\"] ):\n","    print(\"original length\", len(target_df))\n","    # set merge-key (game_step_player_1, 2) to merge tracking_df\n","    target_df[\"game_step\"] = target_df['game_play'].str.cat(target_df['step'].astype(str), sep='_')\n","    target_df[\"game_step_player_1\"] = target_df['game_step'].str.cat(target_df['nfl_player_id_1'].astype(str), sep='_')\n","    target_df[\"game_step_player_2\"] = target_df['game_step'].str.cat(target_df['nfl_player_id_2'].astype(str), sep='_')\n","\n","    # merge-key\n","    TRACKING_COLS.extend(SHIFT_COLS)\n","    tracking_df = tracking_df[TRACKING_COLS]\n","    tracking_df[\"frame\"] = (tracking_df['step']/10*59.94+5*59.94).astype('int')+1\n","    tracking_df[\"game_step\"] = tracking_df['game_play'].str.cat(tracking_df['step'].astype(str), sep='_')\n","    tracking_df[\"game_step_player\"] = tracking_df['game_step'].str.cat(tracking_df['nfl_player_id'].astype(str), sep='_')\n","    tracking_df = tracking_df.drop([\"game_step\", \"game_play\", \"step\", \"nfl_player_id\"], axis=1)\n","    \n","    for player_id in [1,2]:\n","        tracking_player = tracking_df.copy()\n","        tracking_player.rename(columns={\"game_step_player\":f\"game_step_player_{player_id}\"}, inplace=True)\n","        rename_cols = [col for col in tracking_player.columns if col != f\"game_step_player_{player_id}\"]\n","        tracking_player = tracking_player.rename(columns={rename_col: f\"{rename_col}_{player_id}\" for rename_col in rename_cols})\n","        target_df = target_df.merge(tracking_player, on=[f\"game_step_player_{player_id}\"], how=\"left\")\n","        # add features col\n","        FEATURE_COLS = add_feature_cols(tracking_player, FEATURE_COLS,\n","                                        [f\"game_step_player_{player_id}\", f\"frame_{player_id}\", f\"datetime_{player_id}\"])\n","    target_df[\"frame\"] = target_df[\"frame_1\"]\n","    FEATURE_COLS.append(\"frame\")\n","    \n","    target_df = target_df.drop([\"frame_1\", \"frame_2\", \"game_step_player_1\", \"game_step_player_2\",\n","                                \"datetime_1\", \"datetime_2\"], axis=1)\n","#     print(target_df.columns)\n","    print(len(target_df.columns))\n","    print(\"original length\", len(target_df))\n","    return target_df, FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## helmet df func"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def target_merge_helmet(target_df, helmet_df, FEATURE_COLS):\n","    print(\"original length\", len(target_df))\n","    # set merge-key (game_frame_player_1,2) to merge helmet_df\n","    target_df[\"game_frame\"] = target_df['game_play'].str.cat(target_df['frame'].astype(str), sep='_')\n","    target_df[\"game_frame_player_1\"] = target_df['game_frame'].str.cat(target_df['nfl_player_id_1'], sep='_')\n","    target_df[\"game_frame_player_2\"] = target_df['game_frame'].str.cat(target_df['nfl_player_id_2'], sep='_')\n","    # set merge key\n","    helmet_df[\"game_frame\"] = helmet_df['game_play'].str.cat(helmet_df['frame'].astype(str), sep='_')\n","    helmet_df[\"game_frame_player\"] = helmet_df['game_frame'].str.cat(helmet_df['nfl_player_id'].astype(str), sep='_')\n","    \n","    # merge target df & helmet_df\n","    player_views = [[1, \"Endzone\"],[2, \"Endzone\"], [1, \"Sideline\"],[2, \"Sideline\"]]\n","    for player_id, view in player_views:\n","        helmet_view = helmet_df[helmet_df[\"view\"]==view]\n","        helmet_view = helmet_view[[\"game_frame_player\", \"left\", \"width\", \"top\", \"height\"]]\n","        helmet_view.rename(columns={\"game_frame_player\":f\"game_frame_player_{player_id}\"}, inplace=True)\n","        rename_cols = helmet_view.columns[1:]\n","        helmet_view = helmet_view.rename(columns={rename_col: f\"{view[0]}_{rename_col}_{player_id}\" for rename_col in rename_cols})\n","        if not torch.cuda.is_available():\n","            target_df = pd.merge(target_df, helmet_view, on=f\"game_frame_player_{player_id}\", how=\"left\")\n","        else:\n","            target_df = target_df.merge(helmet_view, on=[f\"game_frame_player_{player_id}\"], how=\"left\")  \n","        # add features col\n","        FEATURE_COLS = add_feature_cols(helmet_view, FEATURE_COLS, [f\"game_frame_player_{player_id}\"])\n","\n","    print(len(target_df.columns))\n","    print(\"original length\", len(target_df))\n","    return target_df, FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Load Target"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>game_play</th>\n","      <th>datetime</th>\n","      <th>step</th>\n","      <th>nfl_player_id_1</th>\n","      <th>nfl_player_id_2</th>\n","      <th>contact</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58168_003392_0_38590_43854</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>43854</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58168_003392_0_38590_41257</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>41257</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58168_003392_0_38590_41944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>41944</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58168_003392_0_38590_42386</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>42386</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58168_003392_0_38590_47944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>47944</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4721613</th>\n","      <td>58582_003121_91_48220_G</td>\n","      <td>58582_003121</td>\n","      <td>2021-10-12 02:42:29.100</td>\n","      <td>91</td>\n","      <td>48220</td>\n","      <td>G</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4721614</th>\n","      <td>58582_003121_91_47906_G</td>\n","      <td>58582_003121</td>\n","      <td>2021-10-12 02:42:29.100</td>\n","      <td>91</td>\n","      <td>47906</td>\n","      <td>G</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4721615</th>\n","      <td>58582_003121_91_38557_G</td>\n","      <td>58582_003121</td>\n","      <td>2021-10-12 02:42:29.100</td>\n","      <td>91</td>\n","      <td>38557</td>\n","      <td>G</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4721616</th>\n","      <td>58582_003121_91_47872_G</td>\n","      <td>58582_003121</td>\n","      <td>2021-10-12 02:42:29.100</td>\n","      <td>91</td>\n","      <td>47872</td>\n","      <td>G</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4721617</th>\n","      <td>58582_003121_91_52619_G</td>\n","      <td>58582_003121</td>\n","      <td>2021-10-12 02:42:29.100</td>\n","      <td>91</td>\n","      <td>52619</td>\n","      <td>G</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4721618 rows × 7 columns</p>\n","</div>"],"text/plain":["                         contact_id     game_play                datetime  \\\n","0        58168_003392_0_38590_43854  58168_003392 2020-09-11 03:01:48.100   \n","1        58168_003392_0_38590_41257  58168_003392 2020-09-11 03:01:48.100   \n","2        58168_003392_0_38590_41944  58168_003392 2020-09-11 03:01:48.100   \n","3        58168_003392_0_38590_42386  58168_003392 2020-09-11 03:01:48.100   \n","4        58168_003392_0_38590_47944  58168_003392 2020-09-11 03:01:48.100   \n","...                             ...           ...                     ...   \n","4721613     58582_003121_91_48220_G  58582_003121 2021-10-12 02:42:29.100   \n","4721614     58582_003121_91_47906_G  58582_003121 2021-10-12 02:42:29.100   \n","4721615     58582_003121_91_38557_G  58582_003121 2021-10-12 02:42:29.100   \n","4721616     58582_003121_91_47872_G  58582_003121 2021-10-12 02:42:29.100   \n","4721617     58582_003121_91_52619_G  58582_003121 2021-10-12 02:42:29.100   \n","\n","         step  nfl_player_id_1 nfl_player_id_2  contact  \n","0           0            38590           43854        0  \n","1           0            38590           41257        0  \n","2           0            38590           41944        0  \n","3           0            38590           42386        0  \n","4           0            38590           47944        0  \n","...       ...              ...             ...      ...  \n","4721613    91            48220               G        0  \n","4721614    91            47906               G        0  \n","4721615    91            38557               G        0  \n","4721616    91            47872               G        0  \n","4721617    91            52619               G        0  \n","\n","[4721618 rows x 7 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["if not torch.cuda.is_available():\n","    target_df = pd.read_csv(CFG[\"TRAIN_LABEL_CSV\"], parse_dates=[\"datetime\"])    \n","else:\n","    target_df = cudf.read_csv(CFG[\"TRAIN_LABEL_CSV\"], parse_dates=[\"datetime\"])\n","FEATURE_COLS = [\"nfl_player_id_1\", \"nfl_player_id_2\", \"step\"]\n","display(target_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Merge tracking_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["if not torch.cuda.is_available():\n","    tracking_df = pd.read_csv(CFG[\"TRAIN_TRACKING_CSV\"], parse_dates=[\"datetime\"])\n","else:\n","    tracking_df = cudf.read_csv(CFG[\"TRAIN_TRACKING_CSV\"], parse_dates=[\"datetime\"])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["original length 4721618\n","77\n","original length 4721618\n"]}],"source":["tracking_df, SHIFT_COLS = get_tracking_shift(tracking_df)\n","target_df, FEATURE_COLS = target_merge_tracking(target_df, tracking_df, FEATURE_COLS, SHIFT_COLS)\n","del tracking_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["original length 4721618\n","after length 4721618\n"]}],"source":["arget_df, FEATURE_COLS = create_trackmerged_ftr(target_df, FEATURE_COLS)\n","target_df, FEATURE_COLS = create_roll_ftr(target_df, FEATURE_COLS)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["660560\n"]}],"source":["target_df = target_df[target_df[\"players_dis\"] <= 2].reset_index(drop=True)\n","print(len(target_df))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Merge helmet df"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["original length 660560\n","119\n","original length 660560\n"]}],"source":["if not torch.cuda.is_available():\n","    helmet_df = pd.read_csv(CFG[\"TRAIN_HELMET_CSV\"])\n","else:\n","    helmet_df = cudf.read_csv(CFG[\"TRAIN_HELMET_CSV\"])\n","\n","target_df, FEATURE_COLS = target_merge_helmet(target_df, helmet_df, FEATURE_COLS)\n","del helmet_df"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["660560\n"]}],"source":["target_df, FEATURE_COLS = create_helmetmerged_ftr(target_df, FEATURE_COLS)\n","target_df, FEATURE_COLS = get_categorical_ftr(target_df, FEATURE_COLS)\n","print(len(target_df))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Reduce Data"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["457965\n","240\n"]}],"source":["target_df[\"is_E_helmet\"] = 1 -  ((target_df[\"E_width_1\"]==0) & (target_df[\"E_width_2\"]==0)).astype(int)\n","target_df[\"is_S_helmet\"] = 1 -  ((target_df[\"S_width_1\"]==0) & (target_df[\"S_width_2\"]==0)).astype(int)\n","target_df[\"both_helmet\"] = (target_df[\"is_E_helmet\"]==1) & (target_df[\"is_S_helmet\"]==1).astype(int)\n","target_df = target_df[target_df[\"both_helmet\"]==1].reset_index(drop=True)\n","# target_df.to_csv(\"target_cudf.csv\", index=False)\n","target_df = target_df.fillna(0)\n","target_df = target_df.to_pandas()\n","\n","Saved_contact_frames = pd.read_csv(CFG[\"SAVED_CONTACT_CSV\"])\n","saved_contact_ids = list(Saved_contact_frames[\"contact_id\"].values)\n","target_df = target_df[target_df[\"contact_id\"].isin(saved_contact_ids)]\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"]).reset_index(drop=True)\n","print(len(target_df))\n","print(len(target_df[\"game_play\"].unique()))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Augmentation"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.940381Z","iopub.status.busy":"2023-01-19T12:15:30.938161Z","iopub.status.idle":"2023-01-19T12:15:30.959628Z","shell.execute_reply":"2023-01-19T12:15:30.958635Z","shell.execute_reply.started":"2023-01-19T12:15:30.940343Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.3, 0.3), p=0.5),\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])\n","\n","valid_transform = A.Compose([\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.966042Z","iopub.status.busy":"2023-01-19T12:15:30.963888Z","iopub.status.idle":"2023-01-19T12:15:31.022098Z","shell.execute_reply":"2023-01-19T12:15:31.020913Z","shell.execute_reply.started":"2023-01-19T12:15:30.966004Z"},"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.features = target_df[CFG[\"features\"]].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        features = self.features[idx]\n","        \n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","        contact_id = target_info.contact_id\n","        contact_fileid = f\"{contact_id}_Endzone.jpg\"\n","        contact_filename = os.path.join(CFG[\"CONTACT_IMG_DIR\"], contact_fileid)\n","        img = cv2.imread(contact_filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img / 255. # convert to 0-1\n","                img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = img\n","        contact_fileid = f\"{contact_id}_Sideline.jpg\"\n","        contact_filename = os.path.join(CFG[\"CONTACT_IMG_DIR\"], contact_fileid)\n","        img = cv2.imread(contact_filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img / 255. # convert to 0-1\n","                img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = np.concatenate([input_img, img], axis=0)\n","        input_img = torch.tensor(input_img, dtype=torch.float)\n","        target = torch.tensor(target, dtype=torch.float)\n","        features = torch.tensor(features, dtype=torch.float)\n","        return input_img, features, target"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.050926Z","iopub.status.busy":"2023-01-19T12:15:31.047836Z","iopub.status.idle":"2023-01-19T12:15:31.08031Z","shell.execute_reply":"2023-01-19T12:15:31.07901Z","shell.execute_reply.started":"2023-01-19T12:15:31.050888Z"},"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"num_img_feature\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes=out_features)\n","        self.mlp = nn.Sequential(\n","                        nn.Linear(len(CFG[\"features\"]), 32),\n","                        nn.LayerNorm(32),\n","                        nn.ReLU(),\n","                        nn.Dropout(0.2),\n","                    )\n","        self.fc = nn.Linear(out_features+32, 1)\n","\n","    def forward(self, image, features):\n","        image_feature = self.model(image)\n","        features = self.mlp(features)\n","\n","        output = self.fc(torch.cat([image_feature, features], dim=1))\n","\n","        return output, image_feature"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.089647Z","iopub.status.busy":"2023-01-19T12:15:31.086565Z","iopub.status.idle":"2023-01-19T12:15:31.108085Z","shell.execute_reply":"2023-01-19T12:15:31.106889Z","shell.execute_reply.started":"2023-01-19T12:15:31.089595Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    for batch_idx, (images, features, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)      \n","        features = features.to(device, non_blocking = True).float()\n","        preds, _ = model(images, features)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, features, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.124209Z","iopub.status.busy":"2023-01-19T12:15:31.115126Z","iopub.status.idle":"2023-01-19T12:15:31.151039Z","shell.execute_reply":"2023-01-19T12:15:31.150071Z","shell.execute_reply.started":"2023-01-19T12:15:31.124165Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    img_embs = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    for batch_idx, (images, features, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        features = features.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds, img_emb = model(images, features)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        img_emb = img_emb.detach().cpu().numpy()\n","        img_embs.extend(img_emb)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, features, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, img_embs, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.158195Z","iopub.status.busy":"2023-01-19T12:15:31.155797Z","iopub.status.idle":"2023-01-19T12:15:31.19266Z","shell.execute_reply":"2023-01-19T12:15:31.191464Z","shell.execute_reply.started":"2023-01-19T12:15:31.158157Z"},"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    # set model & learning fn\n","    oof_df = pd.DataFrame()\n","    kf = GroupKFold(n_splits=CFG[\"n_folds\"])\n","    for fold, (idx_train, idx_valid) in enumerate(kf.split(target_df, target_df[\"contact_id\"], target_df[\"game_play\"])):\n","        print(\"---\")\n","        print(f\"fold {fold} start training...\")\n","        model = NFLNet()\n","        model = model.to(device)\n","        criterion = nn.BCEWithLogitsLoss()\n","        optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","        if not fold in CFG[\"train_folds\"]:\n","            print(f\"fold{fold} is skip\")\n","            continue\n","        # separate train/valid data \n","        train_df = target_df.iloc[idx_train]\n","        valid_df = target_df.iloc[idx_valid]\n","        print(\"train target contact\")\n","        print(train_df[\"contact\"].value_counts())\n","        print(\"valid target contact\")\n","        print(valid_df[\"contact\"].value_counts())\n","        # separate train/valid data \n","        train_dataset = NFLDataset(train_df, train_transform)\n","        valid_dataset = NFLDataset(valid_df, valid_transform)\n","        train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","        valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","        # training\n","        best_score = -np.inf\n","        best_auc = -np.inf\n","        start_time, end = time.time(), time.time()\n","        for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","            print(f'\\t === epoch: {epoch}: training ===')\n","            train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","            valid_targets, valid_preds, valid_embs, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","            valid_score = -np.inf\n","            valid_threshold = 0\n","            tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","            for idx in range(1, 10, 1):\n","                thr = idx*0.1\n","                valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","                valid_binary_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","                score_tmp = matthews_corrcoef(valid_targets, valid_binary_preds)\n","                cm = confusion_matrix(valid_targets, valid_binary_preds)\n","                tn, fp, fn, tp = cm.flatten()\n","                if score_tmp > valid_score:\n","                    valid_score = score_tmp \n","                    valid_threshold = thr\n","                    tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","            elapsed = (time.time() - start_time)/60\n","            auc_score = roc_auc_score(valid_targets, valid_preds)\n","            print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}')\n","            print(f'\\t score:{valid_score:.4f}(th={valid_threshold}) AUC = {auc_score:.4f}=> time:{elapsed:.2f} min')\n","            scheduler.step()\n","            # validationスコアがbestを更新したらモデルを保存する\n","            if valid_score > best_score:\n","                best_score = valid_score\n","                model_name = CFG[\"model_name\"]\n","                torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/{model_name}_fold{fold}.pth')\n","                print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                contact_id = valid_df[\"contact_id\"].values\n","                _oof_df = pd.DataFrame({\n","                    \"contact_id\" : contact_id,\n","                    \"pred\" : valid_preds,\n","                    \"contact\" : valid_targets,\n","                    \"fold\" : fold,\n","                })\n","                img_emb_colname = [f\"img_emb_{idx}\" for idx in range(CFG[\"num_img_feature\"])]\n","                img_emb_df = pd.DataFrame(valid_embs, columns=img_emb_colname)\n","                _oof_df = pd.concat([_oof_df, img_emb_df], axis=1)\n","            \n","            logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best, auc_score)\n","\n","        del train_loader, train_dataset, valid_loader, valid_dataset\n","        oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","        del _oof_df\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.200371Z","iopub.status.busy":"2023-01-19T12:15:31.1979Z","iopub.status.idle":"2023-01-19T12:20:32.225707Z","shell.execute_reply":"2023-01-19T12:20:32.2246Z","shell.execute_reply.started":"2023-01-19T12:15:31.200332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","fold 0 start training...\n","train target contact\n","0    269149\n","1     36221\n","Name: contact, dtype: int64\n","valid target contact\n","0    135481\n","1     17114\n","Name: contact, dtype: int64\n","\t === epoch: 1: training ===\n","\t Epoch: [1][0/9543] Elapsed 0m 0s (remain 148m 42s) Loss: 0.9890(0.9890) \n","\t Epoch: [1][1000/9543] Elapsed 2m 47s (remain 23m 51s) Loss: 0.1712(0.2619) \n","\t Epoch: [1][2000/9543] Elapsed 5m 31s (remain 20m 51s) Loss: 0.1938(0.2391) \n","\t Epoch: [1][3000/9543] Elapsed 8m 10s (remain 17m 50s) Loss: 0.1401(0.2293) \n","\t Epoch: [1][4000/9543] Elapsed 10m 41s (remain 14m 48s) Loss: 0.2381(0.2216) \n","\t Epoch: [1][5000/9543] Elapsed 13m 10s (remain 11m 57s) Loss: 0.0600(0.2168) \n","\t Epoch: [1][6000/9543] Elapsed 15m 38s (remain 9m 14s) Loss: 0.2109(0.2135) \n","\t Epoch: [1][7000/9543] Elapsed 18m 7s (remain 6m 34s) Loss: 0.1631(0.2105) \n","\t Epoch: [1][8000/9543] Elapsed 20m 35s (remain 3m 58s) Loss: 0.1786(0.2075) \n","\t Epoch: [1][9000/9543] Elapsed 23m 5s (remain 1m 23s) Loss: 0.0808(0.2050) \n","\t Epoch: [1][9542/9543] Elapsed 24m 26s (remain 0m 0s) Loss: 0.2025(0.2039) \n","\t EVAL: [0/4769] Elapsed 0m 0s (remain 36m 38s) Loss: 0.0073(0.0073) \n","\t EVAL: [1000/4769] Elapsed 2m 39s (remain 10m 0s) Loss: 0.1411(0.2044) \n","\t EVAL: [2000/4769] Elapsed 5m 17s (remain 7m 19s) Loss: 0.2640(0.1974) \n","\t EVAL: [3000/4769] Elapsed 7m 58s (remain 4m 41s) Loss: 0.0728(0.1874) \n","\t EVAL: [4000/4769] Elapsed 10m 42s (remain 2m 3s) Loss: 0.2203(0.1855) \n","\t EVAL: [4768/4769] Elapsed 12m 51s (remain 0m 0s) Loss: 0.1666(0.1849) \n","\t epoch:1, avg train loss:0.2039, avg valid loss:0.1849\n","\t score:0.6042(th=0.2) AUC = 0.9393=> time:37.29 min\n","\t Epoch 1 - Save Best Score: 0.6042. Model is saved.\n","\t === epoch: 2: training ===\n","\t Epoch: [2][0/9543] Elapsed 0m 0s (remain 89m 55s) Loss: 0.1677(0.1677) \n","\t Epoch: [2][1000/9543] Elapsed 2m 15s (remain 19m 18s) Loss: 0.2453(0.1806) \n","\t Epoch: [2][2000/9543] Elapsed 4m 34s (remain 17m 16s) Loss: 0.1288(0.1769) \n","\t Epoch: [2][3000/9543] Elapsed 6m 52s (remain 14m 58s) Loss: 0.0555(0.1770) \n","\t Epoch: [2][4000/9543] Elapsed 9m 6s (remain 12m 37s) Loss: 0.1897(0.1767) \n","\t Epoch: [2][5000/9543] Elapsed 11m 20s (remain 10m 18s) Loss: 0.1391(0.1770) \n","\t Epoch: [2][6000/9543] Elapsed 13m 34s (remain 8m 1s) Loss: 0.0876(0.1760) \n","\t Epoch: [2][7000/9543] Elapsed 15m 49s (remain 5m 44s) Loss: 0.2366(0.1755) \n","\t Epoch: [2][8000/9543] Elapsed 18m 1s (remain 3m 28s) Loss: 0.1452(0.1757) \n","\t Epoch: [2][9000/9543] Elapsed 20m 15s (remain 1m 13s) Loss: 0.2583(0.1757) \n","\t Epoch: [2][9542/9543] Elapsed 21m 28s (remain 0m 0s) Loss: 0.3032(0.1755) \n","\t EVAL: [0/4769] Elapsed 0m 0s (remain 35m 58s) Loss: 0.0039(0.0039) \n","\t EVAL: [1000/4769] Elapsed 2m 52s (remain 10m 49s) Loss: 0.0851(0.1888) \n","\t EVAL: [2000/4769] Elapsed 5m 43s (remain 7m 54s) Loss: 0.3479(0.1837) \n","\t EVAL: [3000/4769] Elapsed 8m 38s (remain 5m 5s) Loss: 0.0867(0.1756) \n","\t EVAL: [4000/4769] Elapsed 11m 37s (remain 2m 13s) Loss: 0.2008(0.1744) \n","\t EVAL: [4768/4769] Elapsed 14m 3s (remain 0m 0s) Loss: 0.1511(0.1743) \n","\t epoch:2, avg train loss:0.1755, avg valid loss:0.1743\n","\t score:0.6295(th=0.30000000000000004) AUC = 0.9455=> time:72.85 min\n","\t Epoch 2 - Save Best Score: 0.6295. Model is saved.\n","\t === epoch: 3: training ===\n","\t Epoch: [3][0/9543] Elapsed 0m 0s (remain 116m 35s) Loss: 0.1385(0.1385) \n","\t Epoch: [3][1000/9543] Elapsed 2m 12s (remain 18m 50s) Loss: 0.1330(0.1665) \n","\t Epoch: [3][2000/9543] Elapsed 4m 24s (remain 16m 36s) Loss: 0.1458(0.1656) \n","\t Epoch: [3][3000/9543] Elapsed 6m 37s (remain 14m 26s) Loss: 0.2428(0.1634) \n","\t Epoch: [3][4000/9543] Elapsed 8m 51s (remain 12m 16s) Loss: 0.1127(0.1623) \n","\t Epoch: [3][5000/9543] Elapsed 11m 5s (remain 10m 4s) Loss: 0.3469(0.1619) \n","\t Epoch: [3][6000/9543] Elapsed 13m 19s (remain 7m 51s) Loss: 0.1058(0.1619) \n","\t Epoch: [3][7000/9543] Elapsed 15m 32s (remain 5m 38s) Loss: 0.1898(0.1624) \n","\t Epoch: [3][8000/9543] Elapsed 17m 45s (remain 3m 25s) Loss: 0.2094(0.1618) \n","\t Epoch: [3][9000/9543] Elapsed 19m 58s (remain 1m 12s) Loss: 0.1480(0.1616) \n","\t Epoch: [3][9542/9543] Elapsed 21m 11s (remain 0m 0s) Loss: 0.3034(0.1617) \n","\t EVAL: [0/4769] Elapsed 0m 0s (remain 30m 46s) Loss: 0.0184(0.0184) \n","\t EVAL: [1000/4769] Elapsed 2m 45s (remain 10m 22s) Loss: 0.1521(0.1853) \n","\t EVAL: [2000/4769] Elapsed 5m 32s (remain 7m 40s) Loss: 0.3305(0.1825) \n","\t EVAL: [3000/4769] Elapsed 8m 24s (remain 4m 56s) Loss: 0.0751(0.1767) \n","\t EVAL: [4000/4769] Elapsed 11m 25s (remain 2m 11s) Loss: 0.2043(0.1753) \n","\t EVAL: [4768/4769] Elapsed 13m 43s (remain 0m 0s) Loss: 0.1571(0.1760) \n","\t epoch:3, avg train loss:0.1617, avg valid loss:0.1760\n","\t score:0.6368(th=0.4) AUC = 0.9466=> time:107.80 min\n","\t Epoch 3 - Save Best Score: 0.6368. Model is saved.\n","\t === epoch: 4: training ===\n","\t Epoch: [4][0/9543] Elapsed 0m 0s (remain 98m 22s) Loss: 0.1690(0.1690) \n","\t Epoch: [4][1000/9543] Elapsed 2m 15s (remain 19m 15s) Loss: 0.1013(0.1530) \n","\t Epoch: [4][2000/9543] Elapsed 4m 30s (remain 17m 1s) Loss: 0.1149(0.1522) \n","\t Epoch: [4][3000/9543] Elapsed 6m 45s (remain 14m 44s) Loss: 0.1501(0.1498) \n","\t Epoch: [4][4000/9543] Elapsed 9m 1s (remain 12m 30s) Loss: 0.1427(0.1493) \n","\t Epoch: [4][5000/9543] Elapsed 11m 17s (remain 10m 15s) Loss: 0.1119(0.1487) \n","\t Epoch: [4][6000/9543] Elapsed 13m 31s (remain 7m 59s) Loss: 0.1050(0.1489) \n","\t Epoch: [4][7000/9543] Elapsed 15m 45s (remain 5m 43s) Loss: 0.1700(0.1495) \n","\t Epoch: [4][8000/9543] Elapsed 17m 59s (remain 3m 28s) Loss: 0.1459(0.1487) \n","\t Epoch: [4][9000/9543] Elapsed 20m 13s (remain 1m 13s) Loss: 0.1876(0.1487) \n","\t Epoch: [4][9542/9543] Elapsed 21m 26s (remain 0m 0s) Loss: 0.2566(0.1485) \n","\t EVAL: [0/4769] Elapsed 0m 0s (remain 32m 0s) Loss: 0.0020(0.0020) \n","\t EVAL: [1000/4769] Elapsed 2m 46s (remain 10m 26s) Loss: 0.1516(0.1959) \n","\t EVAL: [2000/4769] Elapsed 5m 34s (remain 7m 43s) Loss: 0.3390(0.1868) \n","\t EVAL: [3000/4769] Elapsed 8m 28s (remain 4m 59s) Loss: 0.0617(0.1756) \n","\t EVAL: [4000/4769] Elapsed 11m 29s (remain 2m 12s) Loss: 0.2010(0.1745) \n","\t EVAL: [4768/4769] Elapsed 13m 54s (remain 0m 0s) Loss: 0.1931(0.1746) \n","\t epoch:4, avg train loss:0.1485, avg valid loss:0.1746\n","\t score:0.6322(th=0.30000000000000004) AUC = 0.9473=> time:143.17 min\n","\t === epoch: 5: training ===\n","\t Epoch: [5][0/9543] Elapsed 0m 0s (remain 113m 33s) Loss: 0.1110(0.1110) \n","\t Epoch: [5][1000/9543] Elapsed 2m 13s (remain 19m 2s) Loss: 0.1497(0.1337) \n","\t Epoch: [5][2000/9543] Elapsed 4m 27s (remain 16m 49s) Loss: 0.0733(0.1348) \n","\t Epoch: [5][3000/9543] Elapsed 6m 42s (remain 14m 37s) Loss: 0.0784(0.1342) \n","\t Epoch: [5][4000/9543] Elapsed 8m 58s (remain 12m 25s) Loss: 0.1190(0.1350) \n","\t Epoch: [5][5000/9543] Elapsed 11m 15s (remain 10m 13s) Loss: 0.1292(0.1349) \n","\t Epoch: [5][6000/9543] Elapsed 13m 32s (remain 7m 59s) Loss: 0.1196(0.1349) \n","\t Epoch: [5][7000/9543] Elapsed 15m 47s (remain 5m 44s) Loss: 0.0505(0.1348) \n","\t Epoch: [5][8000/9543] Elapsed 18m 3s (remain 3m 28s) Loss: 0.1990(0.1352) \n","\t Epoch: [5][9000/9543] Elapsed 20m 17s (remain 1m 13s) Loss: 0.1423(0.1353) \n","\t Epoch: [5][9542/9543] Elapsed 21m 30s (remain 0m 0s) Loss: 0.0797(0.1353) \n","\t EVAL: [0/4769] Elapsed 0m 0s (remain 31m 11s) Loss: 0.0032(0.0032) \n","\t EVAL: [1000/4769] Elapsed 2m 56s (remain 11m 2s) Loss: 0.1133(0.1988) \n","\t EVAL: [2000/4769] Elapsed 5m 44s (remain 7m 56s) Loss: 0.5118(0.1926) \n","\t EVAL: [3000/4769] Elapsed 8m 37s (remain 5m 4s) Loss: 0.0722(0.1883) \n","\t EVAL: [4000/4769] Elapsed 11m 36s (remain 2m 13s) Loss: 0.2346(0.1876) \n","\t EVAL: [4768/4769] Elapsed 13m 55s (remain 0m 0s) Loss: 0.0633(0.1878) \n","\t epoch:5, avg train loss:0.1353, avg valid loss:0.1878\n","\t score:0.6258(th=0.30000000000000004) AUC = 0.9458=> time:178.61 min\n","---\n","fold 1 start training...\n","fold1 is skip\n","---\n","fold 2 start training...\n","fold2 is skip\n"]}],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","    wandb.finish()\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Save oof_df"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:20:32.238761Z","iopub.status.busy":"2023-01-19T12:20:32.238069Z","iopub.status.idle":"2023-01-19T12:20:32.262842Z","shell.execute_reply":"2023-01-19T12:20:32.261886Z","shell.execute_reply.started":"2023-01-19T12:20:32.23872Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>pred</th>\n","      <th>contact</th>\n","      <th>fold</th>\n","      <th>img_emb_0</th>\n","      <th>img_emb_1</th>\n","      <th>img_emb_2</th>\n","      <th>img_emb_3</th>\n","      <th>img_emb_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58241_001260_69_41361_G</td>\n","      <td>0.000459</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-19.628675</td>\n","      <td>13.993147</td>\n","      <td>-0.018411</td>\n","      <td>21.529093</td>\n","      <td>0.115022</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58241_001260_69_43399_G</td>\n","      <td>0.000457</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-19.587709</td>\n","      <td>13.916854</td>\n","      <td>-0.016965</td>\n","      <td>21.452888</td>\n","      <td>0.133929</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58241_001260_69_39998_G</td>\n","      <td>0.000480</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-19.616171</td>\n","      <td>13.967736</td>\n","      <td>-0.004775</td>\n","      <td>21.475004</td>\n","      <td>0.159519</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58257_001078_39_52419_G</td>\n","      <td>0.001252</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-17.775824</td>\n","      <td>12.397271</td>\n","      <td>-0.112856</td>\n","      <td>19.333233</td>\n","      <td>0.163925</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58257_001078_39_46176_G</td>\n","      <td>0.006360</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-13.645697</td>\n","      <td>9.669694</td>\n","      <td>-0.230003</td>\n","      <td>14.917862</td>\n","      <td>0.102154</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>152590</th>\n","      <td>58537_003722_28_40070_41264</td>\n","      <td>0.212634</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-4.656547</td>\n","      <td>3.240875</td>\n","      <td>0.016410</td>\n","      <td>5.150218</td>\n","      <td>0.040912</td>\n","    </tr>\n","    <tr>\n","      <th>152591</th>\n","      <td>58537_003722_10_41264_46214</td>\n","      <td>0.028590</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-9.531161</td>\n","      <td>6.522679</td>\n","      <td>-0.002742</td>\n","      <td>10.429800</td>\n","      <td>0.135724</td>\n","    </tr>\n","    <tr>\n","      <th>152592</th>\n","      <td>58537_003722_10_41264_52418</td>\n","      <td>0.050318</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-7.638847</td>\n","      <td>5.268019</td>\n","      <td>0.002768</td>\n","      <td>8.375302</td>\n","      <td>0.108608</td>\n","    </tr>\n","    <tr>\n","      <th>152593</th>\n","      <td>58537_003722_51_38619_42443</td>\n","      <td>0.583123</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.198788</td>\n","      <td>-0.093540</td>\n","      <td>-0.006778</td>\n","      <td>0.091046</td>\n","      <td>0.008338</td>\n","    </tr>\n","    <tr>\n","      <th>152594</th>\n","      <td>58537_003722_51_38619_43413</td>\n","      <td>0.568500</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.423876</td>\n","      <td>-0.265841</td>\n","      <td>-0.004309</td>\n","      <td>-0.190186</td>\n","      <td>-0.026408</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>152595 rows × 9 columns</p>\n","</div>"],"text/plain":["                         contact_id      pred  contact  fold  img_emb_0  \\\n","0           58241_001260_69_41361_G  0.000459        0     0 -19.628675   \n","1           58241_001260_69_43399_G  0.000457        0     0 -19.587709   \n","2           58241_001260_69_39998_G  0.000480        0     0 -19.616171   \n","3           58257_001078_39_52419_G  0.001252        0     0 -17.775824   \n","4           58257_001078_39_46176_G  0.006360        0     0 -13.645697   \n","...                             ...       ...      ...   ...        ...   \n","152590  58537_003722_28_40070_41264  0.212634        0     0  -4.656547   \n","152591  58537_003722_10_41264_46214  0.028590        0     0  -9.531161   \n","152592  58537_003722_10_41264_52418  0.050318        0     0  -7.638847   \n","152593  58537_003722_51_38619_42443  0.583123        1     0   0.198788   \n","152594  58537_003722_51_38619_43413  0.568500        1     0   0.423876   \n","\n","        img_emb_1  img_emb_2  img_emb_3  img_emb_4  \n","0       13.993147  -0.018411  21.529093   0.115022  \n","1       13.916854  -0.016965  21.452888   0.133929  \n","2       13.967736  -0.004775  21.475004   0.159519  \n","3       12.397271  -0.112856  19.333233   0.163925  \n","4        9.669694  -0.230003  14.917862   0.102154  \n","...           ...        ...        ...        ...  \n","152590   3.240875   0.016410   5.150218   0.040912  \n","152591   6.522679  -0.002742  10.429800   0.135724  \n","152592   5.268019   0.002768   8.375302   0.108608  \n","152593  -0.093540  -0.006778   0.091046   0.008338  \n","152594  -0.265841  -0.004309  -0.190186  -0.026408  \n","\n","[152595 rows x 9 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
