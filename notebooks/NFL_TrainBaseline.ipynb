{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL EDA"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-11T13:46:28.362881Z","iopub.status.busy":"2022-12-11T13:46:28.362256Z","iopub.status.idle":"2022-12-11T13:46:28.591708Z","shell.execute_reply":"2022-12-11T13:46:28.590982Z","shell.execute_reply.started":"2022-12-11T13:46:28.362786Z"},"trusted":true},"outputs":[],"source":["\n","# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","# deep learning\n","import timm\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef\n"," \n","# exp manager\n","import mlflow\n","\n","# from torchmetrics.classification import BinaryMatthewsCorrCoef\n","# matthews_corrcoef = BinaryMatthewsCorrCoef()\n","\n","# from torchmetrics import MatthewsCorrCoef\n","# matthews_corrcoef = MatthewsCorrCoef(num_classes=1)#default threshold=0.5\n","\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T13:46:28.594555Z","iopub.status.busy":"2022-12-11T13:46:28.593848Z","iopub.status.idle":"2022-12-11T13:46:28.60004Z","shell.execute_reply":"2022-12-11T13:46:28.599192Z","shell.execute_reply.started":"2022-12-11T13:46:28.594502Z"},"trusted":true},"outputs":[],"source":["kaggle = False\n","DEBUG = True\n","class CFG:\n","    if kaggle:\n","        BASE_DIR = \"/kaggle/input/nfl-player-contact-detection\"\n","    else:\n","        BASE_DIR = \"/workspace/input\"\n","    TRAIN_HELMET_CSV = os.path.join(BASE_DIR, \"train_baseline_helmets.csv\")\n","    TRAIN_TRACKING_CSV = os.path.join(BASE_DIR, \"train_player_tracking.csv\")\n","    TRAIN_VIDEO_META_CSV = os.path.join(BASE_DIR, \"train_video_metadata.csv\")\n","    TRAIN_LABEL_CSV = os.path.join(BASE_DIR, \"train_labels.csv\")\n","\n","    # data config    \n","    img_size = (224, 224)\n","    batch_size = 64\n","    num_workers = 0\n","    n_fold = 1\n","\n","    # model config\n","    model_name = \"tf_efficientnet_b0\"\n","    out_features = 1\n","    inp_channels= 3\n","    pretrained = True\n","    model_dir = os.path.join(os.path.dirname(BASE_DIR), \"model\")\n","    \n","    # learning config\n","    n_epoch = 20\n","    lr = 1e-6\n","    T_max = 10\n","    min_lr = 1e-7\n","    weight_decay = 1e-6\n","    \n","    # etc\n","    print_freq = 100\n","    random_seed = 21\n","    \n","    MLFLOW_CATEGORY = \"make_baseline\"\n","    EXP_NAME = \"DEBUG\"\n","    if DEBUG:\n","        n_epoch = 10\n","        # epoch_step_valid = 0\n","        # steps_per_epoch = 10\n","        "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def seed_everything(seed=CFG.random_seed):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_snap_frame(row):\n","    elaped_time_start2snap = row.snap_time - row.start_time\n","    elaped_seconds = elaped_time_start2snap.seconds\n","    snap_frame = elaped_seconds*59.95\n","    return snap_frame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def set_inimg_window(crop_area, img_size=(720, 1280)):\n","    left, top, right, bot = crop_area\n","    # set crop area (area size in img size)\n","    crop_left = max(0, left)\n","    crop_top = max(0, top)\n","    if crop_left != left:   right = right - left\n","    if crop_top != top:    bot = bot - top\n","    crop_bot = min(img_size[0], bot)\n","    crop_right = min(img_size[1], right)\n","    if crop_bot != bot:    crop_top = crop_top - (bot - img_size[0])\n","    if crop_right != right:   crop_left = left - (right - img_size[1])\n","    \n","    return [crop_left, crop_top, crop_right, crop_bot]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_player_mask(img, helmet_pos, img_size=(720, 1280, 3), alpha=0.3):\n","    crop_size=[-helmet_pos[2], -helmet_pos[3], helmet_pos[2]*3, helmet_pos[3]*6] # helmetの大きさによってplayerの範囲も変更\n","    base_area = np.array(helmet_pos) + np.array(crop_size) # [left, top, width, height]\n","    # set players area\n","    palyer_area = [base_area[0],  base_area[1], base_area[0] + base_area[2], base_area[1] + base_area[3]]\n","    palyer_area = set_inimg_window(palyer_area)\n","    mask = np.zeros(img_size, dtype=np.uint8)\n","    cv2.rectangle(mask, [palyer_area[0], palyer_area[1]], [palyer_area[2], palyer_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.uint8)\n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_1player_croparea(helmet_pos, img_size=(720, 1280)):\n","    crop_size=[-helmet_pos[2]*3, -helmet_pos[3]*4, helmet_pos[2]*6, helmet_pos[3]*6] # helmetの大きさによってplayerの範囲も変更\n","    players_area = np.array(helmet_pos) + np.array(crop_size) # [left, top, width, height]\n","    # set players area\n","    crop_area = [players_area[0],  players_area[1], players_area[0] + players_area[2], players_area[1] + players_area[3]]\n","    crop_area = set_inimg_window(crop_area)\n","    return crop_area"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_2player_croparea(helmet1_pos, helmet2_pos, img_size=(720, 1280)):\n","    player1_crop_size=[-10, -10, helmet1_pos[2]*4, helmet1_pos[3]*4] # helmetの大きさによってplayerの範囲も変更\n","    player2_crop_size=[-10, -10, helmet2_pos[2]*4, helmet2_pos[3]*4] # helmetの大きさによってplayerの範囲も変更\n","    player1_area = np.array(helmet1_pos) + np.array(player1_crop_size) # [left, top, width, height]\n","    player2_area = np.array(helmet2_pos) + np.array(player2_crop_size) # [left, top, width, height]\n","    # [left, top, width, height] => [left, top, right, bot]\n","    player1_crop_area = np.array([player1_area[0], player1_area[1], player1_area[0]+player1_area[2], player1_area[1]+player1_area[3]]) # [left, top, right, bot]\n","    player2_crop_area = np.array([player2_area[0], player2_area[1], player2_area[0]+player2_area[2], player2_area[1]+player2_area[3]]) # [left, top, right, bot]\n","    # get min max for set pos in img\n","    area_min = np.min(np.array([player1_crop_area, player2_crop_area]), axis=0)\n","    area_max = np.max(np.array([player1_crop_area, player2_crop_area]), axis=0)\n","    crop_area = [area_min[0], area_min[1], area_max[2], area_max[3]]\n","    crop_area = set_inimg_window(crop_area)\n","    return crop_area"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mask_blend(img, mask):\n","    img = np.clip(img, 0, 255).astype(np.uint8)\n","    mask = np.clip(mask, 0, 1).astype(np.uint8)\n","    img = img*mask\n","    img = np.clip(img, 0, 255).astype(np.uint8)\n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def search_helmet(helmet_df, player, frame):\n","    for diff_frame in range(5):\n","        read_frame = frame + diff_frame\n","        player_helmet = helmet_df.query('nfl_player_id==@player and frame==@read_frame')\n","        if len(player_helmet) > 0:\n","            return player_helmet\n","        read_frame = frame - diff_frame\n","        player_helmet = helmet_df.query('nfl_player_id==@player and frame==@read_frame')\n","        if len(player_helmet) > 0:\n","            return player_helmet\n","    return []"]},{"cell_type":"markdown","metadata":{},"source":["# Read Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T13:46:28.602228Z","iopub.status.busy":"2022-12-11T13:46:28.601756Z","iopub.status.idle":"2022-12-11T13:46:56.551352Z","shell.execute_reply":"2022-12-11T13:46:56.550245Z","shell.execute_reply.started":"2022-12-11T13:46:28.602189Z"},"trusted":true},"outputs":[],"source":["helmet_df = pd.read_csv(CFG.TRAIN_HELMET_CSV)\n","tracking_df = pd.read_csv(CFG.TRAIN_TRACKING_CSV)\n","videometa_df = pd.read_csv(CFG.TRAIN_VIDEO_META_CSV, parse_dates=[\"start_time\", \"end_time\", \"snap_time\"])\n","target_df = pd.read_csv(CFG.TRAIN_LABEL_CSV, parse_dates=[\"datetime\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["videometa_df[\"snap_frame\"] = videometa_df.apply(get_snap_frame, axis=1)\n","helmet_df = helmet_df[['game_play', 'view', 'frame', 'nfl_player_id', 'left', 'width', 'top', 'height']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"all game play num = \" ,len(target_df[\"game_play\"].unique()))\n","\n","if not DEBUG:\n","    train_gameplays = target_df[\"game_play\"].unique()[:50]\n","    valid_gameplays = target_df[\"game_play\"].unique()[-10:]\n","else:\n","    train_gameplays = target_df[\"game_play\"].unique()[:2]\n","    valid_gameplays = target_df[\"game_play\"].unique()[-1:]\n","\n","print(len(train_gameplays), len(valid_gameplays))\n","train_videos = [[gameplay,\"Endzone\"] for gameplay in train_gameplays]\n","valid_videos = [[gameplay,\"Endzone\"] for gameplay in valid_gameplays]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, game_play, view, target_df, helmet_df, meta_df, transform=None):\n","        self.target_df = target_df\n","        self.helmet_df = helmet_df\n","        self.meta_df = meta_df\n","        self.transform = transform\n","        self.game_play = game_play\n","        video_file = game_play + \"_\" + view + \".mp4\"\n","        self.view = view\n","        self.video_path = os.path.join(CFG.BASE_DIR, \"train\", video_file)\n","        self.cam = cv2.VideoCapture(self.video_path)\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        game_play1, game_play2, step, player1, player2 = target_info.contact_id.split(\"_\")\n","        # game_play = game_play1 + \"_\" + game_play2\n","        # view = \"Endzone\"\n","        meta_info = self.meta_df.query('game_play==@self.game_play and view==@self.view')\n","        snap_frame = int(meta_info.snap_frame)\n","        read_frame = snap_frame + int(step) \n","        # print(read_frame)\n","        self.cam.set(cv2.CAP_PROP_POS_FRAMES, int(read_frame))\n","        ret, img = self.cam.read()\n","        if ret:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img = np.clip(img, 0, 255).astype(np.uint8)\n","            player1 = int(player1)\n","            helmet_info = self.helmet_df.query('game_play==@self.game_play and view==@self.view')\n","            # player1_helmet = helmet_info.query('nfl_player_id==@player1 and frame==@read_frame')\n","            player1_helmet = search_helmet(helmet_info, player1, read_frame)\n","            if player2 == \"G\":\n","                if len(player1_helmet) > 0:\n","                    # print(\"only player1 p2=G\")\n","                    helmet_pos = [player1_helmet.left.values[0], player1_helmet.top.values[0],\n","                                  player1_helmet.width.values[0], player1_helmet.height.values[0]]\n","                    crop_area = get_1player_croparea(helmet_pos)\n","                    mask = make_player_mask(img, helmet_pos)\n","                    img = mask_blend(img, mask)\n","                    img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","                else:\n","                    # print(\"no player p2=G\")\n","                    pass\n","            else:\n","                player2 = int(player2)\n","                # player2_helmet = helmet_info.query('nfl_player_id==@player2 and frame==@read_frame')\n","                player2_helmet = search_helmet(helmet_info, player2, read_frame)\n","                if len(player2_helmet) == 0 and len(player1_helmet)==0:\n","                    # print(\"no player len0 p2 not G\")\n","                    pass\n","                elif len(player1_helmet) > 0 and len(player2_helmet) == 0:\n","                    # print(\"only player1 p2notG\")\n","                    helmet_pos = [player1_helmet.left.values[0], player1_helmet.top.values[0],\n","                                  player1_helmet.width.values[0], player1_helmet.height.values[0]]\n","                    # img = make_player_mask(img, helmet_pos)\n","                    mask = make_player_mask(img, helmet_pos)\n","                    img = mask_blend(img, mask)\n","                    crop_area = get_1player_croparea(helmet_pos)\n","                    img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]                    \n","                elif len(player2_helmet) > 0 and len(player1_helmet) == 0:\n","                    # print(\"only player2\")\n","                    helmet_pos = [player2_helmet.left.values[0], player2_helmet.top.values[0],\n","                                  player2_helmet.width.values[0], player2_helmet.height.values[0]]\n","                    # img = make_player_mask(img, helmet_pos)\n","                    mask = make_player_mask(img, helmet_pos)\n","                    img = mask_blend(img, mask)\n","                    crop_area = get_1player_croparea(helmet_pos)\n","                    img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","                else:\n","                    # print(\"two players\")\n","                    helmet1_pos = [player1_helmet.left.values[0], player1_helmet.top.values[0],\n","                                  player1_helmet.width.values[0], player1_helmet.height.values[0]]\n","                    helmet2_pos = [player2_helmet.left.values[0], player2_helmet.top.values[0],\n","                                  player2_helmet.width.values[0], player2_helmet.height.values[0]]\n","                    mask1 = make_player_mask(img, helmet1_pos)\n","                    mask2 = make_player_mask(img, helmet2_pos)\n","                    mask = mask1 + mask2\n","                    img = mask_blend(img, mask)\n","                    crop_area = get_2player_croparea(helmet1_pos, helmet2_pos)\n","                    img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","\n","            img = cv2.resize(img, dsize=CFG.img_size)\n","            img = img / 255. # convert to 0-1\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","            target = torch.tensor(target, dtype=torch.float)\n","            return img, target\n","        else:\n","            img = np.zeros(CFG.img_size)\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","            target = torch.tensor(target, dtype=torch.float)\n","            return img, target"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG.model_name,\n","        out_features = CFG.out_features,\n","        inp_channels= CFG.inp_channels,\n","        pretrained = CFG.pretrained\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n","    \n","    def forward(self, image):\n","        output = self.model(image)\n","        return output"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# criterion = nn.BCEWithLogitsLoss() #define in train loop"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(train_loader):    \n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","                \n","        preds = model(images)\n","        loss = criterion(preds, targets)\n","        mlflow.log_metric(\"train loss\", loss.item(), step=batch_idx)\n","        losses.update(loss.item(), CFG.batch_size) \n","        \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        \n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG.print_freq == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        # if batch_idx > 2:\n","        #     break\n","        del preds, images, targets\n","    del batch_time, model\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def valid_fn(model, criterion, valid_videos):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    for game_play, view in valid_videos:\n","        print(f\"[valid] game_play={game_play}, view={view}\")\n","        target_game = target_df.query('game_play==@game_play')\n","        helmet_game = helmet_df.query('game_play==@game_play and view==@view')\n","        videometa_game = videometa_df.query('game_play==@game_play and view==@view')\n","        valid_dataset = NFLDataset(game_play, view, target_game, helmet_game, videometa_game)\n","            \n","        valid_loader = DataLoader(\n","            valid_dataset,\n","            batch_size = CFG.batch_size,\n","            shuffle = False,\n","            num_workers = CFG.num_workers,\n","            pin_memory = True\n","        )\n","        batch_time = AverageMeter()\n","        losses = AverageMeter()\n","        start = end = time.time()\n","        for batch_idx, (images, targets) in enumerate(valid_loader):\n","            images = images.to(device, non_blocking = True).float()\n","            targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","            with torch.no_grad():\n","                preds = model(images)\n","                loss = criterion(preds, targets)\n","                mlflow.log_metric(\"valid loss\", loss.item(), step=batch_idx)\n","                losses.update(loss.item(), CFG.batch_size)\n","                batch_time.update(time.time() - end)\n","                \n","                targets = targets.detach().cpu().numpy().ravel().tolist()\n","                preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","                # targets = (np.array(targets) > 0.5).astype(int)\n","                # preds = (np.array(preds) > 0.5).astype(int)\n","            \n","                test_preds.extend(preds)\n","                test_targets.extend(targets)\n","                # score = matthews_corrcoef(preds, targets)\n","                if batch_idx % CFG.print_freq == 0 or batch_idx == (len(valid_loader)-1):\n","                    print('\\t EVAL: [{0}/{1}] '\n","                        'Elapsed {remain:s} '\n","                        'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                        .format(\n","                            batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                            remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                        ))\n","            # if batch_idx > 2:\n","            #     break\n","        \n","            del preds, images, targets\n","        \n","        test_preds = np.array(test_preds)\n","        test_targets = np.array(test_targets)\n","        del valid_loader, valid_dataset\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return test_targets, test_preds, losses.avg"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Train Loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def training_loop(train_videos, valid_videos):\n","    oof_df = pd.DataFrame()\n","    \"\"\"\n","    instantiate model, cost function and optimizer\n","    \"\"\"\n","    model = NFLNet()\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    # norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n","    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n","    \n","    \"\"\" \n","    Set dataset\n","    \"\"\"\n","    # train_dataset = \"\"\n","    best_score = -np.inf\n","    start_time = end = time.time()\n","    for epoch in range(1, CFG.n_epoch + 1):\n","        print(f'=== epoch: {epoch}: training ===')\n","        for data_idx, (game_play, view) in enumerate(train_videos):\n","            print(f\"[train] game_play={game_play}, view={view}\")\n","            target_game = target_df.query('game_play==@game_play')\n","            helmet_game = helmet_df.query('game_play==@game_play and view==@view')\n","            videometa_game = videometa_df.query('game_play==@game_play and view==@view')\n","            train_dataset = NFLDataset(game_play, view, target_game, helmet_game, videometa_game)\n","\n","            train_loader = DataLoader(\n","                train_dataset,\n","                batch_size = CFG.batch_size,\n","                shuffle = False,\n","                num_workers = CFG.num_workers,\n","                pin_memory = True\n","            )\n","            \"\"\"\n","            train / valid loop\n","            \"\"\"\n","            train_loss_avg = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler)\n","            mlflow.log_metric(\"train loss avg\", train_loss_avg, step=epoch+data_idx)                 \n","        valid_targets, valid_preds, valid_loss_avg = valid_fn(model, criterion, valid_videos)\n","        mlflow.log_metric(\"valid loss avg\", valid_loss_avg, step=epoch)\n","        # valid_score = matthews_corrcoef(valid_preds, valid_targets)\n","        \n","        valid_score = 0\n","        valid_threshold = 0\n","        for idx in range(1, 10, 1):\n","            thr = idx*0.1\n","            valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","            valid_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","            score_tmp = matthews_corrcoef(valid_targets, valid_preds)\n","            mlflow.log_metric(\"valid score tmp\", score_tmp, step=epoch+idx)\n","            if score_tmp > valid_score:\n","                valid_score = score_tmp \n","                valid_threshold = thr           \n","        \n","        mlflow.log_metric(\"valid score\", valid_score, step=epoch)\n","        mlflow.log_metric(\"valid threshold\", valid_threshold, step=epoch)\n","        elapsed = time.time() - start_time\n","        print(f'epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","        # scheduler.step(valid_score)\n","        scheduler.step()\n","        # validationスコアがbestを更新したらモデルを保存する\n","        if valid_score > best_score:\n","            best_score = valid_score\n","            model_name = CFG.model_name\n","            # torch.save(model.state_dict(), f'{CFG.model_dir}/{model_name}_fold{i_fold}.pth')\n","            torch.save(model.state_dict(), f'{CFG.model_dir}/{model_name}.pth')\n","            print(f'Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","            _oof_df = pd.DataFrame({\n","                \"pred\" : valid_preds,\n","                \"target\" : valid_targets,\n","            })\n","            # _oof_df = pd.DataFrame(data={'Id': valid_ids, 'pred':preds, 'fold': i_fold, 'Pawpularity':valid_targets}, index=valid_idx)\n","\n","        del train_loader, train_dataset\n","        gc.collect()\n","        \n","        torch.cuda.empty_cache()\n","        oof_df = pd.concat([oof_df, _oof_df], axis = 1)\n","        return oof_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# RUN EXP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["experiment = mlflow.get_experiment_by_name(CFG.MLFLOW_CATEGORY)\n","if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","    experiment_id = mlflow.create_experiment(\n","                            name=CFG.MLFLOW_CATEGORY)\n","else: # 当該Experiment存在するとき、IDを取得\n","    experiment_id = experiment.experiment_id\n","\n","# mlflow.pytorch.autolog(log_every_n_epoch=1)\n","with mlflow.start_run(experiment_id=experiment_id) as run:\n","    oof_df = training_loop(train_videos, valid_videos)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_dir = os.path.join(os.path.dirname(CFG.BASE_DIR), \"output\")\n","filename = os.path.join(output_dir, f\"oof_{CFG.EXP_NAME}.csv\")\n","num = 0\n","while os.path.exists(filename):\n","    print(filename)\n","    filename = os.path.join(output_dir, f\"oof_{CFG.EXP_NAME}_{num}.csv\")\n","    num += 1\n","display(oof_df)\n","display(oof_df[\"target\"].value_counts())\n","oof_df.to_csv(filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(oof_df)\n","valid_df = pd.DataFrame()\n","for game_play, view in valid_videos:\n","    target_game = target_df.query('game_play==@game_play')\n","    valid_tmp = target_game[[\"game_play\", \"contact\"]]\n","    valid_df = pd.concat([valid_df, valid_tmp])\n","print(len(valid_df), len(oof_df))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
