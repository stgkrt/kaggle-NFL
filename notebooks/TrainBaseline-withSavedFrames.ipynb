{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"model_name\" : \"tf_efficientnet_b0\",\n","        \"out_features\" : 1,\n","        \"inp_channels\": 3,\n","        \"pretrained\" : True,\n","\n","        # learning config\n","        \"n_fold\" : 5,\n","        # \"train_fold\" : [0, 1, 2, 3, 4],\n","        \"train_fold\" : [0],\n","        \"n_epoch\" : 10,\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-6,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 100,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 128,\n","        \"num_workers\" : 0,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"USE_VIDEO_NUM\" : 3,\n","        \"sample_num\" : -1, \n","\n","        \"EXP_CATEGORY\" : \"make_baseline\",\n","        \"EXP_NAME\" : \"baseline002\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 2\n","    CFG[\"train_fold\"] = [0, 1]\n","    CFG[\"sample_num\"] = 1000\n","\n","if CFG[\"kaggle\"]:\n","    CFG[\"INPUT_DIR\"] = \"/kaggle/input/\"\n","    CFG[\"OUTPUT_DIR\"] = \"/kaggle/working\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-baseline-saveframes\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], \"model\")\n","else:\n","    CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","    CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_images\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best):\n","    if CFG[\"kaggle\"]:\n","            pass # set wandb logger\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def set_inimg_window(crop_pos, mask_size, img_size=(720, 1280)):#crop_pos = [left, top, right, bot]\n","    if mask_size[1] >= img_size[0]:\n","        top, bot = 0, img_size[1]\n","    else:\n","        top=(crop_pos[1] + crop_pos[3])//2 - mask_size[1]//2\n","        bot=(crop_pos[1] + crop_pos[3])//2 + mask_size[1]//2\n","        if top < 0:\n","            bot = bot - top\n","            top = 0\n","        elif bot > img_size[0]:\n","            top = top - (bot-img_size[0])\n","            bot = img_size[0]\n","\n","    if mask_size[0] >= img_size[1]:\n","        left, right = 0, img_size[1]\n","    else:\n","        left = (crop_pos[0] + crop_pos[2])//2 - mask_size[0]//2\n","        right = (crop_pos[0] + crop_pos[2])//2 + mask_size[0]//2\n","        if left < 0:\n","            right = right - left\n","            left = 0\n","        elif right > img_size[1]:\n","            left = left - (right - img_size[1])\n","            right = img_size[1]\n","    crop_area = np.array([left, top, right, bot]).astype(np.int)\n","    return crop_area"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["def get_crop_area(p1_helmet, p2_helmet, input_size=(720, 1280), output_size=(448, 448)):\n","    p1_x_center, p1_y_center = p1_helmet[0] + p1_helmet[2]//2, p1_helmet[1] + p1_helmet[3]//2\n","    p2_x_center, p2_y_center = p2_helmet[0] + p2_helmet[2]//2, p2_helmet[1] + p2_helmet[3]//2\n","    if p1_helmet[2] > 0 and p2_helmet[2] > 0:\n","        crop_x_center, crop_y_center = (p1_x_center + p2_x_center)//2, (p1_y_center + p2_y_center)//2\n","    elif p1_helmet[2] > 0:\n","        crop_x_center, crop_y_center = p1_x_center, p1_y_center\n","    elif p2_helmet[2] > 0:\n","        crop_x_center, crop_y_center = p2_x_center, p2_y_center\n","    else:\n","        crop_area = [0, 0, input_size[1], input_size[0]]\n","#         crop_x_center, crop_y_center = p2_x_center, p2_y_center\n","        return crop_area\n","    crop_left = crop_x_center - output_size[1]//2\n","    crop_top = crop_y_center - output_size[0]//2\n","    crop_right = crop_x_center + output_size[1]//2\n","    crop_bot = crop_y_center + output_size[0]//2\n","    crop_area = [crop_left, crop_top, crop_right, crop_bot]\n","    mask_size = (crop_right-crop_left, crop_right-crop_left)\n","    crop_area = set_inimg_window(crop_area, mask_size)\n","    return crop_area"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["def get_playermasked_img(img, helmet_pos, img_size=(720, 1280, 3)):#helmet pos = [left, width, top, height]\n","    if helmet_pos[2] == 0:\n","        return img\n","    mask_size=(helmet_pos[1]+helmet_pos[3]/2)*CFG[\"masksize_helmet_ratio\"]# helmetの大きさによってplayerの範囲も変更\n","    helmet_area = [helmet_pos[0], helmet_pos[2], helmet_pos[0]+helmet_pos[1], helmet_pos[2]+helmet_pos[3]]#[left, top, right, bot]\n","    player_area = set_inimg_window(helmet_area, (mask_size,mask_size))\n","    mask = np.zeros(img_size, dtype=np.float)\n","    cv2.rectangle(mask, [player_area[0], player_area[1]], [player_area[2], player_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.float)\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["38535\n"]}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","target_game_plays = target_df[\"game_play\"].unique()[:CFG[\"USE_VIDEO_NUM\"]]\n","CFG[\"target_game_plays\"] = list(target_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","    \n","print(len(target_df))"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>game_play</th>\n","      <th>datetime</th>\n","      <th>step</th>\n","      <th>nfl_player_id_1</th>\n","      <th>nfl_player_id_2</th>\n","      <th>contact</th>\n","      <th>snap_frame</th>\n","      <th>frame</th>\n","      <th>game_frame</th>\n","      <th>...</th>\n","      <th>E_top_2</th>\n","      <th>E_height_2</th>\n","      <th>S_left_1</th>\n","      <th>S_width_1</th>\n","      <th>S_top_1</th>\n","      <th>S_height_1</th>\n","      <th>S_left_2</th>\n","      <th>S_width_2</th>\n","      <th>S_top_2</th>\n","      <th>S_height_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58168_003392_0_38590_43854</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>43854</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>300</td>\n","      <td>58168_003392_300</td>\n","      <td>...</td>\n","      <td>277.0</td>\n","      <td>21.0</td>\n","      <td>468.0</td>\n","      <td>14.0</td>\n","      <td>370.0</td>\n","      <td>18.0</td>\n","      <td>464.0</td>\n","      <td>14.0</td>\n","      <td>509.0</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58168_003392_0_38590_41944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>41944</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>300</td>\n","      <td>58168_003392_300</td>\n","      <td>...</td>\n","      <td>288.0</td>\n","      <td>33.0</td>\n","      <td>468.0</td>\n","      <td>14.0</td>\n","      <td>370.0</td>\n","      <td>18.0</td>\n","      <td>510.0</td>\n","      <td>13.0</td>\n","      <td>413.0</td>\n","      <td>16.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58168_003392_0_38590_42386</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>42386</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>300</td>\n","      <td>58168_003392_300</td>\n","      <td>...</td>\n","      <td>331.0</td>\n","      <td>21.0</td>\n","      <td>468.0</td>\n","      <td>14.0</td>\n","      <td>370.0</td>\n","      <td>18.0</td>\n","      <td>676.0</td>\n","      <td>15.0</td>\n","      <td>386.0</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58168_003392_0_38590_47944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>47944</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>300</td>\n","      <td>58168_003392_300</td>\n","      <td>...</td>\n","      <td>313.0</td>\n","      <td>18.0</td>\n","      <td>468.0</td>\n","      <td>14.0</td>\n","      <td>370.0</td>\n","      <td>18.0</td>\n","      <td>530.0</td>\n","      <td>14.0</td>\n","      <td>350.0</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58168_003392_0_38590_46137</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>46137</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>300</td>\n","      <td>58168_003392_300</td>\n","      <td>...</td>\n","      <td>351.0</td>\n","      <td>25.0</td>\n","      <td>468.0</td>\n","      <td>14.0</td>\n","      <td>370.0</td>\n","      <td>18.0</td>\n","      <td>798.0</td>\n","      <td>15.0</td>\n","      <td>398.0</td>\n","      <td>15.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 35 columns</p>\n","</div>"],"text/plain":["                   contact_id     game_play                          datetime  \\\n","0  58168_003392_0_38590_43854  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","1  58168_003392_0_38590_41944  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","2  58168_003392_0_38590_42386  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","3  58168_003392_0_38590_47944  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","4  58168_003392_0_38590_46137  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","\n","   step  nfl_player_id_1 nfl_player_id_2  contact  snap_frame  frame  \\\n","0     0            38590           43854        0         300    300   \n","1     0            38590           41944        0         300    300   \n","2     0            38590           42386        0         300    300   \n","3     0            38590           47944        0         300    300   \n","4     0            38590           46137        0         300    300   \n","\n","         game_frame  ... E_top_2 E_height_2  S_left_1  S_width_1  S_top_1  \\\n","0  58168_003392_300  ...   277.0       21.0     468.0       14.0    370.0   \n","1  58168_003392_300  ...   288.0       33.0     468.0       14.0    370.0   \n","2  58168_003392_300  ...   331.0       21.0     468.0       14.0    370.0   \n","3  58168_003392_300  ...   313.0       18.0     468.0       14.0    370.0   \n","4  58168_003392_300  ...   351.0       25.0     468.0       14.0    370.0   \n","\n","   S_height_1  S_left_2  S_width_2  S_top_2  S_height_2  \n","0        18.0     464.0       14.0    509.0        17.0  \n","1        18.0     510.0       13.0    413.0        16.0  \n","2        18.0     676.0       15.0    386.0        17.0  \n","3        18.0     530.0       14.0    350.0        17.0  \n","4        18.0     798.0       15.0    398.0        15.0  \n","\n","[5 rows x 35 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Index(['contact_id', 'game_play', 'datetime', 'step', 'nfl_player_id_1',\n","       'nfl_player_id_2', 'contact', 'snap_frame', 'frame', 'game_frame',\n","       'game_frame_player_1', 'game_frame_player_2', 'x_position_1',\n","       'y_position_1', 'snap_frame_1', 'x_position_2', 'y_position_2',\n","       'snap_frame_2', 'players_dis', 'E_left_1', 'E_width_1', 'E_top_1',\n","       'E_height_1', 'E_left_2', 'E_width_2', 'E_top_2', 'E_height_2',\n","       'S_left_1', 'S_width_1', 'S_top_1', 'S_height_1', 'S_left_2',\n","       'S_width_2', 'S_top_2', 'S_height_2'],\n","      dtype='object')\n"]}],"source":["display(target_df.head())\n","print(target_df.columns)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["157 1381 11.368573497465604\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["contact_df = target_df.query('contact==1')\n","contact_df[\"E_width_1\"].hist(bins=100)\n","print(len(contact_df.query('E_width_1==0')), len(contact_df), len(contact_df.query('E_width_1==0'))/len(contact_df)*100)"]},{"cell_type":"markdown","metadata":{},"source":["Endzoneのviewのplayer1では全体の14%ぐらいがヘルメット検知なしになっている。"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","#         file_id = f\"{game_play}_{view}_{frame:05}.png\"\n","        file_id = f\"{game_play}_Endzone_{frame:05}.png\"\n","        filename = os.path.join(CFG[\"TRAIN_IMG_DIR\"], file_id)\n","        img = cv2.imread(filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","            return img, target\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        # player highlight mask\n","        player1 = target_info.nfl_player_id_1\n","        player2 = target_info.nfl_player_id_2\n","        p1_helmet = np.array([target_info.E_left_1, target_info.E_width_1,\n","                            target_info.E_top_1, target_info.E_height_1]).astype(np.int)\n","        p2_helmet = np.array([target_info.E_left_2, target_info.E_width_2,\n","                            target_info.E_top_2, target_info.E_height_2]).astype(np.int)\n","        mask1 = get_playermasked_img(img, p1_helmet)\n","        mask2 = get_playermasked_img(img, p2_helmet)\n","        mask = np.clip(mask1 + mask2, 0, 1).astype(np.float)\n","        img = mask*img\n","        # crop players area\n","        crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","\n","        img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","        img = cv2.resize(img, dsize=CFG[\"img_size\"])\n","        img = img / 255. # convert to 0-1\n","        img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","        img = torch.tensor(img, dtype=torch.float)\n","        target = torch.tensor(target, dtype=torch.float)\n","        return img, target"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"out_features\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n","    \n","    def forward(self, image):\n","        output = self.model(image)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)                \n","        preds = model(images)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        with torch.no_grad():\n","            preds = model(images)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    \n","    # set model & learning fn\n","    model = NFLNet()\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","    oof_df = pd.DataFrame()\n","    skf = StratifiedKFold(n_splits = CFG[\"n_fold\"], shuffle=True, random_state=CFG[\"random_seed\"])\n","    for fold, (train_idx, valid_idx) in enumerate(skf.split(target_df,target_df[\"contact\"].values)):\n","        if not fold in CFG[\"train_fold\"]:\n","            continue\n","        print(f'fold {fold} training start.')        \n","        # separate train/valid data \n","        train_df = target_df.iloc[train_idx]\n","        valid_df = target_df.iloc[valid_idx]\n","        train_dataset = NFLDataset(train_df)\n","        valid_dataset = NFLDataset(valid_df)\n","        train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","        valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","        # training\n","        best_score = -np.inf\n","        start_time = end = time.time()\n","        for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","            print(f'\\t === epoch: {epoch}: training ===')\n","            train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","            valid_targets, valid_preds, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","            valid_score = -np.inf\n","            valid_threshold = 0\n","            tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","            for idx in range(1, 10, 1):\n","                thr = idx*0.1\n","                valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","                valid_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","                score_tmp = matthews_corrcoef(valid_targets, valid_preds)\n","                cm = confusion_matrix(valid_targets, valid_preds)\n","                tn, fp, fn, tp = cm.flatten()\n","                if score_tmp > valid_score:\n","                    valid_score = score_tmp \n","                    valid_threshold = thr\n","                    tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","            elapsed = time.time() - start_time\n","            print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","            scheduler.step()\n","            # validationスコアがbestを更新したらモデルを保存する\n","            if valid_score > best_score:\n","                best_score = valid_score\n","                model_name = CFG[\"model_name\"]\n","                torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/{model_name}_fold{fold}.pth')\n","                print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                contact_id = valid_df[\"contact_id\"].values\n","                _oof_df = pd.DataFrame({\n","                    \"contact_id\" : contact_id,\n","                    \"pred\" : valid_preds,\n","                    \"target\" : valid_targets,\n","                    \"fold\" : fold,\n","                })\n","            logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best)\n","\n","        del train_loader, train_dataset, valid_loader, valid_dataset\n","        oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","        del _oof_df\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fold 0 training start.\n","\t === epoch: 1: training ===\n","\t Epoch: [1][0/241] Elapsed 0m 14s (remain 58m 59s) Loss: 4.2517(4.2517) \n","\t Epoch: [1][100/241] Elapsed 29m 8s (remain 40m 24s) Loss: 0.0805(0.3255) \n","\t Epoch: [1][200/241] Elapsed 58m 42s (remain 11m 41s) Loss: 0.1358(0.2192) \n","\t Epoch: [1][240/241] Elapsed 70m 30s (remain 0m 0s) Loss: 0.1327(0.1989) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 8s) Loss: 0.1171(0.1171) \n","\t EVAL: [60/61] Elapsed 17m 41s (remain 0m 0s) Loss: 0.0055(0.0890) \n","\t epoch:1, avg train loss:0.1989, avg valid loss:0.0890, score:0.4760(th=0.1) ::: time:5292.37s\n","\t Epoch 1 - Save Best Score: 0.4760. Model is saved.\n","\t === epoch: 2: training ===\n","\t Epoch: [2][0/241] Elapsed 0m 18s (remain 72m 19s) Loss: 0.0611(0.0611) \n","\t Epoch: [2][100/241] Elapsed 29m 45s (remain 41m 14s) Loss: 0.1483(0.0599) \n","\t Epoch: [2][200/241] Elapsed 59m 20s (remain 11m 48s) Loss: 0.0386(0.0615) \n","\t Epoch: [2][240/241] Elapsed 71m 8s (remain 0m 0s) Loss: 0.0418(0.0609) \n","\t EVAL: [0/61] Elapsed 0m 18s (remain 18m 5s) Loss: 0.1138(0.1138) \n","\t EVAL: [60/61] Elapsed 17m 37s (remain 0m 0s) Loss: 0.0126(0.0792) \n","\t epoch:2, avg train loss:0.0609, avg valid loss:0.0792, score:0.5011(th=0.1) ::: time:10618.84s\n","\t Epoch 2 - Save Best Score: 0.5011. Model is saved.\n","\t === epoch: 3: training ===\n","\t Epoch: [3][0/241] Elapsed 0m 18s (remain 72m 1s) Loss: 0.1107(0.1107) \n","\t Epoch: [3][100/241] Elapsed 28m 43s (remain 39m 48s) Loss: 0.0266(0.0428) \n","\t Epoch: [3][200/241] Elapsed 58m 33s (remain 11m 39s) Loss: 0.0492(0.0429) \n","\t Epoch: [3][240/241] Elapsed 70m 21s (remain 0m 0s) Loss: 0.0699(0.0445) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 40s) Loss: 0.0451(0.0451) \n","\t EVAL: [60/61] Elapsed 17m 45s (remain 0m 0s) Loss: 0.0479(0.0714) \n","\t epoch:3, avg train loss:0.0445, avg valid loss:0.0714, score:0.5569(th=0.1) ::: time:15906.13s\n","\t Epoch 3 - Save Best Score: 0.5569. Model is saved.\n","\t === epoch: 4: training ===\n","\t Epoch: [4][0/241] Elapsed 0m 17s (remain 70m 23s) Loss: 0.0720(0.0720) \n","\t Epoch: [4][100/241] Elapsed 30m 6s (remain 41m 44s) Loss: 0.0289(0.0374) \n","\t Epoch: [4][200/241] Elapsed 60m 17s (remain 11m 59s) Loss: 0.0115(0.0368) \n","\t Epoch: [4][240/241] Elapsed 72m 9s (remain 0m 0s) Loss: 0.0223(0.0379) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 55s) Loss: 0.0957(0.0957) \n","\t EVAL: [60/61] Elapsed 17m 55s (remain 0m 0s) Loss: 0.0026(0.0750) \n","\t epoch:4, avg train loss:0.0379, avg valid loss:0.0750, score:0.5101(th=0.1) ::: time:21311.90s\n","\t === epoch: 5: training ===\n","\t Epoch: [5][0/241] Elapsed 0m 18s (remain 73m 4s) Loss: 0.0357(0.0357) \n","\t Epoch: [5][100/241] Elapsed 30m 15s (remain 41m 57s) Loss: 0.0624(0.0331) \n","\t Epoch: [5][200/241] Elapsed 60m 10s (remain 11m 58s) Loss: 0.0423(0.0341) \n","\t Epoch: [5][240/241] Elapsed 72m 7s (remain 0m 0s) Loss: 0.0400(0.0346) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 30s) Loss: 0.0516(0.0516) \n","\t EVAL: [60/61] Elapsed 17m 53s (remain 0m 0s) Loss: 0.1522(0.0729) \n","\t epoch:5, avg train loss:0.0346, avg valid loss:0.0729, score:0.6028(th=0.1) ::: time:26713.35s\n","\t Epoch 5 - Save Best Score: 0.6028. Model is saved.\n","\t === epoch: 6: training ===\n","\t Epoch: [6][0/241] Elapsed 0m 17s (remain 71m 45s) Loss: 0.0287(0.0287) \n","\t Epoch: [6][100/241] Elapsed 30m 9s (remain 41m 48s) Loss: 0.0576(0.0304) \n","\t Epoch: [6][200/241] Elapsed 60m 13s (remain 11m 59s) Loss: 0.0266(0.0306) \n","\t Epoch: [6][240/241] Elapsed 72m 14s (remain 0m 0s) Loss: 0.0300(0.0307) \n","\t EVAL: [0/61] Elapsed 0m 18s (remain 18m 29s) Loss: 0.1143(0.1143) \n","\t EVAL: [60/61] Elapsed 18m 2s (remain 0m 0s) Loss: 0.0097(0.0676) \n","\t epoch:6, avg train loss:0.0307, avg valid loss:0.0676, score:0.6067(th=0.1) ::: time:32130.53s\n","\t Epoch 6 - Save Best Score: 0.6067. Model is saved.\n","\t === epoch: 7: training ===\n","\t Epoch: [7][0/241] Elapsed 0m 18s (remain 73m 58s) Loss: 0.0043(0.0043) \n","\t Epoch: [7][100/241] Elapsed 29m 42s (remain 41m 11s) Loss: 0.0696(0.0266) \n","\t Epoch: [7][200/241] Elapsed 59m 27s (remain 11m 49s) Loss: 0.0196(0.0283) \n","\t Epoch: [7][240/241] Elapsed 71m 16s (remain 0m 0s) Loss: 0.0110(0.0287) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 34s) Loss: 0.0255(0.0255) \n","\t EVAL: [60/61] Elapsed 17m 48s (remain 0m 0s) Loss: 0.0946(0.0702) \n","\t epoch:7, avg train loss:0.0287, avg valid loss:0.0702, score:0.5636(th=0.1) ::: time:37476.45s\n","\t === epoch: 8: training ===\n","\t Epoch: [8][0/241] Elapsed 0m 16s (remain 67m 54s) Loss: 0.0210(0.0210) \n","\t Epoch: [8][100/241] Elapsed 30m 10s (remain 41m 49s) Loss: 0.0077(0.0260) \n","\t Epoch: [8][200/241] Elapsed 60m 22s (remain 12m 0s) Loss: 0.0310(0.0261) \n","\t Epoch: [8][240/241] Elapsed 72m 22s (remain 0m 0s) Loss: 0.0431(0.0272) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 56s) Loss: 0.0730(0.0730) \n","\t EVAL: [60/61] Elapsed 17m 59s (remain 0m 0s) Loss: 0.0129(0.0709) \n","\t epoch:8, avg train loss:0.0272, avg valid loss:0.0709, score:0.5431(th=0.1) ::: time:42899.05s\n","\t === epoch: 9: training ===\n","\t Epoch: [9][0/241] Elapsed 0m 17s (remain 70m 58s) Loss: 0.0612(0.0612) \n","\t Epoch: [9][100/241] Elapsed 30m 14s (remain 41m 55s) Loss: 0.0178(0.0266) \n","\t Epoch: [9][200/241] Elapsed 60m 13s (remain 11m 59s) Loss: 0.0239(0.0257) \n","\t Epoch: [9][240/241] Elapsed 72m 10s (remain 0m 0s) Loss: 0.0518(0.0253) \n","\t EVAL: [0/61] Elapsed 0m 17s (remain 17m 31s) Loss: 0.0224(0.0224) \n","\t EVAL: [60/61] Elapsed 17m 58s (remain 0m 0s) Loss: 0.1107(0.0701) \n","\t epoch:9, avg train loss:0.0253, avg valid loss:0.0701, score:0.5947(th=0.1) ::: time:48308.59s\n","\t === epoch: 10: training ===\n","\t Epoch: [10][0/241] Elapsed 0m 17s (remain 70m 58s) Loss: 0.0168(0.0168) \n","\t Epoch: [10][100/241] Elapsed 30m 31s (remain 42m 18s) Loss: 0.0094(0.0242) \n","\t Epoch: [10][200/241] Elapsed 60m 41s (remain 12m 4s) Loss: 0.0426(0.0245) \n","\t Epoch: [10][240/241] Elapsed 72m 43s (remain 0m 0s) Loss: 0.0254(0.0243) \n","\t EVAL: [0/61] Elapsed 0m 18s (remain 18m 19s) Loss: 0.0587(0.0587) \n","\t EVAL: [60/61] Elapsed 18m 4s (remain 0m 0s) Loss: 0.0051(0.0704) \n","\t epoch:10, avg train loss:0.0243, avg valid loss:0.0704, score:0.5860(th=0.1) ::: time:53756.68s\n"]}],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>pred</th>\n","      <th>target</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58168_003392_0_41257_41944</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58168_003392_0_41257_46137</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58168_003392_0_41257_44869</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58168_003392_0_41944_46445</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58168_003392_0_42386_46137</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7702</th>\n","      <td>58173_003606_129_38642_46108</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7703</th>\n","      <td>58173_003606_129_46151_G</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7704</th>\n","      <td>58173_003606_129_42590_G</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7705</th>\n","      <td>58173_003606_129_43987_G</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7706</th>\n","      <td>58173_003606_129_52581_G</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7707 rows × 4 columns</p>\n","</div>"],"text/plain":["                        contact_id  pred  target  fold\n","0       58168_003392_0_41257_41944     0       0     0\n","1       58168_003392_0_41257_46137     0       0     0\n","2       58168_003392_0_41257_44869     0       0     0\n","3       58168_003392_0_41944_46445     0       0     0\n","4       58168_003392_0_42386_46137     0       0     0\n","...                            ...   ...     ...   ...\n","7702  58173_003606_129_38642_46108     0       0     0\n","7703      58173_003606_129_46151_G     0       0     0\n","7704      58173_003606_129_42590_G     0       0     0\n","7705      58173_003606_129_43987_G     0       0     0\n","7706      58173_003606_129_52581_G     0       0     0\n","\n","[7707 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    pass\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
