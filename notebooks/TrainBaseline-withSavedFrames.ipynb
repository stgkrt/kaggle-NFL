{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"model_name\" : \"tf_efficientnet_b0\",\n","        \"out_features\" : 1,\n","        \"inp_channels\": 3,\n","        \"pretrained\" : True,\n","\n","        # learning config\n","        \"n_epoch\" : 10,\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 100,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 128,\n","        \"shuffle\" : True, \n","        \"num_workers\" : 0,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"TRAIN_VIDEO_NUM\" : 12,\n","        \"VALID_VIDEO_NUM\" : 2,\n","        \"sample_num\" : -1,\n","        \"ONLY_GROUND\" : True,\n","        \"ONLY_PLAYERS\" :  False,\n","        \"USE_ONLY_HELMET_AVAIL\" : True,\n","\n","        \"EXP_CATEGORY\" : \"make_baseline\",\n","        \"EXP_NAME\" : \"baseline014G\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 1\n","    CFG[\"sample_num\"] = 500\n","\n","if CFG[\"kaggle\"]:\n","    CFG[\"INPUT_DIR\"] = \"/kaggle/input/\"\n","    CFG[\"OUTPUT_DIR\"] = \"/kaggle/working\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-baseline-saveframes\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], \"model\")\n","else:\n","    CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","    CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0_3.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_frames\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best):\n","    if CFG[\"kaggle\"]:\n","            pass # set wandb logger\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Scoring Utils"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def score_targetlong_concat(df_, long_df_):\n","    long_df_[\"pred\"] = 0\n","    long_df_.iloc[-1][\"pred\"] = 1\n","\n","    for threshold in [0.1, 0.5, 0.9]:\n","        scoring_df = pd.concat([long_df_[[\"contact_id\", \"contact\", \"pred\"]], df_[[\"contact_id\", \"contact\", \"pred\"]]], axis=0)\n","        scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","        score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","        cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","        tn, fp, fn, tp = cm.flatten()\n","        print(f\"score = {score}, thr={threshold}\")\n","        print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","        mlflow.log_metric(\"oof target concat score\", score, step=int(threshold*10))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def ground_players_score_log(df_, threshold = 0.5):\n","    scoring_df = df_.copy()\n","    concat_df = scoring_df[\"contact_id\"].str.split(\"_\", expand=True) \n","    concat_df.columns=[\"game_key\", \"play_id\", \"step\", \"nfl_player_id_1\", \"nfl_player_id_2\"]\n","    concat_df[\"game_play\"] = concat_df['game_key'].str.cat(concat_df['play_id'].astype(str), sep='_')\n","    concat_df[\"step\"] = concat_df[\"step\"].map(int)\n","    scoring_df = pd.concat([scoring_df, concat_df], axis=1)\n","\n","    scoring_df = scoring_df[scoring_df[\"nfl_player_id_2\"]==\"G\"]\n","    scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","    score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    tn, fp, fn, tp = cm.flatten()\n","    print(\"-- ground score --\")\n","    print(f\"score = {score}, thr={threshold}\")\n","    print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","    mlflow.log_metric(\"oof ground score\", score)\n","\n","\n","    scoring_df = df_.copy()\n","    concat_df = scoring_df[\"contact_id\"].str.split(\"_\", expand=True) \n","    concat_df.columns=[\"game_key\", \"play_id\", \"step\", \"nfl_player_id_1\", \"nfl_player_id_2\"]\n","    concat_df[\"game_play\"] = concat_df['game_key'].str.cat(concat_df['play_id'].astype(str), sep='_')\n","    concat_df[\"step\"] = concat_df[\"step\"].map(int)\n","    scoring_df = pd.concat([scoring_df, concat_df], axis=1)\n","\n","    scoring_df = scoring_df[scoring_df[\"nfl_player_id_2\"]!=\"G\"]\n","    scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","    score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    tn, fp, fn, tp = cm.flatten()\n","    print(\"-- players score --\")\n","    print(f\"score = {score}, thr={threshold}\")\n","    print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","    mlflow.log_metric(\"oof players score\", score)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["def set_inimg_window(crop_pos, mask_size, img_size=(720, 1280)):#crop_pos = [left, top, right, bot]\n","    # print(\"[set_in_window] crop_pos\", crop_pos)\n","    # print(\"[set_in_window] mask_size\",mask_size)\n","    # print(\"[set_in_window] img_size\",img_size)\n","    if mask_size[1] >= img_size[0]:\n","        top, bot = 0, img_size[1]\n","    else:\n","        top=(crop_pos[1] + crop_pos[3])//2 - mask_size[1]//2\n","        bot=(crop_pos[1] + crop_pos[3])//2 + mask_size[1]//2\n","        if top < 0:\n","            bot = bot - top\n","            top = 0\n","        elif bot > img_size[0]:\n","            top = top - (bot-img_size[0])\n","            bot = img_size[0]\n","\n","    if mask_size[0] >= img_size[1]:\n","        left, right = 0, img_size[1]\n","    else:\n","        left = (crop_pos[0] + crop_pos[2])//2 - mask_size[0]//2\n","        right = (crop_pos[0] + crop_pos[2])//2 + mask_size[0]//2\n","        if left < 0:\n","            right = right - left\n","            left = 0\n","        elif right > img_size[1]:\n","            left = left - (right - img_size[1])\n","            right = img_size[1]\n","    crop_area = np.array([left, top, right, bot]).astype(np.int)\n","    return crop_area"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["def get_crop_area(p1_helmet, p2_helmet, input_size=(720, 1280)):#helmet[left, width, top, height]\n","    if (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]==0 and p2_helmet[3]==0):\n","        crop_area = [0, 0, input_size[1], input_size[0]]\n","        # print(\"bose player's helmet is not detected.\")\n","        return crop_area\n","    elif (p2_helmet[1]==0 and p2_helmet[3]==0) and (p1_helmet[1] != 0 and p1_helmet[3]!=0):\n","        # print(\"p1 detected.\")\n","        crop_x_center, crop_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        helmet_base_size = (p1_helmet[1] + p1_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    elif (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]!=0 and p2_helmet[3]!=0):\n","        # print(\"p2 detected.\")\n","        crop_x_center, crop_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        helmet_base_size = (p2_helmet[1] + p2_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    else:\n","    #     print(\"p1 and p2 detected.\")\n","        p1_x_center, p1_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        p2_x_center, p2_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        crop_x_center, crop_y_center = (p1_x_center + p2_x_center)//2, (p1_y_center + p2_y_center)//2\n","        helmet_base_size = (abs(p1_x_center - p2_x_center) + abs(p1_y_center - p2_y_center))*0.5 \\\n","                            + ((p1_helmet[1] + p2_helmet[1])*0.5 + (p1_helmet[3] + p2_helmet[3])*0.5)*0.5*CFG[\"masksize_helmet_ratio\"]*2\n","        output_size = [helmet_base_size, helmet_base_size]\n","    \n","    # print(\"crop center\", crop_x_center, crop_y_center)\n","    crop_left = crop_x_center - output_size[1]//2\n","    crop_top = crop_y_center - output_size[0]//2\n","    crop_right = crop_x_center + output_size[1]//2\n","    crop_bot = crop_y_center + output_size[0]//2\n","    crop_area = [crop_left, crop_top, crop_right, crop_bot]\n","    crop_area = set_inimg_window(crop_area, output_size)\n","    return crop_area"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["def get_playermasked_img(img, helmet_pos, img_size=(720, 1280, 3)):#helmet pos = [left, width, top, height]\n","    if helmet_pos[1] == 0 and helmet_pos[3] == 0:\n","        mask = np.ones_like(img)\n","        return mask\n","    mask_size=(helmet_pos[1]+helmet_pos[3])*0.5*CFG[\"masksize_helmet_ratio\"]# helmetの大きさによってplayerの範囲も変更\n","    helmet_area = [helmet_pos[0], helmet_pos[2], helmet_pos[0]+helmet_pos[1], helmet_pos[2]+helmet_pos[3]]#[left, top, right, bot]\n","    player_area = set_inimg_window(helmet_area, (mask_size,mask_size))\n","    mask = np.zeros(img_size, dtype=np.float)\n","    cv2.rectangle(mask, [player_area[0], player_area[1]], [player_area[2], player_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.float)\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["17527\n"]},{"data":{"text/plain":["0    16537\n","1      990\n","Name: contact, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","train_game_plays = target_df[\"game_play\"].unique()[:CFG[\"TRAIN_VIDEO_NUM\"]]\n","valid_game_plays = target_df[\"game_play\"].unique()[CFG[\"TRAIN_VIDEO_NUM\"]: CFG[\"TRAIN_VIDEO_NUM\"]+CFG[\"VALID_VIDEO_NUM\"]]\n","\n","target_game_plays = list(set(train_game_plays) | set(valid_game_plays))\n","CFG[\"train_game_plays\"] = list(train_game_plays)\n","CFG[\"valid_game_plays\"] = list(valid_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"ONLY_GROUND\"]:\n","    target_df = target_df[target_df[\"nfl_player_id_2\"]==\"G\"]\n","    if CFG[\"USE_ONLY_HELMET_AVAIL\"]:\n","        target_df = target_df[target_df[\"E_width_1\"]!=0]\n","\n","if CFG[\"ONLY_PLAYERS\"]:\n","    target_df = target_df[target_df[\"nfl_player_id_2\"]!=\"G\"]\n","    if CFG[\"USE_ONLY_HELMET_AVAIL\"]:\n","        target_df = target_df[target_df[\"E_width_1\"]!=0]\n","        target_df = target_df[target_df[\"E_width_2\"]!=0]\n","\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","    \n","print(len(target_df))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>game_play</th>\n","      <th>datetime</th>\n","      <th>step</th>\n","      <th>nfl_player_id_1</th>\n","      <th>nfl_player_id_2</th>\n","      <th>contact</th>\n","      <th>frame</th>\n","      <th>game_frame</th>\n","      <th>game_frame_player_1</th>\n","      <th>...</th>\n","      <th>E_top_2</th>\n","      <th>E_height_2</th>\n","      <th>S_left_1</th>\n","      <th>S_width_1</th>\n","      <th>S_top_1</th>\n","      <th>S_height_1</th>\n","      <th>S_left_2</th>\n","      <th>S_width_2</th>\n","      <th>S_top_2</th>\n","      <th>S_height_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24</th>\n","      <td>58168_003392_0_38590_G</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>G</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>58168_003392_0_43854_G</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>43854</td>\n","      <td>G</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_43854</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>465.0</td>\n","      <td>14.0</td>\n","      <td>510.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>58168_003392_0_41257_G</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>41257</td>\n","      <td>G</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_41257</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>628.0</td>\n","      <td>14.0</td>\n","      <td>541.0</td>\n","      <td>17.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>58168_003392_0_41944_G</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>41944</td>\n","      <td>G</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_41944</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>511.0</td>\n","      <td>13.0</td>\n","      <td>415.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>58168_003392_0_42386_G</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>42386</td>\n","      <td>G</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_42386</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>676.0</td>\n","      <td>15.0</td>\n","      <td>387.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 32 columns</p>\n","</div>"],"text/plain":["                contact_id     game_play                          datetime  \\\n","24  58168_003392_0_38590_G  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","25  58168_003392_0_43854_G  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","26  58168_003392_0_41257_G  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","27  58168_003392_0_41944_G  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","28  58168_003392_0_42386_G  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","\n","    step  nfl_player_id_1 nfl_player_id_2  contact  frame        game_frame  \\\n","24     0            38590               G        0    298  58168_003392_298   \n","25     0            43854               G        0    298  58168_003392_298   \n","26     0            41257               G        0    298  58168_003392_298   \n","27     0            41944               G        0    298  58168_003392_298   \n","28     0            42386               G        0    298  58168_003392_298   \n","\n","       game_frame_player_1  ... E_top_2  E_height_2  S_left_1  S_width_1  \\\n","24  58168_003392_298_38590  ...     0.0         0.0     468.0       13.0   \n","25  58168_003392_298_43854  ...     0.0         0.0     465.0       14.0   \n","26  58168_003392_298_41257  ...     0.0         0.0     628.0       14.0   \n","27  58168_003392_298_41944  ...     0.0         0.0     511.0       13.0   \n","28  58168_003392_298_42386  ...     0.0         0.0     676.0       15.0   \n","\n","    S_top_1  S_height_1  S_left_2  S_width_2  S_top_2  S_height_2  \n","24    372.0        18.0       0.0        0.0      0.0         0.0  \n","25    510.0        17.0       0.0        0.0      0.0         0.0  \n","26    541.0        17.0       0.0        0.0      0.0         0.0  \n","27    415.0        15.0       0.0        0.0      0.0         0.0  \n","28    387.0        16.0       0.0        0.0      0.0         0.0  \n","\n","[5 rows x 32 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Index(['contact_id', 'game_play', 'datetime', 'step', 'nfl_player_id_1',\n","       'nfl_player_id_2', 'contact', 'frame', 'game_frame',\n","       'game_frame_player_1', 'game_frame_player_2', 'x_position_1',\n","       'y_position_1', 'x_position_2', 'y_position_2', 'players_dis',\n","       'E_left_1', 'E_width_1', 'E_top_1', 'E_height_1', 'E_left_2',\n","       'E_width_2', 'E_top_2', 'E_height_2', 'S_left_1', 'S_width_1',\n","       'S_top_1', 'S_height_1', 'S_left_2', 'S_width_2', 'S_top_2',\n","       'S_height_2'],\n","      dtype='object')\n"]}],"source":["display(target_df.head())\n","print(target_df.columns)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.ShiftScaleRotate(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])\n","\n","valid_transform = A.Compose([\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","        file_id = f\"{game_play}_Endzone_{frame:04}.jpg\"\n","        filename = os.path.join(CFG[\"TRAIN_IMG_DIR\"], file_id)\n","        img = cv2.imread(filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float32)\n","            return img, target\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        # player highlight mask\n","        player1 = target_info.nfl_player_id_1\n","        player2 = target_info.nfl_player_id_2\n","        p1_helmet = np.array([target_info.E_left_1, target_info.E_width_1,\n","                            target_info.E_top_1, target_info.E_height_1]).astype(np.int)#[left, width, top, height]\n","        p2_helmet = np.array([target_info.E_left_2, target_info.E_width_2,\n","                            target_info.E_top_2, target_info.E_height_2]).astype(np.int)\n","        mask1 = get_playermasked_img(img, p1_helmet)\n","        mask2 = get_playermasked_img(img, p2_helmet)\n","        mask = np.clip(mask1 + mask2, 0, 1).astype(np.float32)\n","        img = (mask*img).astype(np.float32)\n","        # crop players area\n","        crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","        \n","        # for debug\n","        # if CFG[\"DEBUG\"]:\n","            # print(\"p1_helmet\", p1_helmet)\n","            # print(\"p2_helmet\", p2_helmet)\n","            # print(\"crop_area\", crop_area)\n","            # rec_img = cv2.rectangle(img, (p1_helmet[0],p1_helmet[2]), (p1_helmet[0]+p1_helmet[1],p1_helmet[2]+p1_helmet[3]), (0,255,0), thickness=10)\n","            # rec_img = cv2.rectangle(rec_img, (p2_helmet[0],p2_helmet[2]), (p2_helmet[0]+p2_helmet[1],p2_helmet[2]+p2_helmet[3]), (0, 0, 255), thickness=10)\n","            # rec_img = cv2.rectangle(rec_img, (crop_area[0],crop_area[1]), (crop_area[2],crop_area[3]), (255, 0,0), thickness=10)\n","            # plt.figure()\n","            # plt.imshow(rec_img)\n","            # plt.show()\n","            # print(\"---\")\n","\n","        img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","        img = cv2.resize(img, dsize=CFG[\"img_size\"])\n","        img = img / 255. # convert to 0-1\n","        # img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","        # img = np.transpose(img, (1, 2, 0)).astype(np.float32)\n","        # img = torch.tensor(img, dtype=torch.float)\n","        if self.transform is not None:\n","            img = self.transform(image=img)[\"image\"]\n","        # print(\"aug shape\", img.shape)\n","        target = torch.tensor(target, dtype=torch.float32)\n","        \n","        return img, target"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# train_dataset = NFLDataset(target_df, transform=train_transform)\n","# show_img_num = 4\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","\n","\n","# for batch_idx, (images, targets) in enumerate(train_loader):\n","#     fig = plt.figure(figsize=(12, 25))\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()*255\n","#         img = img.transpose((1,2,0))\n","#         fig.add_subplot(1,show_img_num ,idx+1)\n","#         plt.imshow(img)\n","#         plt.title(targets[idx].numpy())\n","#     plt.show()\n","#     break\n","# del train_loader, train_dataset\n","\n","# positive_df = target_df[target_df[\"contact\"]==1]\n","# train_dataset = NFLDataset(positive_df, transform=train_transform)\n","# show_img_num = 4\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","\n","\n","# for batch_idx, (images, targets) in enumerate(train_loader):\n","#     fig = plt.figure(figsize=(12, 25))\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()*255\n","#         img = img.transpose((1,2,0))\n","#         fig.add_subplot(1,show_img_num ,idx+1)\n","#         plt.imshow(img)\n","#         plt.title(targets[idx].numpy())\n","#     plt.show()\n","#     break\n","# del train_loader, train_dataset\n","\n","# raise Exception()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"out_features\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n","    \n","    def forward(self, image):\n","        output = self.model(image)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)                \n","        preds = model(images)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        with torch.no_grad():\n","            preds = model(images)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    \n","    # set model & learning fn\n","    model = NFLNet()\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","    oof_df = pd.DataFrame()\n","\n","    fold = 0\n","    print(f'fold {fold} training start.')        \n","    # separate train/valid data \n","    train_df = target_df[target_df[\"game_play\"].isin(train_game_plays)]\n","    valid_df = target_df[target_df[\"game_play\"].isin(valid_game_plays)]\n","    # train_dataset = NFLDataset(train_df)\n","    # valid_dataset = NFLDataset(valid_df)\n","    train_dataset = NFLDataset(train_df, train_transform)\n","    valid_dataset = NFLDataset(valid_df, valid_transform)\n","    train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = CFG[\"shuffle\"],\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","    valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = CFG[\"shuffle\"],\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","    # training\n","    best_score = -np.inf\n","    start_time = end = time.time()\n","    for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","        print(f'\\t === epoch: {epoch}: training ===')\n","        train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","        valid_targets, valid_preds, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","        valid_score = -np.inf\n","        valid_threshold = 0\n","        tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","        for idx in range(1, 10, 1):\n","            thr = idx*0.1\n","            valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","            valid_binary_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","            score_tmp = matthews_corrcoef(valid_targets, valid_binary_preds)\n","            cm = confusion_matrix(valid_targets, valid_binary_preds)\n","            tn, fp, fn, tp = cm.flatten()\n","            if score_tmp > valid_score:\n","                valid_score = score_tmp \n","                valid_threshold = thr\n","                tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","        elapsed = time.time() - start_time\n","        print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","        scheduler.step()\n","        # validationスコアがbestを更新したらモデルを保存する\n","        if valid_score > best_score:\n","            best_score = valid_score\n","            model_name = CFG[\"model_name\"]\n","            torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/{model_name}_fold{fold}.pth')\n","            print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","            contact_id = valid_df[\"contact_id\"].values\n","            _oof_df = pd.DataFrame({\n","                \"contact_id\" : contact_id,\n","                \"pred\" : valid_preds,\n","                \"contact\" : valid_targets,\n","                \"fold\" : fold,\n","            })\n","        logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best)\n","\n","    del train_loader, train_dataset, valid_loader, valid_dataset\n","    oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","    del _oof_df\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fold 0 training start.\n","\t === epoch: 1: training ===\n","\t Epoch: [1][0/127] Elapsed 0m 7s (remain 15m 22s) Loss: 5.4519(5.4519) \n","\t Epoch: [1][100/127] Elapsed 12m 49s (remain 3m 17s) Loss: 0.1422(0.5731) \n","\t Epoch: [1][126/127] Elapsed 16m 2s (remain 0m 0s) Loss: 0.0191(0.4916) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 14s) Loss: 0.1664(0.1664) \n","\t EVAL: [10/11] Elapsed 1m 19s (remain 0m 0s) Loss: 0.3521(0.2813) \n","\t epoch:1, avg train loss:0.4916, avg valid loss:0.2813, score:0.0784(th=0.30000000000000004) ::: time:1041.90s\n","\t Epoch 1 - Save Best Score: 0.0784. Model is saved.\n","\t === epoch: 2: training ===\n","\t Epoch: [2][0/127] Elapsed 0m 7s (remain 15m 37s) Loss: 0.1503(0.1503) \n","\t Epoch: [2][100/127] Elapsed 12m 42s (remain 3m 16s) Loss: 0.0909(0.1433) \n","\t Epoch: [2][126/127] Elapsed 15m 54s (remain 0m 0s) Loss: 0.1613(0.1417) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 12s) Loss: 0.6006(0.6006) \n","\t EVAL: [10/11] Elapsed 1m 19s (remain 0m 0s) Loss: 0.4034(0.2790) \n","\t epoch:2, avg train loss:0.1417, avg valid loss:0.2790, score:0.1147(th=0.2) ::: time:2076.71s\n","\t Epoch 2 - Save Best Score: 0.1147. Model is saved.\n","\t === epoch: 3: training ===\n","\t Epoch: [3][0/127] Elapsed 0m 7s (remain 16m 16s) Loss: 0.1415(0.1415) \n","\t Epoch: [3][100/127] Elapsed 12m 50s (remain 3m 18s) Loss: 0.0554(0.0971) \n","\t Epoch: [3][126/127] Elapsed 16m 2s (remain 0m 0s) Loss: 0.0597(0.0954) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 10s) Loss: 0.3703(0.3703) \n","\t EVAL: [10/11] Elapsed 1m 20s (remain 0m 0s) Loss: 0.4639(0.3000) \n","\t epoch:3, avg train loss:0.0954, avg valid loss:0.3000, score:0.0724(th=0.2) ::: time:3120.16s\n","\t === epoch: 4: training ===\n","\t Epoch: [4][0/127] Elapsed 0m 7s (remain 15m 46s) Loss: 0.0672(0.0672) \n","\t Epoch: [4][100/127] Elapsed 12m 52s (remain 3m 18s) Loss: 0.0444(0.0768) \n","\t Epoch: [4][126/127] Elapsed 16m 3s (remain 0m 0s) Loss: 0.0401(0.0766) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 14s) Loss: 0.2316(0.2316) \n","\t EVAL: [10/11] Elapsed 1m 22s (remain 0m 0s) Loss: 0.3960(0.3019) \n","\t epoch:4, avg train loss:0.0766, avg valid loss:0.3019, score:0.0929(th=0.1) ::: time:4166.43s\n","\t === epoch: 5: training ===\n","\t Epoch: [5][0/127] Elapsed 0m 8s (remain 16m 59s) Loss: 0.0963(0.0963) \n","\t Epoch: [5][100/127] Elapsed 12m 57s (remain 3m 20s) Loss: 0.0421(0.0654) \n","\t Epoch: [5][126/127] Elapsed 16m 9s (remain 0m 0s) Loss: 0.1998(0.0665) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 17s) Loss: 0.2244(0.2244) \n","\t EVAL: [10/11] Elapsed 1m 19s (remain 0m 0s) Loss: 0.2306(0.2963) \n","\t epoch:5, avg train loss:0.0665, avg valid loss:0.2963, score:0.0724(th=0.2) ::: time:5215.66s\n","\t === epoch: 6: training ===\n","\t Epoch: [6][0/127] Elapsed 0m 7s (remain 16m 7s) Loss: 0.0437(0.0437) \n","\t Epoch: [6][100/127] Elapsed 12m 50s (remain 3m 18s) Loss: 0.0274(0.0537) \n","\t Epoch: [6][126/127] Elapsed 15m 59s (remain 0m 0s) Loss: 0.0606(0.0564) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 13s) Loss: 0.2817(0.2817) \n","\t EVAL: [10/11] Elapsed 1m 21s (remain 0m 0s) Loss: 0.2908(0.2886) \n","\t epoch:6, avg train loss:0.0564, avg valid loss:0.2886, score:0.1361(th=0.5) ::: time:6256.86s\n","\t Epoch 6 - Save Best Score: 0.1361. Model is saved.\n","\t === epoch: 7: training ===\n","\t Epoch: [7][0/127] Elapsed 0m 7s (remain 15m 59s) Loss: 0.0158(0.0158) \n","\t Epoch: [7][100/127] Elapsed 12m 53s (remain 3m 19s) Loss: 0.0396(0.0511) \n","\t Epoch: [7][126/127] Elapsed 16m 3s (remain 0m 0s) Loss: 0.1490(0.0520) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 12s) Loss: 0.6437(0.6437) \n","\t EVAL: [10/11] Elapsed 1m 18s (remain 0m 0s) Loss: 0.1348(0.2980) \n","\t epoch:7, avg train loss:0.0520, avg valid loss:0.2980, score:0.1361(th=0.5) ::: time:7299.31s\n","\t === epoch: 8: training ===\n","\t Epoch: [8][0/127] Elapsed 0m 8s (remain 17m 9s) Loss: 0.1024(0.1024) \n","\t Epoch: [8][100/127] Elapsed 13m 4s (remain 3m 22s) Loss: 0.0404(0.0436) \n","\t Epoch: [8][126/127] Elapsed 16m 20s (remain 0m 0s) Loss: 0.0136(0.0441) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 15s) Loss: 0.4254(0.4254) \n","\t EVAL: [10/11] Elapsed 1m 20s (remain 0m 0s) Loss: 0.2069(0.3044) \n","\t epoch:8, avg train loss:0.0441, avg valid loss:0.3044, score:0.0925(th=0.2) ::: time:8361.17s\n","\t === epoch: 9: training ===\n","\t Epoch: [9][0/127] Elapsed 0m 7s (remain 15m 46s) Loss: 0.0559(0.0559) \n","\t Epoch: [9][100/127] Elapsed 13m 0s (remain 3m 20s) Loss: 0.0235(0.0408) \n","\t Epoch: [9][126/127] Elapsed 16m 15s (remain 0m 0s) Loss: 0.0128(0.0416) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 14s) Loss: 0.2992(0.2992) \n","\t EVAL: [10/11] Elapsed 1m 20s (remain 0m 0s) Loss: 0.3705(0.3157) \n","\t epoch:9, avg train loss:0.0416, avg valid loss:0.3157, score:0.0925(th=0.30000000000000004) ::: time:9417.41s\n","\t === epoch: 10: training ===\n","\t Epoch: [10][0/127] Elapsed 0m 7s (remain 15m 21s) Loss: 0.0280(0.0280) \n","\t Epoch: [10][100/127] Elapsed 12m 56s (remain 3m 19s) Loss: 0.0735(0.0441) \n","\t Epoch: [10][126/127] Elapsed 16m 9s (remain 0m 0s) Loss: 0.0874(0.0433) \n","\t EVAL: [0/11] Elapsed 0m 7s (remain 1m 15s) Loss: 0.1131(0.1131) \n","\t EVAL: [10/11] Elapsed 1m 21s (remain 0m 0s) Loss: 0.1199(0.2941) \n","\t epoch:10, avg train loss:0.0433, avg valid loss:0.2941, score:0.0925(th=0.2) ::: time:10468.61s\n","score = 0.04206477795592081, thr=0.1\n","tn=3843687, fp=4, fn=112, tp=1\n","score = 0.09407071630109799, thr=0.5\n","tn=3843691, fp=0, fn=112, tp=1\n","score = 0.0, thr=0.9\n","tn=3843691, fp=0, fn=113, tp=0\n"]}],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)\n","        target_long_df = pd.read_csv(\"/workspace/input/long_distance_3_target.csv\")\n","        score_targetlong_concat(oof_df, target_long_df)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>pred</th>\n","      <th>contact</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58187_002815_0_52483_G</td>\n","      <td>5.287318e-06</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58187_002815_0_44905_G</td>\n","      <td>1.176369e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58187_002815_0_40089_G</td>\n","      <td>2.500205e-04</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58187_002815_0_43426_G</td>\n","      <td>3.246694e-11</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58187_002815_0_47791_G</td>\n","      <td>5.049017e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1367</th>\n","      <td>58187_003092_83_40039_G</td>\n","      <td>1.651234e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1368</th>\n","      <td>58187_003092_84_52411_G</td>\n","      <td>2.907566e-11</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1369</th>\n","      <td>58187_003092_84_46243_G</td>\n","      <td>4.548631e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1370</th>\n","      <td>58187_003092_84_45635_G</td>\n","      <td>3.186384e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1371</th>\n","      <td>58187_003092_84_40039_G</td>\n","      <td>3.388477e-05</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1372 rows × 4 columns</p>\n","</div>"],"text/plain":["                   contact_id          pred  contact  fold\n","0      58187_002815_0_52483_G  5.287318e-06        0     0\n","1      58187_002815_0_44905_G  1.176369e-05        0     0\n","2      58187_002815_0_40089_G  2.500205e-04        0     0\n","3      58187_002815_0_43426_G  3.246694e-11        0     0\n","4      58187_002815_0_47791_G  5.049017e-05        0     0\n","...                       ...           ...      ...   ...\n","1367  58187_003092_83_40039_G  1.651234e-05        0     0\n","1368  58187_003092_84_52411_G  2.907566e-11        0     0\n","1369  58187_003092_84_46243_G  4.548631e-05        0     0\n","1370  58187_003092_84_45635_G  3.186384e-05        0     0\n","1371  58187_003092_84_40039_G  3.388477e-05        0     0\n","\n","[1372 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    pass\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["<AxesSubplot:>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAATB0lEQVR4nO3cf6zd9X3f8eereBACLRDorpBtzbS1WtGQqfSOMEWqLqUiQCqMVBqB2OKkrqyu9NdASpxmElKiaskayhKWZfWCF5BQSMo62WtoM49wFEUaNCElOEBTbqkT2zKQBuLshqWR1/f+OF+zg3vNvfece8+5936eD+nI3+/n+/l+vp/3vfbrfP05P1JVSJLa8EOTnoAkaXwMfUlqiKEvSQ0x9CWpIYa+JDXE0JekhiwY+kn2JHkhydfmOXZbkkpyQbefJB9NMpvkiSSXDvTdnuSZ7rF9ecuQJC3GYu70PwlcfXJjks3AVcA3B5qvAbZ2j53Ax7u+bwBuB94MXAbcnuS8USYuSVq6BUO/qr4AvDjPoTuBdwODn+7aBtxbfY8A5ya5EHgrsL+qXqyql4D9zPNEIklaWRuGOSnJNuBIVX01yeChjcChgf3DXdup2l/TBRdcUFu2bBlmigB873vf46yzzhr6/LXCOtcX61xfJlHnY4899rdV9aPzHVty6Cd5PfC79Jd2ll2SnfSXhpiamuLDH/7w0GPNzc1x9tlnL9fUVi3rXF+sc32ZRJ1XXHHFN051bJg7/R8HLgJO3OVvAr6S5DLgCLB5oO+mru0IMHNSe2++watqN7AbYHp6umZmZubrtii9Xo9Rzl8rrHN9sc71ZbXVueS3bFbVgar6x1W1paq20F+qubSqngP2Ae/o3sVzOXCsqo4CnwOuSnJe9wLuVV2bJGmMFvOWzU8B/wv4ySSHk+x4je4PAs8Cs8B/Bn4doKpeBD4AfKl7vL9rkySN0YLLO1V10wLHtwxsF3DLKfrtAfYscX6SpGXkJ3IlqSGGviQ1xNCXpIYY+pLUEENfkhqyrkP/wJFjbNn1Wbbs+uykpyJJq8K6Dn1J0qsZ+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDVkwdBPsifJC0m+NtD2+0n+MskTSf5bknMHjr03yWySryd560D71V3bbJJdy16JJGlBi7nT/yRw9Ult+4E3VtWbgL8C3guQ5GLgRuCnu3P+Y5LTkpwGfAy4BrgYuKnrK0kaowVDv6q+ALx4Utv/qKrj3e4jwKZuextwf1X9XVX9DTALXNY9Zqvq2ar6AXB/11eSNEbLsab/K8CfdtsbgUMDxw53badqlySN0YZRTk7yPuA4cN/yTAeS7AR2AkxNTdHr9YYea+pMuO2S/n9IRhlntZubm1vX9Z1gneuLdU7G0KGf5J3ALwJXVlV1zUeAzQPdNnVtvEb7q1TVbmA3wPT0dM3MzAw7Re66by93HOiXePDm4cdZ7Xq9HqP8nNYK61xfrHMyhlreSXI18G7guqp6eeDQPuDGJGckuQjYCvw58CVga5KLkpxO/8XefaNNXZK0VAve6Sf5FDADXJDkMHA7/XfrnAHsTwLwSFX9WlU9meQzwFP0l31uqar/243zG8DngNOAPVX15ArUI0l6DQuGflXdNE/z3a/R//eA35un/UHgwSXNTpK0rPxEriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasiCoZ9kT5IXknxtoO0NSfYneab787yuPUk+mmQ2yRNJLh04Z3vX/5kk21emHEnSa1nMnf4ngatPatsFPFRVW4GHun2Aa4Ct3WMn8HHoP0kAtwNvBi4Dbj/xRCFJGp8FQ7+qvgC8eFLzNuCebvse4PqB9nur7xHg3CQXAm8F9lfVi1X1ErCff/hEIklaYcOu6U9V1dFu+zlgqtveCBwa6He4aztVuyRpjDaMOkBVVZJajskAJNlJf2mIqakper3e0GNNnQm3XXIcYKRxVru5ubl1Xd8J1rm+WOdkDBv6zye5sKqOdss3L3TtR4DNA/02dW1HgJmT2nvzDVxVu4HdANPT0zUzMzNft0W567693HGgX+LBm4cfZ7Xr9XqM8nNaK6xzfbHOyRh2eWcfcOIdONuBvQPt7+jexXM5cKxbBvoccFWS87oXcK/q2iRJY7TgnX6ST9G/S78gyWH678L5IPCZJDuAbwBv77o/CFwLzAIvA+8CqKoXk3wA+FLX7/1VdfKLw5KkFbZg6FfVTac4dOU8fQu45RTj7AH2LGl2kqRl5SdyJakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ0YK/ST/OsmTSb6W5FNJXpfkoiSPJplN8ukkp3d9z+j2Z7vjW5alAknSog0d+kk2Ar8FTFfVG4HTgBuBDwF3VtVPAC8BO7pTdgAvde13dv0kSWM06vLOBuDMJBuA1wNHgZ8HHuiO3wNc321v6/bpjl+ZJCNeX5K0BEOHflUdAT4MfJN+2B8DHgO+U1XHu26HgY3d9kbgUHfu8a7/+cNeX5K0dBuGPTHJefTv3i8CvgP8EXD1qBNKshPYCTA1NUWv1xt6rKkz4bZL+s8/o4yz2s3Nza3r+k6wzvXFOidj6NAHfgH4m6r6FkCSPwbeApybZEN3N78JONL1PwJsBg53y0HnAN8+edCq2g3sBpienq6ZmZmhJ3jXfXu540C/xIM3Dz/Oatfr9Rjl57RWWOf6Yp2TMcqa/jeBy5O8vlubvxJ4CngYuKHrsx3Y223v6/bpjn++qmqE60uSlmiUNf1H6b8g+xXgQDfWbuA9wK1JZumv2d/dnXI3cH7Xfiuwa4R5S5KGMMryDlV1O3D7Sc3PApfN0/f7wC+Pcj1J0mj8RK4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrISKGf5NwkDyT5yyRPJ/nnSd6QZH+SZ7o/z+v6JslHk8wmeSLJpctTgiRpsUa90/8I8GdV9VPAPwWeBnYBD1XVVuChbh/gGmBr99gJfHzEa0uSlmjo0E9yDvBzwN0AVfWDqvoOsA24p+t2D3B9t70NuLf6HgHOTXLhsNeXJC3dKHf6FwHfAv5Lkr9I8okkZwFTVXW06/McMNVtbwQODZx/uGuTJI1Jqmq4E5Np4BHgLVX1aJKPAN8FfrOqzh3o91JVnZfkT4APVtUXu/aHgPdU1ZdPGncn/eUfpqamfvb+++8fan4AL7x4jOf/T3/7ko3nDD3Oajc3N8fZZ5896WmsOOtcX6xz5VxxxRWPVdX0fMc2jDDuYeBwVT3a7T9Af/3++SQXVtXRbvnmhe74EWDzwPmburZXqardwG6A6enpmpmZGXqCd923lzsO9Es8ePPw46x2vV6PUX5Oa4V1ri/WORlDL+9U1XPAoSQ/2TVdCTwF7AO2d23bgb3d9j7gHd27eC4Hjg0sA0mSxmCUO32A3wTuS3I68CzwLvpPJJ9JsgP4BvD2ru+DwLXALPBy11eSNEYjhX5VPQ7Mt2505Tx9C7hllOtJkkbjJ3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDRg79JKcl+Yskf9LtX5Tk0SSzST6d5PSu/Yxuf7Y7vmXUa0uSlmY57vR/G3h6YP9DwJ1V9RPAS8COrn0H8FLXfmfXT5I0RiOFfpJNwNuAT3T7AX4eeKDrcg9wfbe9rdunO35l11+SNCaj3un/e+DdwN93++cD36mq493+YWBjt70ROATQHT/W9ZckjcmGYU9M8ovAC1X1WJKZ5ZpQkp3AToCpqSl6vd7QY02dCbdd0n/+GWWc1W5ubm5d13eCda4v1jkZQ4c+8BbguiTXAq8DfgT4CHBukg3d3fwm4EjX/wiwGTicZANwDvDtkwetqt3AboDp6emamZkZeoJ33beXOw70Szx48/DjrHa9Xo9Rfk5rhXWuL9Y5GUMv71TVe6tqU1VtAW4EPl9VNwMPAzd03bYDe7vtfd0+3fHPV1UNe31J0tKtxPv03wPcmmSW/pr93V373cD5XfutwK4VuLYk6TWMsrzziqrqAb1u+1ngsnn6fB/45eW4niRpOH4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNWTo0E+yOcnDSZ5K8mSS3+7a35Bkf5Jnuj/P69qT5KNJZpM8keTS5SpCkrQ4o9zpHwduq6qLgcuBW5JcDOwCHqqqrcBD3T7ANcDW7rET+PgI15YkDWHo0K+qo1X1lW77fwNPAxuBbcA9Xbd7gOu77W3AvdX3CHBukguHvb4kaemWZU0/yRbgZ4BHgamqOtodeg6Y6rY3AocGTjvctUmSxmTDqAMkORv4r8DvVNV3k7xyrKoqSS1xvJ30l3+Ympqi1+sNPbepM+G2S44DjDTOajc3N7eu6zvBOtcX65yMkUI/yT+iH/j3VdUfd83PJ7mwqo52yzcvdO1HgM0Dp2/q2l6lqnYDuwGmp6drZmZm6Pnddd9e7jjQL/HgzcOPs9r1ej1G+TmtFda5vljnZIzy7p0AdwNPV9UfDBzaB2zvtrcDewfa39G9i+dy4NjAMpAkaQxGudN/C/AvgQNJHu/afhf4IPCZJDuAbwBv7449CFwLzAIvA+8a4dqSpCEMHfpV9UUgpzh85Tz9C7hl2OtJkkbnJ3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDxh76Sa5O8vUks0l2jfv6ktSysYZ+ktOAjwHXABcDNyW5eJxzkKSWbRjz9S4DZqvqWYAk9wPbgKdW+sJbdn32le2DH3zbSl9OklalcYf+RuDQwP5h4M1jnsOrngBOZfCJYalPGD7BSFqtxh36C0qyE9jZ7c4l+foIw10A/O1Q8/jQ0tqXOs4yG7rONcY61xfrXDn/5FQHxh36R4DNA/uburZXVNVuYPdyXCzJl6tqejnGWs2sc32xzvVltdU57nfvfAnYmuSiJKcDNwL7xjwHSWrWWO/0q+p4kt8APgecBuypqifHOQdJatnY1/Sr6kHgwTFdblmWidYA61xfrHN9WVV1pqomPQdJ0pj4NQyS1JA1H/oLfa1DkjOSfLo7/miSLROY5sgWUefPJflKkuNJbpjEHJfDIuq8NclTSZ5I8lCSU741bTVbRJ2/luRAkseTfHGtfnJ9sV+7kuSXklSSVfMul6VYxO/znUm+1f0+H0/yq5OYJwBVtWYf9F8M/mvgx4DTga8CF5/U59eB/9Rt3wh8etLzXqE6twBvAu4Fbpj0nFewziuA13fb/2od/z5/ZGD7OuDPJj3vlaiz6/fDwBeAR4DpSc97hX6f7wT+w6TnWlVr/k7/la91qKofACe+1mHQNuCebvsB4MokGeMcl8OCdVbVwap6Avj7SUxwmSymzoer6uVu9xH6n/VYaxZT53cHds8C1uKLb4v59wnwAeBDwPfHOblltNg6V4W1Hvrzfa3DxlP1qarjwDHg/LHMbvksps71YKl17gD+dEVntDIWVWeSW5L8NfDvgN8a09yW04J1JrkU2FxVC383yuq12L+3v9QtSz6QZPM8x8dirYe+GpXkXwDTwO9Pei4rpao+VlU/DrwH+DeTns9yS/JDwB8At016LmPw34EtVfUmYD//f/Vh7NZ66C/4tQ6DfZJsAM4Bvj2W2S2fxdS5HiyqziS/ALwPuK6q/m5Mc1tOS/193g9cv5ITWiEL1fnDwBuBXpKDwOXAvjX4Yu5ivl7m2wN/Vz8B/OyY5vYPrPXQX8zXOuwDtnfbNwCfr+6VlTWkla+vWLDOJD8D/CH9wH9hAnNcDoupc+vA7tuAZ8Y4v+XymnVW1bGquqCqtlTVFvqv0VxXVV+ezHSHtpjf54UDu9cBT49xfq826VeSl+GV82uBv6L/6vn7urb30//LA/A64I+AWeDPgR+b9JxXqM5/Rn8t8Xv0/yfz5KTnvEJ1/k/geeDx7rFv0nNeoTo/AjzZ1fgw8NOTnvNK1HlS3x5r8N07i/x9/tvu9/nV7vf5U5Oaq5/IlaSGrPXlHUnSEhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ15P8B4eGiQ/50AjsAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["oof_df[\"pred\"].hist(bins=100)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
