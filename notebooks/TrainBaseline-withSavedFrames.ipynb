{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef\n","\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["kaggle = False\n","DEBUG = True\n","class CFG:\n","    if kaggle:\n","        BASE_DIR = \"/kaggle/input/nfl-player-contact-detection\"\n","    else:\n","        BASE_DIR = \"/workspace/input\"\n","    TRAIN_HELMET_CSV = os.path.join(BASE_DIR, \"train_baseline_helmets.csv\")\n","    TRAIN_TRACKING_CSV = os.path.join(BASE_DIR, \"train_player_tracking.csv\")\n","    TRAIN_VIDEO_META_CSV = os.path.join(BASE_DIR, \"train_video_metadata.csv\")\n","    TRAIN_LABEL_CSV = os.path.join(BASE_DIR, \"train_labels.csv\")\n","    TARGET_CSV = os.path.join(\"/kaggle/input/dfl-creatatraindataset-helmet/target_fillna0.csv\")\n","    TRAIN_IMG_DIR = \"/kaggle/input/nfl-baseline-saveframes\"\n","    # data config    \n","    img_size = (224, 224)\n","    batch_size = 64\n","    num_workers = 0\n","    n_fold = 1\n","    masksize_helmet_ratio = 4 # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","\n","    # model config\n","    model_name = \"tf_efficientnet_b0\"\n","    out_features = 1\n","    inp_channels= 3\n","    pretrained = True\n","    model_dir = os.path.join(os.path.dirname(BASE_DIR), \"model\")\n","    if kaggle:\n","        model_dir = \"/kaggle/working\"\n","    \n","    # learning config\n","    n_fold = 5\n","    train_fold = [0, 1, 2, 3, 4]\n","    n_epoch = 20\n","    lr = 1e-6\n","    T_max = 10\n","    min_lr = 1e-7\n","    weight_decay = 1e-6\n","    \n","    # etc\n","    print_freq = 100\n","    random_seed = 21\n","    \n","    MLFLOW_CATEGORY = \"make_baseline\"\n","    EXP_NAME = \"DEBUG\"\n","    if DEBUG:\n","        n_epoch = 3\n","        batch_size=4\n","        train_fold = [0, 1]\n","        # epoch_step_valid = 0\n","        # steps_per_epoch = 10\n","        "]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def seed_everything(seed=CFG.random_seed):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def set_inimg_window(crop_pos, mask_size, img_size=(720, 1280)):#crop_pos = [left, top, right, bot]\n","    if mask_size[1] >= img_size[0]:\n","        top, bot = 0, img_size[1]\n","    else:\n","        top=(crop_pos[1] + crop_pos[3])//2 - mask_size[1]//2\n","        bot=(crop_pos[1] + crop_pos[3])//2 + mask_size[1]//2\n","        if top < 0:\n","            bot = bot - top\n","            top = 0\n","        elif bot > img_size[0]:\n","            top = top - (bot-img_size[0])\n","            bot = img_size[0]\n","\n","    if mask_size[0] >= img_size[1]:\n","        left, right = 0, img_size[1]\n","    else:\n","        left = (crop_pos[0] + crop_pos[2])//2 - mask_size[0]//2\n","        right = (crop_pos[0] + crop_pos[2])//2 + mask_size[0]//2\n","        if left < 0:\n","            right = right - left\n","            left = 0\n","        elif right > img_size[1]:\n","            left = left - (right - img_size[1])\n","            right = img_size[1]\n","    crop_area = np.array([left, top, right, bot]).astype(np.int)\n","    return crop_area"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_crop_area(p1_helmet, p2_helmet, input_size=(720, 1280), output_size=(448, 448)):\n","    p1_x_center, p1_y_center = p1_helmet[0] + p1_helmet[2]//2, p1_helmet[1] + p1_helmet[3]//2\n","    p2_x_center, p2_y_center = p2_helmet[0] + p2_helmet[2]//2, p2_helmet[1] + p2_helmet[3]//2\n","    if p1_helmet[2] > 0 and p2_helmet[2] > 0:\n","        crop_x_center, crop_y_center = (p1_x_center + p2_x_center)//2, (p1_y_center + p2_y_center)//2\n","    elif p1_helmet[2] > 0:\n","        crop_x_center, crop_y_center = p1_x_center, p1_y_center\n","    elif p2_helmet[2] > 0:\n","        crop_x_center, crop_y_center = p2_x_center, p2_y_center\n","    else:\n","        crop_area = [0, 0, input_size[1], input_size[0]]\n","#         crop_x_center, crop_y_center = p2_x_center, p2_y_center\n","        return crop_area\n","    crop_left = crop_x_center - output_size[1]//2\n","    crop_top = crop_y_center - output_size[0]//2\n","    crop_right = crop_x_center + output_size[1]//2\n","    crop_bot = crop_y_center + output_size[0]//2\n","    crop_area = [crop_left, crop_top, crop_right, crop_bot]\n","    mask_size = (crop_right-crop_left, crop_right-crop_left)\n","    crop_area = set_inimg_window(crop_area, mask_size)\n","    return crop_area"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_playermasked_img(img, helmet_pos, img_size=(720, 1280, 3)):#helmet pos = [left, width, top, height]\n","    if helmet_pos[2] == 0:\n","        return img\n","    mask_size=(helmet_pos[1]+helmet_pos[3]/2)*CFG.masksize_helmet_ratio# helmetの大きさによってplayerの範囲も変更\n","    helmet_area = [helmet_pos[0], helmet_pos[2], helmet_pos[0]+helmet_pos[1], helmet_pos[2]+helmet_pos[3]]#[left, top, right, bot]\n","    player_area = set_inimg_window(helmet_area, (mask_size,mask_size))\n","    mask = np.zeros(img_size, dtype=np.float)\n","    cv2.rectangle(mask, [player_area[0], player_area[1]], [player_area[2], player_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.float)\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["target_df = pd.read_csv(CFG.TARGET_CSV)\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","target_game_plays = target_df[\"game_play\"].unique()[:5]\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","print(len(target_df))\n","if DEBUG:\n","    target_df = target_df.sample(20000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["display(target_df.head())\n","print(target_df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["contact_df = target_df.query('contact==1')\n","contact_df[\"E_width_1\"].hist(bins=100)\n","print(len(contact_df.query('E_width_1==0')), len(contact_df), len(contact_df.query('E_width_1==0'))/len(contact_df)*100)"]},{"cell_type":"markdown","metadata":{},"source":["Endzoneのviewのplayer1では全体の14%ぐらいがヘルメット検知なしになっている。"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","#         file_id = f\"{game_play}_{view}_{frame:05}.png\"\n","        file_id = f\"{game_play}_Endzone_{frame:05}.png\"\n","        filename = os.path.join(CFG.TRAIN_IMG_DIR, file_id)\n","        img = cv2.imread(filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","            return img, target\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        # player highlight mask\n","        player1 = target_info.nfl_player_id_1\n","        player2 = target_info.nfl_player_id_2\n","        p1_helmet = np.array([target_info.E_left_1, target_info.E_width_1,\n","                            target_info.E_top_1, target_info.E_height_1]).astype(np.int)\n","        p2_helmet = np.array([target_info.E_left_2, target_info.E_width_2,\n","                            target_info.E_top_2, target_info.E_height_2]).astype(np.int)\n","        mask1 = get_playermasked_img(img, p1_helmet)\n","        mask2 = get_playermasked_img(img, p2_helmet)\n","        mask = np.clip(mask1 + mask2, 0, 1).astype(np.float)\n","        img = mask*img\n","        # crop players area\n","        crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","#         print(p1_helmet)\n","#         print(p2_helmet)\n","#         print(crop_area)\n","        img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","        img = cv2.resize(img, dsize=CFG.img_size)\n","        img = img / 255. # convert to 0-1\n","        img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","        img = torch.tensor(img, dtype=torch.float)\n","        target = torch.tensor(target, dtype=torch.float)\n","        return img, target"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = NFLDataset(target_df)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size = CFG.batch_size,\n","    shuffle = True,\n","    num_workers = CFG.num_workers,\n","    pin_memory = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["show_img_num = 4\n","for batch_idx, (images, targets) in enumerate(train_loader):\n","    fig = plt.figure(figsize=(12, 25))\n","    for idx in range(show_img_num):\n","        img = images[idx].numpy()\n","        img = img.transpose((1,2,0))\n","#         if np.sum(img)>0:\n","        fig.add_subplot(1,show_img_num ,idx+1)\n","        plt.imshow(img)\n","        plt.title(targets[idx].numpy())\n","    plt.show()\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG.model_name,\n","        out_features = CFG.out_features,\n","        inp_channels= CFG.inp_channels,\n","        pretrained = CFG.pretrained\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n","    \n","    def forward(self, image):\n","        output = self.model(image)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)                \n","        preds = model(images)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG.batch_size) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG.print_freq == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        with torch.no_grad():\n","            preds = model(images)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG.batch_size)\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG.print_freq == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    \n","    # set model & learning fn\n","    model = NFLNet()\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n","\n","    oof_df = pd.DataFrame()\n","    skf = StratifiedKFold(n_splits = CFG.n_fold, shuffle=True, random_state=CFG.random_seed)\n","    for fold, (train_idx, valid_idx) in enumerate(skf.split(target_df,target_df[\"contact\"].values)):\n","        print(f'fold {fold} training start.')        \n","        # separate train/valid data \n","        train_df = target_df.iloc[train_idx]\n","        valid_df = target_df.iloc[valid_idx]\n","        train_dataset = NFLDataset(train_df)\n","        valid_dataset = NFLDataset(valid_df)\n","        train_loader = DataLoader(train_dataset,batch_size=CFG.batch_size, shuffle = True,\n","                                    num_workers = CFG.num_workers, pin_memory = True)\n","        valid_loader = DataLoader(valid_dataset,batch_size=CFG.batch_size, shuffle = True,\n","                                    num_workers = CFG.num_workers, pin_memory = True)\n","\n","        # training\n","        best_score = -np.inf\n","        start_time = end = time.time()\n","        for epoch in range(1, CFG.n_epoch + 1):\n","            print(f'=== epoch: {epoch}: training ===')\n","            train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","            valid_targets, valid_preds, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","            valid_score = 0\n","            valid_threshold = 0\n","            for idx in range(1, 10, 1):\n","                thr = idx*0.1\n","                valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","                valid_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","                score_tmp = matthews_corrcoef(valid_targets, valid_preds)\n","                if score_tmp > valid_score:\n","                    valid_score = score_tmp \n","                    valid_threshold = thr           \n","            elapsed = time.time() - start_time\n","            print(f'epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","            scheduler.step()\n","            # validationスコアがbestを更新したらモデルを保存する\n","            if valid_score > best_score:\n","                best_score = valid_score\n","                model_name = CFG.model_name\n","                # torch.save(model.state_dict(), f'{CFG.model_dir}/{model_name}_fold{i_fold}.pth')\n","                torch.save(model.state_dict(), f'{CFG.model_dir}/{model_name}.pth')\n","                print(f'Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                contact_id = valid_df[\"contact_id\"].values\n","                _oof_df = pd.DataFrame({\n","                    \"contact_id\" : contact_id,\n","                    \"pred\" : valid_preds,\n","                    \"target\" : valid_targets,\n","                })\n","\n","        del train_loader, train_dataset, valid_loader, valid_dataset\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        oof_df = pd.concat([oof_df, _oof_df], axis = 1)\n","    return oof_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["oof_df = training_loop(target_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(oof_df)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
