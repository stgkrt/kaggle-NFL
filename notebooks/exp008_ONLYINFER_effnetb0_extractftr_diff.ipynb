{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline\n","- create target_df (distance in tracking_df is lower than threshold=3)\n","https://www.kaggle.com/code/stgkrtua/nfl-creatatraindataset-targetdf\n","- create dataset save frames in target_df\n","https://www.kaggle.com/code/stgkrtua/nfl-createdataset-saveframes\n","- check saved images\n","https://www.kaggle.com/code/stgkrtua/nfl-checkdataset-plotsavedimage"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-19T12:15:11.586666Z","iopub.status.busy":"2023-01-19T12:15:11.585912Z","iopub.status.idle":"2023-01-19T12:15:13.779848Z","shell.execute_reply":"2023-01-19T12:15:13.778792Z","shell.execute_reply.started":"2023-01-19T12:15:11.586576Z"},"trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_auc_score\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.783214Z","iopub.status.busy":"2023-01-19T12:15:13.782224Z","iopub.status.idle":"2023-01-19T12:15:13.801082Z","shell.execute_reply":"2023-01-19T12:15:13.800004Z","shell.execute_reply.started":"2023-01-19T12:15:13.783176Z"},"trusted":true},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"model_name\" : \"tf_efficientnet_b0\",\n","        \"out_features\" : 20,\n","        \"inp_channels\": 3*2,\n","        \"num_extractFTR\" : 5,\n","        \"pretrained\" : True,\n","        \"features\" : ['x_position_1', 'y_position_1', 'x_position_2', 'y_position_2', \n","                      'speed_1', 'distance_1', 'direction_1', 'orientation_1','acceleration_1', 'sa_1', \n","                      'speed_2', 'distance_2', 'direction_2', 'orientation_2', 'acceleration_2', 'sa_2',\n","                      'speed_diff', 'distance_diff', 'direction_diff', 'orientation_diff','acceleration_diff', 'sa_diff', # diff-feature\n","                      'players_dis', 'is_ground'],\n","        \"track_features_x_1\" : ['x_position_shift-6_1','x_position_shift-5_1', 'x_position_shift-4_1',\n","                                'x_position_shift-3_1','x_position_shift-2_1', 'x_position_shift-1_1', \n","                                'x_position_shift0_1','x_position_shift1_1', 'x_position_shift2_1', \n","                                'x_position_shift3_1','x_position_shift4_1', 'x_position_shift5_1'],    \n","        \"track_features_y_1\" : ['y_position_shift-6_1','y_position_shift-5_1', 'y_position_shift-4_1',\n","                                'y_position_shift-3_1','y_position_shift-2_1', 'y_position_shift-1_1',\n","                                'y_position_shift0_1','y_position_shift1_1', 'y_position_shift2_1',\n","                                'y_position_shift3_1','y_position_shift4_1', 'y_position_shift5_1'],\n","        \"track_features_x_2\" : ['x_position_shift-6_2','x_position_shift-5_2', 'x_position_shift-4_2',\n","                                'x_position_shift-3_2','x_position_shift-2_2', 'x_position_shift-1_2',\n","                                'x_position_shift0_2','x_position_shift1_2', 'x_position_shift2_2',\n","                                'x_position_shift3_2','x_position_shift4_2', 'x_position_shift5_2'],\n","        \"track_features_y_2\" : ['y_position_shift-6_2','y_position_shift-5_2', 'y_position_shift-4_2',\n","                                'y_position_shift-3_2','y_position_shift-2_2', 'y_position_shift-1_2',\n","                                'y_position_shift0_2','y_position_shift1_2', 'y_position_shift2_2',\n","                                'y_position_shift3_2','y_position_shift4_2', 'y_position_shift5_2'],\n","        # learning config\n","        \"n_epoch\" : 20,\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 1000,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 32,\n","        \"num_workers\" : 8,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"TRAIN_VIDEO_NUM\" : 100,\n","        \"VALID_VIDEO_NUM\" : 10,\n","        \"sample_num\" : -1, \n","\n","        \"EXP_CATEGORY\" : \"exps\",\n","        \"EXP_NAME\" : \"exp008_effnetb0_extractFTR_diff\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_CATEGORY\"] = \"DEBUG\"\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 2\n","    CFG[\"sample_num\"] = 1000\n","    CFG[\"batch_size\"] = 32\n","\n","if CFG[\"kaggle\"]:\n","    CFG[\"INPUT_DIR\"] = \"/kaggle/input/\"\n","    CFG[\"OUTPUT_DIR\"] = \"/kaggle/working/\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift\", \"saved_frame_target.csv\")\n","    CFG[\"TRAIN_E_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift\", \"train_images\")\n","    CFG[\"TRAIN_S_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift-sview\", \"train_images\")\n","    CFG[\"MODEL_DIR\"] = CFG[\"OUTPUT_DIR\"]\n","else:\n","    CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","    CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0_shift_2.csv\")\n","    CFG[\"TRAIN_E_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_frames\")\n","    CFG[\"TRAIN_S_IMG_DIR\"] = CFG[\"TRAIN_E_IMG_DIR\"]\n","    CFG[\"CONTACT_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"contact_images\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","# if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","#     os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","#     os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.802877Z","iopub.status.busy":"2023-01-19T12:15:13.802383Z","iopub.status.idle":"2023-01-19T12:15:24.348525Z","shell.execute_reply":"2023-01-19T12:15:24.34747Z","shell.execute_reply.started":"2023-01-19T12:15:13.802838Z"},"trusted":true},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"])\n","\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{"_kg_hide-input":true},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.352268Z","iopub.status.busy":"2023-01-19T12:15:24.35167Z","iopub.status.idle":"2023-01-19T12:15:24.3647Z","shell.execute_reply":"2023-01-19T12:15:24.363754Z","shell.execute_reply.started":"2023-01-19T12:15:24.352219Z"},"trusted":true},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best, auc_score):\n","    if CFG[\"kaggle\"]:\n","        wandb.log({\"loss avg\":{f\"train/fold{fold}\": train_loss_avg,\n","                                f\"valid/fold{fold}\": valid_loss_avg}}, step=epoch)\n","        wandb.log({\"Metircs\" : {f\"score/fold{fold}\":score,\n","                                f\"score threshold/fold{fold}\":threshold,\n","                                f\"tn/fold{fold}\":tn_best,\n","                                f\"fp/fold{fold}\":fp_best,\n","                                f\"fn/fold{fold}\":fn_best,\n","                                f\"tp/fold{fold}\":tp_best,\n","                                f\"auc/fold{fold}\":auc_score,\n","                               }}, step=epoch)\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} auc\", auc_score, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.366999Z","iopub.status.busy":"2023-01-19T12:15:24.366307Z","iopub.status.idle":"2023-01-19T12:15:24.418709Z","shell.execute_reply":"2023-01-19T12:15:24.417791Z","shell.execute_reply.started":"2023-01-19T12:15:24.366946Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.425285Z","iopub.status.busy":"2023-01-19T12:15:24.423016Z","iopub.status.idle":"2023-01-19T12:15:24.437655Z","shell.execute_reply":"2023-01-19T12:15:24.436601Z","shell.execute_reply.started":"2023-01-19T12:15:24.425246Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:24.527286Z","iopub.status.busy":"2023-01-19T12:15:24.524605Z","iopub.status.idle":"2023-01-19T12:15:30.921171Z","shell.execute_reply":"2023-01-19T12:15:30.92017Z","shell.execute_reply.started":"2023-01-19T12:15:24.527244Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["305164\n"]},{"data":{"text/plain":["0    274357\n","1     30807\n","Name: contact, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","train_game_plays = target_df[\"game_play\"].unique()[:CFG[\"TRAIN_VIDEO_NUM\"]]\n","valid_game_plays = target_df[\"game_play\"].unique()[-CFG[\"VALID_VIDEO_NUM\"]:]\n","target_game_plays = list(set(train_game_plays) | set(valid_game_plays))\n","CFG[\"target_game_plays\"] = list(target_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","\n","target_df[\"is_ground\"] = (target_df[\"nfl_player_id_2\"] == \"G\").astype(np.int)\n","print(len(target_df))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.927775Z","iopub.status.busy":"2023-01-19T12:15:30.925489Z","iopub.status.idle":"2023-01-19T12:15:30.935228Z","shell.execute_reply":"2023-01-19T12:15:30.934014Z","shell.execute_reply.started":"2023-01-19T12:15:30.927736Z"},"trusted":true},"outputs":[],"source":["# diff_cols = ['speed', 'distance', 'direction', 'orientation','acceleration', 'sa']\n","\n","# for col in diff_cols:\n","#     target_df[f\"{col}_diff\"] = abs(target_df[f\"{col}_1\"] - target_df[f\"{col}_2\"])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.940381Z","iopub.status.busy":"2023-01-19T12:15:30.938161Z","iopub.status.idle":"2023-01-19T12:15:30.959628Z","shell.execute_reply":"2023-01-19T12:15:30.958635Z","shell.execute_reply.started":"2023-01-19T12:15:30.940343Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.3, 0.3), p=0.5),\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])\n","\n","valid_transform = A.Compose([\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.966042Z","iopub.status.busy":"2023-01-19T12:15:30.963888Z","iopub.status.idle":"2023-01-19T12:15:31.022098Z","shell.execute_reply":"2023-01-19T12:15:31.020913Z","shell.execute_reply.started":"2023-01-19T12:15:30.966004Z"},"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.features = target_df[CFG[\"features\"]].values\n","        self.track_features_x_1 = target_df[CFG[\"track_features_x_1\"]].values\n","        self.track_features_y_1 = target_df[CFG[\"track_features_y_1\"]].values\n","        self.track_features_x_2 = target_df[CFG[\"track_features_x_2\"]].values\n","        self.track_features_y_2 = target_df[CFG[\"track_features_y_2\"]].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        features = self.features[idx]\n","        track_x_1 = self.track_features_x_1[idx]\n","        track_y_1 = self.track_features_y_1[idx]\n","        track_x_2 = self.track_features_x_2[idx]\n","        track_y_2 = self.track_features_y_2[idx]\n","        track_features = np.concatenate([track_x_1[np.newaxis, :],\n","                                         track_y_1[np.newaxis, :],\n","                                         track_x_2[np.newaxis, :],\n","                                         track_y_2[np.newaxis, :]])\n","\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","        contact_id = target_info.contact_id\n","        contact_fileid = f\"{contact_id}_Endzone.jpg\"\n","        contact_filename = os.path.join(CFG[\"CONTACT_IMG_DIR\"], contact_fileid)\n","        img = cv2.imread(contact_filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img / 255. # convert to 0-1\n","                img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = img\n","        contact_fileid = f\"{contact_id}_Sideline.jpg\"\n","        contact_filename = os.path.join(CFG[\"CONTACT_IMG_DIR\"], contact_fileid)\n","        img = cv2.imread(contact_filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img / 255. # convert to 0-1\n","                img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = np.concatenate([input_img, img], axis=0)\n","        input_img = torch.tensor(input_img, dtype=torch.float)\n","        target = torch.tensor(target, dtype=torch.float)\n","        features = torch.tensor(features, dtype=torch.float)\n","        track_features = torch.tensor(track_features, dtype=torch.float)\n","        return input_img, features, track_features, target"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.050926Z","iopub.status.busy":"2023-01-19T12:15:31.047836Z","iopub.status.idle":"2023-01-19T12:15:31.08031Z","shell.execute_reply":"2023-01-19T12:15:31.07901Z","shell.execute_reply.started":"2023-01-19T12:15:31.050888Z"},"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"out_features\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes=out_features)\n","        self.mlp = nn.Sequential(\n","                        nn.Linear(len(CFG[\"features\"]), 32),\n","                        nn.LayerNorm(32),\n","                        nn.ReLU(),\n","                        nn.Dropout(0.2),\n","                    )\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(4, 1, 5),\n","                        nn.Linear(len(CFG[\"track_features_y_2\"])-4, 32),\n","                        nn.ReLU(),\n","                    )\n","        self.fc = nn.Linear(out_features+32+32, 1)\n","        self.emb = nn.Linear(out_features+32, CFG[\"num_extractFTR\"])\n","\n","    def forward(self, image, features, track_features):\n","        image_feature = self.model(image)\n","        features = self.mlp(features)\n","        track_features = self.conv1(track_features)\n","        if features.shape[0] == 1:\n","            track_featurs = track_featurs.reshape(1, -1)\n","        else:\n","            track_featurs = torch.squeeze(track_features)\n","        output = self.fc(torch.cat([image_feature, features, track_featurs], dim=1))\n","        embeddings = self.emb(torch.cat([image_feature, track_featurs], dim=1))\n","        return output, embeddings"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.089647Z","iopub.status.busy":"2023-01-19T12:15:31.086565Z","iopub.status.idle":"2023-01-19T12:15:31.108085Z","shell.execute_reply":"2023-01-19T12:15:31.106889Z","shell.execute_reply.started":"2023-01-19T12:15:31.089595Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    for batch_idx, (images, features, track_features, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)      \n","        features = features.to(device, non_blocking = True).float()\n","        track_features = track_features.to(device, non_blocking = True).float()\n","        preds, _ = model(images, features, track_features)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, features, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.124209Z","iopub.status.busy":"2023-01-19T12:15:31.115126Z","iopub.status.idle":"2023-01-19T12:15:31.151039Z","shell.execute_reply":"2023-01-19T12:15:31.150071Z","shell.execute_reply.started":"2023-01-19T12:15:31.124165Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    for batch_idx, (images, features, track_features, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        features = features.to(device, non_blocking = True).float()\n","        track_features = track_features.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds, _ = model(images, features, track_features)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, features, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Create CNN-Emb df"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["276406\n"]},{"data":{"text/plain":["0    251345\n","1     25061\n","Name: contact, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","target_game_plays = target_df[\"game_play\"].unique()[-100:]\n","CFG[\"target_game_plays\"] = list(target_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","\n","target_df = target_df.reset_index(drop=True)\n","target_df[\"is_ground\"] = (target_df[\"nfl_player_id_2\"] == \"G\").astype(np.int)\n","target_df[\"is_helmet\"] = 1 - ((target_df[\"E_width_1\"]==0) & (target_df[\"E_width_2\"]==0) & (target_df[\"S_width_1\"]==0) & (target_df[\"S_width_2\"]==0)).astype(np.int)\n","\n","diff_cols = ['speed', 'distance', 'direction', 'orientation','acceleration', 'sa']\n","\n","for col in diff_cols:\n","    target_df[f\"{col}_diff\"] = abs(target_df[f\"{col}_1\"] - target_df[f\"{col}_2\"])\n","\n","print(len(target_df))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:28:58.749449Z","iopub.status.busy":"2023-01-19T12:28:58.748576Z","iopub.status.idle":"2023-01-19T12:28:58.757764Z","shell.execute_reply":"2023-01-19T12:28:58.755865Z","shell.execute_reply.started":"2023-01-19T12:28:58.74941Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" 8637/8638"]}],"source":["emb_dataset = NFLDataset(target_df, valid_transform)\n","emb_loader = DataLoader(\n","    emb_dataset,\n","    batch_size = CFG[\"batch_size\"],\n","    shuffle = False,\n","    num_workers = CFG[\"num_workers\"],\n","    pin_memory = True\n",")\n","model = NFLNet()\n","model = model.to(device)\n","# model.load_state_dict(torch.load(CFG[\"trained_model_path\"]))\n","model.load_state_dict(torch.load(f'{CFG[\"MODEL_DIR\"]}/{CFG[\"model_name\"]}_fold0.pth'))\n","model.eval()# モデルを検証モードに設定\n","cnn_features = []\n","preds_list = []\n","for batch_idx, (images, features, track_features, targets) in enumerate(emb_loader):\n","    print(\"\\r {}/{}\".format(batch_idx, len(emb_loader)), end=\"\")\n","    images = images.to(device, non_blocking = True).float()\n","    features = features.to(device, non_blocking = True).float()\n","    track_features = track_features.to(device, non_blocking = True).float()    \n","    preds, emb = model(images, features, track_features)    \n","    emb_numpy = emb.detach().cpu().numpy()\n","    preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","    cnn_features.extend(emb_numpy)\n","    preds_list.extend(preds)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cnn_feature_0</th>\n","      <th>cnn_feature_1</th>\n","      <th>cnn_feature_2</th>\n","      <th>cnn_feature_3</th>\n","      <th>cnn_feature_4</th>\n","      <th>cnn_feature_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.136395</td>\n","      <td>-0.673413</td>\n","      <td>0.507142</td>\n","      <td>-2.366220</td>\n","      <td>0.254403</td>\n","      <td>0.112521</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.523748</td>\n","      <td>-0.330362</td>\n","      <td>-0.315764</td>\n","      <td>-0.953514</td>\n","      <td>1.518363</td>\n","      <td>0.003813</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.682343</td>\n","      <td>-0.076067</td>\n","      <td>-0.537305</td>\n","      <td>-1.108595</td>\n","      <td>1.244534</td>\n","      <td>0.001502</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.156566</td>\n","      <td>0.162144</td>\n","      <td>-0.733773</td>\n","      <td>-0.972097</td>\n","      <td>1.638120</td>\n","      <td>0.000244</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.184496</td>\n","      <td>-0.214151</td>\n","      <td>-0.601016</td>\n","      <td>-0.934313</td>\n","      <td>0.937113</td>\n","      <td>0.011210</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>276401</th>\n","      <td>0.498940</td>\n","      <td>-1.355482</td>\n","      <td>-1.817199</td>\n","      <td>0.810515</td>\n","      <td>0.266204</td>\n","      <td>0.000158</td>\n","    </tr>\n","    <tr>\n","      <th>276402</th>\n","      <td>0.907171</td>\n","      <td>-1.103048</td>\n","      <td>-0.278720</td>\n","      <td>0.868856</td>\n","      <td>0.441013</td>\n","      <td>0.000086</td>\n","    </tr>\n","    <tr>\n","      <th>276403</th>\n","      <td>0.490379</td>\n","      <td>-1.905960</td>\n","      <td>-0.841696</td>\n","      <td>0.345230</td>\n","      <td>0.863513</td>\n","      <td>0.000156</td>\n","    </tr>\n","    <tr>\n","      <th>276404</th>\n","      <td>2.163716</td>\n","      <td>-0.368858</td>\n","      <td>1.324089</td>\n","      <td>-1.723379</td>\n","      <td>-0.575344</td>\n","      <td>0.011071</td>\n","    </tr>\n","    <tr>\n","      <th>276405</th>\n","      <td>0.387285</td>\n","      <td>-0.802426</td>\n","      <td>-0.384473</td>\n","      <td>-0.429645</td>\n","      <td>0.840242</td>\n","      <td>0.000091</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>276406 rows × 6 columns</p>\n","</div>"],"text/plain":["        cnn_feature_0  cnn_feature_1  cnn_feature_2  cnn_feature_3  \\\n","0           -0.136395      -0.673413       0.507142      -2.366220   \n","1           -0.523748      -0.330362      -0.315764      -0.953514   \n","2            0.682343      -0.076067      -0.537305      -1.108595   \n","3            0.156566       0.162144      -0.733773      -0.972097   \n","4            0.184496      -0.214151      -0.601016      -0.934313   \n","...               ...            ...            ...            ...   \n","276401       0.498940      -1.355482      -1.817199       0.810515   \n","276402       0.907171      -1.103048      -0.278720       0.868856   \n","276403       0.490379      -1.905960      -0.841696       0.345230   \n","276404       2.163716      -0.368858       1.324089      -1.723379   \n","276405       0.387285      -0.802426      -0.384473      -0.429645   \n","\n","        cnn_feature_4  cnn_feature_5  \n","0            0.254403       0.112521  \n","1            1.518363       0.003813  \n","2            1.244534       0.001502  \n","3            1.638120       0.000244  \n","4            0.937113       0.011210  \n","...               ...            ...  \n","276401       0.266204       0.000158  \n","276402       0.441013       0.000086  \n","276403       0.863513       0.000156  \n","276404      -0.575344       0.011071  \n","276405       0.840242       0.000091  \n","\n","[276406 rows x 6 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["cnn_feature_df = pd.DataFrame(cnn_features, columns=[f'cnn_feature_{i}' for i in range(CFG[\"num_extractFTR\"])])\n","# display(cnn_feature_df)\n","\n","feat_num = CFG[\"num_extractFTR\"]\n","preds_list_numpy = np.array(preds_list)\n","preds_list_numpy = preds_list_numpy.reshape(len(preds_list_numpy))\n","cnn_feature_df[f\"cnn_feature_{feat_num}\"] = preds_list_numpy\n","display(cnn_feature_df)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>cnn_feature_0</th>\n","      <th>cnn_feature_1</th>\n","      <th>cnn_feature_2</th>\n","      <th>cnn_feature_3</th>\n","      <th>cnn_feature_4</th>\n","      <th>cnn_feature_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58403_001076_0_46082_46232</td>\n","      <td>-0.136395</td>\n","      <td>-0.673413</td>\n","      <td>0.507142</td>\n","      <td>-2.366220</td>\n","      <td>0.254403</td>\n","      <td>0.112521</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58403_001076_0_42424_46082</td>\n","      <td>-0.523748</td>\n","      <td>-0.330362</td>\n","      <td>-0.315764</td>\n","      <td>-0.953514</td>\n","      <td>1.518363</td>\n","      <td>0.003813</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58403_001076_0_42424_46232</td>\n","      <td>0.682343</td>\n","      <td>-0.076067</td>\n","      <td>-0.537305</td>\n","      <td>-1.108595</td>\n","      <td>1.244534</td>\n","      <td>0.001502</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58403_001076_0_42424_44876</td>\n","      <td>0.156566</td>\n","      <td>0.162144</td>\n","      <td>-0.733773</td>\n","      <td>-0.972097</td>\n","      <td>1.638120</td>\n","      <td>0.000244</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58403_001076_0_42393_46649</td>\n","      <td>0.184496</td>\n","      <td>-0.214151</td>\n","      <td>-0.601016</td>\n","      <td>-0.934313</td>\n","      <td>0.937113</td>\n","      <td>0.011210</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>276401</th>\n","      <td>58582_003121_91_48220_G</td>\n","      <td>0.498940</td>\n","      <td>-1.355482</td>\n","      <td>-1.817199</td>\n","      <td>0.810515</td>\n","      <td>0.266204</td>\n","      <td>0.000158</td>\n","    </tr>\n","    <tr>\n","      <th>276402</th>\n","      <td>58582_003121_91_47906_G</td>\n","      <td>0.907171</td>\n","      <td>-1.103048</td>\n","      <td>-0.278720</td>\n","      <td>0.868856</td>\n","      <td>0.441013</td>\n","      <td>0.000086</td>\n","    </tr>\n","    <tr>\n","      <th>276403</th>\n","      <td>58582_003121_91_38557_G</td>\n","      <td>0.490379</td>\n","      <td>-1.905960</td>\n","      <td>-0.841696</td>\n","      <td>0.345230</td>\n","      <td>0.863513</td>\n","      <td>0.000156</td>\n","    </tr>\n","    <tr>\n","      <th>276404</th>\n","      <td>58582_003121_91_47872_G</td>\n","      <td>2.163716</td>\n","      <td>-0.368858</td>\n","      <td>1.324089</td>\n","      <td>-1.723379</td>\n","      <td>-0.575344</td>\n","      <td>0.011071</td>\n","    </tr>\n","    <tr>\n","      <th>276405</th>\n","      <td>58582_003121_91_52619_G</td>\n","      <td>0.387285</td>\n","      <td>-0.802426</td>\n","      <td>-0.384473</td>\n","      <td>-0.429645</td>\n","      <td>0.840242</td>\n","      <td>0.000091</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>276406 rows × 7 columns</p>\n","</div>"],"text/plain":["                        contact_id  cnn_feature_0  cnn_feature_1  \\\n","0       58403_001076_0_46082_46232      -0.136395      -0.673413   \n","1       58403_001076_0_42424_46082      -0.523748      -0.330362   \n","2       58403_001076_0_42424_46232       0.682343      -0.076067   \n","3       58403_001076_0_42424_44876       0.156566       0.162144   \n","4       58403_001076_0_42393_46649       0.184496      -0.214151   \n","...                            ...            ...            ...   \n","276401     58582_003121_91_48220_G       0.498940      -1.355482   \n","276402     58582_003121_91_47906_G       0.907171      -1.103048   \n","276403     58582_003121_91_38557_G       0.490379      -1.905960   \n","276404     58582_003121_91_47872_G       2.163716      -0.368858   \n","276405     58582_003121_91_52619_G       0.387285      -0.802426   \n","\n","        cnn_feature_2  cnn_feature_3  cnn_feature_4  cnn_feature_5  \n","0            0.507142      -2.366220       0.254403       0.112521  \n","1           -0.315764      -0.953514       1.518363       0.003813  \n","2           -0.537305      -1.108595       1.244534       0.001502  \n","3           -0.733773      -0.972097       1.638120       0.000244  \n","4           -0.601016      -0.934313       0.937113       0.011210  \n","...               ...            ...            ...            ...  \n","276401      -1.817199       0.810515       0.266204       0.000158  \n","276402      -0.278720       0.868856       0.441013       0.000086  \n","276403      -0.841696       0.345230       0.863513       0.000156  \n","276404       1.324089      -1.723379      -0.575344       0.011071  \n","276405      -0.384473      -0.429645       0.840242       0.000091  \n","\n","[276406 rows x 7 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["concat_df = target_df.copy()\n","concat_df = pd.concat([target_df[\"contact_id\"], cnn_feature_df], axis=1)\n","display(concat_df)\n","exp_name = CFG[\"EXP_NAME\"]\n","cnn_features_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,f\"{exp_name}_emb.csv\")\n","concat_df.to_csv(cnn_features_filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
