{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"model_name\" : \"tf_efficientnet_b0\",\n","        \"out_features\" : 1,\n","        \"inp_channels\": 3*5,\n","        \"pretrained\" : True,\n","\n","        # learning config\n","        \"n_epoch\" : 10,\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 100,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 16,\n","        \"shuffle\" : True, \n","        \"num_workers\" : 0,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"TRAIN_VIDEO_NUM\" : 2,\n","        \"VALID_VIDEO_NUM\" : 1,\n","        \"sample_num\" : -1,\n","        \"ONLY_GROUND\" : False,\n","        \"ONLY_PLAYERS\" :  True,\n","        \"USE_ONLY_HELMET_AVAIL\" : True,\n","\n","        \"EXP_CATEGORY\" : \"make_baseline\",\n","        \"EXP_NAME\" : \"baseline018P_D\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 1\n","    CFG[\"sample_num\"] = 500\n","\n","if CFG[\"kaggle\"]:\n","    CFG[\"INPUT_DIR\"] = \"/kaggle/input/\"\n","    CFG[\"OUTPUT_DIR\"] = \"/kaggle/working\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-baseline-saveframes\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], \"model\")\n","else:\n","    CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","    CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0_3.csv\")\n","    CFG[\"TRAIN_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_frames\")\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best):\n","    if CFG[\"kaggle\"]:\n","            pass # set wandb logger\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Scoring Utils"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def score_targetlong_concat(df_, long_df_):\n","    long_df_[\"pred\"] = 0\n","    long_df_.iloc[-1][\"pred\"] = 1\n","\n","    for threshold in [0.1, 0.5, 0.9]:\n","        scoring_df = pd.concat([long_df_[[\"contact_id\", \"contact\", \"pred\"]], df_[[\"contact_id\", \"contact\", \"pred\"]]], axis=0)\n","        scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","        score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","        cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","        tn, fp, fn, tp = cm.flatten()\n","        print(f\"score = {score}, thr={threshold}\")\n","        print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","        mlflow.log_metric(\"oof target concat score\", score, step=int(threshold*10))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def ground_players_score_log(df_, threshold = 0.5):\n","    scoring_df = df_.copy()\n","    concat_df = scoring_df[\"contact_id\"].str.split(\"_\", expand=True) \n","    concat_df.columns=[\"game_key\", \"play_id\", \"step\", \"nfl_player_id_1\", \"nfl_player_id_2\"]\n","    concat_df[\"game_play\"] = concat_df['game_key'].str.cat(concat_df['play_id'].astype(str), sep='_')\n","    concat_df[\"step\"] = concat_df[\"step\"].map(int)\n","    scoring_df = pd.concat([scoring_df, concat_df], axis=1)\n","\n","    scoring_df = scoring_df[scoring_df[\"nfl_player_id_2\"]==\"G\"]\n","    scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","    score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    tn, fp, fn, tp = cm.flatten()\n","    print(\"-- ground score --\")\n","    print(f\"score = {score}, thr={threshold}\")\n","    print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","    mlflow.log_metric(\"oof ground score\", score)\n","\n","\n","    scoring_df = df_.copy()\n","    concat_df = scoring_df[\"contact_id\"].str.split(\"_\", expand=True) \n","    concat_df.columns=[\"game_key\", \"play_id\", \"step\", \"nfl_player_id_1\", \"nfl_player_id_2\"]\n","    concat_df[\"game_play\"] = concat_df['game_key'].str.cat(concat_df['play_id'].astype(str), sep='_')\n","    concat_df[\"step\"] = concat_df[\"step\"].map(int)\n","    scoring_df = pd.concat([scoring_df, concat_df], axis=1)\n","\n","    scoring_df = scoring_df[scoring_df[\"nfl_player_id_2\"]!=\"G\"]\n","    scoring_df[\"pred\"] = (scoring_df[\"pred\"].values > threshold).astype(int)\n","    score = matthews_corrcoef(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    cm = confusion_matrix(scoring_df[\"contact\"].values, scoring_df[\"pred\"].values)\n","    tn, fp, fn, tp = cm.flatten()\n","    print(\"-- players score --\")\n","    print(f\"score = {score}, thr={threshold}\")\n","    print(f\"tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n","    mlflow.log_metric(\"oof players score\", score)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["def set_inimg_window(crop_pos, mask_size, img_size=(720, 1280)):#crop_pos = [left, top, right, bot]\n","    # print(\"[set_in_window] crop_pos\", crop_pos)\n","    # print(\"[set_in_window] mask_size\",mask_size)\n","    # print(\"[set_in_window] img_size\",img_size)\n","    if mask_size[1] >= img_size[0]:\n","        top, bot = 0, img_size[1]\n","    else:\n","        top=(crop_pos[1] + crop_pos[3])//2 - mask_size[1]//2\n","        bot=(crop_pos[1] + crop_pos[3])//2 + mask_size[1]//2\n","        if top < 0:\n","            bot = bot - top\n","            top = 0\n","        elif bot > img_size[0]:\n","            top = top - (bot-img_size[0])\n","            bot = img_size[0]\n","\n","    if mask_size[0] >= img_size[1]:\n","        left, right = 0, img_size[1]\n","    else:\n","        left = (crop_pos[0] + crop_pos[2])//2 - mask_size[0]//2\n","        right = (crop_pos[0] + crop_pos[2])//2 + mask_size[0]//2\n","        if left < 0:\n","            right = right - left\n","            left = 0\n","        elif right > img_size[1]:\n","            left = left - (right - img_size[1])\n","            right = img_size[1]\n","    crop_area = np.array([left, top, right, bot]).astype(np.int)\n","    return crop_area"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["def get_crop_area(p1_helmet, p2_helmet, input_size=(720, 1280)):#helmet[left, width, top, height]\n","    if (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]==0 and p2_helmet[3]==0):\n","        crop_area = [0, 0, input_size[1], input_size[0]]\n","        # print(\"bose player's helmet is not detected.\")\n","        return crop_area\n","    elif (p2_helmet[1]==0 and p2_helmet[3]==0) and (p1_helmet[1] != 0 and p1_helmet[3]!=0):\n","        # print(\"p1 detected.\")\n","        crop_x_center, crop_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        helmet_base_size = (p1_helmet[1] + p1_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    elif (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]!=0 and p2_helmet[3]!=0):\n","        # print(\"p2 detected.\")\n","        crop_x_center, crop_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        helmet_base_size = (p2_helmet[1] + p2_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    else:\n","    #     print(\"p1 and p2 detected.\")\n","        p1_x_center, p1_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        p2_x_center, p2_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        crop_x_center, crop_y_center = (p1_x_center + p2_x_center)//2, (p1_y_center + p2_y_center)//2\n","        helmet_base_size = (abs(p1_x_center - p2_x_center) + abs(p1_y_center - p2_y_center))*0.5 \\\n","                            + ((p1_helmet[1] + p2_helmet[1])*0.5 + (p1_helmet[3] + p2_helmet[3])*0.5)*0.5*CFG[\"masksize_helmet_ratio\"]*2\n","        output_size = [helmet_base_size, helmet_base_size]\n","    \n","    # print(\"crop center\", crop_x_center, crop_y_center)\n","    crop_left = crop_x_center - output_size[1]//2\n","    crop_top = crop_y_center - output_size[0]//2\n","    crop_right = crop_x_center + output_size[1]//2\n","    crop_bot = crop_y_center + output_size[0]//2\n","    crop_area = [crop_left, crop_top, crop_right, crop_bot]\n","    crop_area = set_inimg_window(crop_area, output_size)\n","    return crop_area"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["def get_playermasked_img(img, helmet_pos, img_size=(720, 1280, 3)):#helmet pos = [left, width, top, height]\n","    if helmet_pos[1] == 0 and helmet_pos[3] == 0:\n","        mask = np.ones_like(img)\n","        return mask\n","    mask_size=(helmet_pos[1]+helmet_pos[3])*0.5*CFG[\"masksize_helmet_ratio\"]# helmetの大きさによってplayerの範囲も変更\n","    helmet_area = [helmet_pos[0], helmet_pos[2], helmet_pos[0]+helmet_pos[1], helmet_pos[2]+helmet_pos[3]]#[left, top, right, bot]\n","    player_area = set_inimg_window(helmet_area, (mask_size,mask_size))\n","    mask = np.zeros(img_size, dtype=np.float)\n","    cv2.rectangle(mask, [player_area[0], player_area[1]], [player_area[2], player_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.float)\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5847\n"]},{"data":{"text/plain":["0    5033\n","1     814\n","Name: contact, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","train_game_plays = target_df[\"game_play\"].unique()[:CFG[\"TRAIN_VIDEO_NUM\"]]\n","valid_game_plays = target_df[\"game_play\"].unique()[CFG[\"TRAIN_VIDEO_NUM\"]: CFG[\"TRAIN_VIDEO_NUM\"]+CFG[\"VALID_VIDEO_NUM\"]]\n","\n","target_game_plays = list(set(train_game_plays) | set(valid_game_plays))\n","CFG[\"train_game_plays\"] = list(train_game_plays)\n","CFG[\"valid_game_plays\"] = list(valid_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"ONLY_GROUND\"]:\n","    target_df = target_df[target_df[\"nfl_player_id_2\"]==\"G\"]\n","    if CFG[\"USE_ONLY_HELMET_AVAIL\"]:\n","        target_df = target_df[target_df[\"E_width_1\"]!=0]\n","\n","if CFG[\"ONLY_PLAYERS\"]:\n","    target_df = target_df[target_df[\"nfl_player_id_2\"]!=\"G\"]\n","    if CFG[\"USE_ONLY_HELMET_AVAIL\"]:\n","        target_df = target_df[target_df[\"E_width_1\"]!=0]\n","        target_df = target_df[target_df[\"E_width_2\"]!=0]\n","\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","    \n","print(len(target_df))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>game_play</th>\n","      <th>datetime</th>\n","      <th>step</th>\n","      <th>nfl_player_id_1</th>\n","      <th>nfl_player_id_2</th>\n","      <th>contact</th>\n","      <th>frame</th>\n","      <th>game_frame</th>\n","      <th>game_frame_player_1</th>\n","      <th>...</th>\n","      <th>E_top_2</th>\n","      <th>E_height_2</th>\n","      <th>S_left_1</th>\n","      <th>S_width_1</th>\n","      <th>S_top_1</th>\n","      <th>S_height_1</th>\n","      <th>S_left_2</th>\n","      <th>S_width_2</th>\n","      <th>S_top_2</th>\n","      <th>S_height_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58168_003392_0_38590_41944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>41944</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>291.0</td>\n","      <td>34.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>511.0</td>\n","      <td>13.0</td>\n","      <td>415.0</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58168_003392_0_38590_47944</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>47944</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>315.0</td>\n","      <td>17.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>530.0</td>\n","      <td>14.0</td>\n","      <td>351.0</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58168_003392_0_38590_44822</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>44822</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>254.0</td>\n","      <td>33.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>427.0</td>\n","      <td>14.0</td>\n","      <td>384.0</td>\n","      <td>19.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58168_003392_0_38590_39947</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>39947</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>281.0</td>\n","      <td>34.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>473.0</td>\n","      <td>15.0</td>\n","      <td>342.0</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58168_003392_0_38590_42565</td>\n","      <td>58168_003392</td>\n","      <td>2020-09-11 03:01:48.100000+00:00</td>\n","      <td>0</td>\n","      <td>38590</td>\n","      <td>42565</td>\n","      <td>0</td>\n","      <td>298</td>\n","      <td>58168_003392_298</td>\n","      <td>58168_003392_298_38590</td>\n","      <td>...</td>\n","      <td>313.0</td>\n","      <td>19.0</td>\n","      <td>468.0</td>\n","      <td>13.0</td>\n","      <td>372.0</td>\n","      <td>18.0</td>\n","      <td>478.0</td>\n","      <td>15.0</td>\n","      <td>400.0</td>\n","      <td>18.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 32 columns</p>\n","</div>"],"text/plain":["                   contact_id     game_play                          datetime  \\\n","0  58168_003392_0_38590_41944  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","1  58168_003392_0_38590_47944  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","2  58168_003392_0_38590_44822  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","3  58168_003392_0_38590_39947  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","4  58168_003392_0_38590_42565  58168_003392  2020-09-11 03:01:48.100000+00:00   \n","\n","   step  nfl_player_id_1 nfl_player_id_2  contact  frame        game_frame  \\\n","0     0            38590           41944        0    298  58168_003392_298   \n","1     0            38590           47944        0    298  58168_003392_298   \n","2     0            38590           44822        0    298  58168_003392_298   \n","3     0            38590           39947        0    298  58168_003392_298   \n","4     0            38590           42565        0    298  58168_003392_298   \n","\n","      game_frame_player_1  ... E_top_2  E_height_2  S_left_1  S_width_1  \\\n","0  58168_003392_298_38590  ...   291.0        34.0     468.0       13.0   \n","1  58168_003392_298_38590  ...   315.0        17.0     468.0       13.0   \n","2  58168_003392_298_38590  ...   254.0        33.0     468.0       13.0   \n","3  58168_003392_298_38590  ...   281.0        34.0     468.0       13.0   \n","4  58168_003392_298_38590  ...   313.0        19.0     468.0       13.0   \n","\n","   S_top_1  S_height_1  S_left_2  S_width_2  S_top_2  S_height_2  \n","0    372.0        18.0     511.0       13.0    415.0        15.0  \n","1    372.0        18.0     530.0       14.0    351.0        17.0  \n","2    372.0        18.0     427.0       14.0    384.0        19.0  \n","3    372.0        18.0     473.0       15.0    342.0        18.0  \n","4    372.0        18.0     478.0       15.0    400.0        18.0  \n","\n","[5 rows x 32 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Index(['contact_id', 'game_play', 'datetime', 'step', 'nfl_player_id_1',\n","       'nfl_player_id_2', 'contact', 'frame', 'game_frame',\n","       'game_frame_player_1', 'game_frame_player_2', 'x_position_1',\n","       'y_position_1', 'x_position_2', 'y_position_2', 'players_dis',\n","       'E_left_1', 'E_width_1', 'E_top_1', 'E_height_1', 'E_left_2',\n","       'E_width_2', 'E_top_2', 'E_height_2', 'S_left_1', 'S_width_1',\n","       'S_top_1', 'S_height_1', 'S_left_2', 'S_width_2', 'S_top_2',\n","       'S_height_2'],\n","      dtype='object')\n"]}],"source":["display(target_df.head())\n","print(target_df.columns)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.ShiftScaleRotate(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])\n","\n","valid_transform = A.Compose([\n","    A.Normalize(mean=[0.], std=[1.]),\n","    ToTensorV2()\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","        input_img = None\n","        load_frame_list = [-6, -3, 0, 3, 6]\n","        for load_idx in range(CFG[\"inp_channels\"]//3):\n","            load_frame = frame + load_frame_list[load_idx]\n","            file_id = f\"{game_play}_Endzone_{load_frame:04}.jpg\"\n","            # file_id = f\"{game_play}_Endzone_{frame:04}.jpg\"\n","            filename = os.path.join(CFG[\"TRAIN_IMG_DIR\"], file_id)\n","            img = cv2.imread(filename)\n","            if img is None:\n","                img = np.zeros((224, 224, 3))\n","                img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n","                img = torch.tensor(img, dtype=torch.float32)\n","                print(filename)\n","            else:\n","                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","                # player highlight mask\n","                player1 = target_info.nfl_player_id_1\n","                player2 = target_info.nfl_player_id_2\n","                p1_helmet = np.array([target_info.E_left_1, target_info.E_width_1,\n","                                    target_info.E_top_1, target_info.E_height_1]).astype(np.int)#[left, width, top, height]\n","                p2_helmet = np.array([target_info.E_left_2, target_info.E_width_2,\n","                                    target_info.E_top_2, target_info.E_height_2]).astype(np.int)\n","                mask1 = get_playermasked_img(img, p1_helmet)\n","                mask2 = get_playermasked_img(img, p2_helmet)\n","                mask = np.clip(mask1 + mask2, 0, 1).astype(np.float32)\n","                img = (mask*img).astype(np.float32)\n","                # crop players area\n","                crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","                img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","                img = cv2.resize(img, dsize=CFG[\"img_size\"])\n","                img = (img / 255.).astype(np.float32) # convert to 0-1\n","                if self.transform is not None:\n","                    img = self.transform(image=img)[\"image\"]\n","                else:\n","                    img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            if input_img is None:\n","                input_img = img\n","            else:\n","                input_img = np.concatenate([input_img, img], axis=0)\n","        target = torch.tensor(target, dtype=torch.float32)\n","        \n","        return input_img, target"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# train_dataset = NFLDataset(target_df, transform=train_transform)\n","# show_img_num = 4\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","\n","# for batch_idx, (images, targets) in enumerate(train_loader):\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()\n","#         img = np.transpose(img, (1, 2, 0)).astype(np.float)\n","#         print(img.shape)\n","#         fig = plt.figure(figsize=(12, 25))\n","#         for frame in range(CFG[\"inp_channels\"]//3):\n","#             frame_img = img[:,:, frame*3:(frame+1)*3]*255\n","#             fig.add_subplot(1, CFG[\"inp_channels\"]//3, frame+1)\n","#             plt.imshow(frame_img)\n","#         plt.title(targets[idx].numpy())\n","#         plt.show()\n","#     break\n","# del train_loader, train_dataset\n","\n","# positive_df = target_df[target_df[\"contact\"]==1]\n","# train_dataset = NFLDataset(positive_df, transform=train_transform)\n","# show_img_num = 4\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","\n","\n","# for batch_idx, (images, targets) in enumerate(train_loader):\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()\n","#         img = np.transpose(img, (1, 2, 0)).astype(np.float)\n","#         print(img.shape)\n","#         fig = plt.figure(figsize=(12, 25))\n","#         for frame in range(CFG[\"inp_channels\"]//3):\n","#             frame_img = img[:,:, frame*3:(frame+1)*3]*255\n","#             fig.add_subplot(1, CFG[\"inp_channels\"]//3, frame+1)\n","#             plt.imshow(frame_img)\n","#         plt.title(targets[idx].numpy())\n","#         plt.show()\n","#     break\n","# del train_loader, train_dataset\n","\n","# raise Exception()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"out_features\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n","    \n","    def forward(self, image):\n","        output = self.model(image)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)                \n","        preds = model(images)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        with torch.no_grad():\n","            preds = model(images)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    \n","    # set model & learning fn\n","    model = NFLNet()\n","    model = model.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","    oof_df = pd.DataFrame()\n","\n","    fold = 0\n","    print(f'fold {fold} training start.')        \n","    # separate train/valid data \n","    train_df = target_df[target_df[\"game_play\"].isin(train_game_plays)]\n","    valid_df = target_df[target_df[\"game_play\"].isin(valid_game_plays)]\n","    # train_dataset = NFLDataset(train_df)\n","    # valid_dataset = NFLDataset(valid_df)\n","    train_dataset = NFLDataset(train_df, train_transform)\n","    valid_dataset = NFLDataset(valid_df, valid_transform)\n","    train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = CFG[\"shuffle\"],\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","    valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = CFG[\"shuffle\"],\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","    # training\n","    best_score = -np.inf\n","    start_time = end = time.time()\n","    for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","        print(f'\\t === epoch: {epoch}: training ===')\n","        train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","        valid_targets, valid_preds, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","        valid_score = -np.inf\n","        valid_threshold = 0\n","        tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","        for idx in range(1, 10, 1):\n","            thr = idx*0.1\n","            valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","            valid_binary_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","            score_tmp = matthews_corrcoef(valid_targets, valid_binary_preds)\n","            cm = confusion_matrix(valid_targets, valid_binary_preds)\n","            tn, fp, fn, tp = cm.flatten()\n","            if score_tmp > valid_score:\n","                valid_score = score_tmp \n","                valid_threshold = thr\n","                tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","        elapsed = time.time() - start_time\n","        print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","        scheduler.step()\n","        # validationスコアがbestを更新したらモデルを保存する\n","        if valid_score > best_score:\n","            best_score = valid_score\n","            model_name = CFG[\"model_name\"]\n","            torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/{model_name}_fold{fold}.pth')\n","            print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","            contact_id = valid_df[\"contact_id\"].values\n","            _oof_df = pd.DataFrame({\n","                \"contact_id\" : contact_id,\n","                \"pred\" : valid_preds,\n","                \"contact\" : valid_targets,\n","                \"fold\" : fold,\n","            })\n","        logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best)\n","\n","    del train_loader, train_dataset, valid_loader, valid_dataset\n","    oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","    del _oof_df\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fold 0 training start.\n","\t === epoch: 1: training ===\n","\t Epoch: [1][0/248] Elapsed 0m 4s (remain 18m 34s) Loss: 3.5774(3.5774) \n","\t Epoch: [1][100/248] Elapsed 7m 19s (remain 10m 39s) Loss: 0.1009(0.6464) \n","\t Epoch: [1][200/248] Elapsed 14m 39s (remain 3m 25s) Loss: 0.3943(0.4919) \n","\t Epoch: [1][247/248] Elapsed 18m 10s (remain 0m 0s) Loss: 0.0044(0.4529) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 7m 59s) Loss: 7.7038(7.7038) \n","\t EVAL: [100/119] Elapsed 7m 47s (remain 1m 23s) Loss: 3.0005(9.7695) \n","\t EVAL: [118/119] Elapsed 9m 6s (remain 0m 0s) Loss: 44.9015(9.8465) \n","\t epoch:1, avg train loss:0.4529, avg valid loss:9.8465, score:0.0236(th=0.1) ::: time:1636.76s\n","\t Epoch 1 - Save Best Score: 0.0236. Model is saved.\n","\t === epoch: 2: training ===\n","\t Epoch: [2][0/248] Elapsed 0m 4s (remain 19m 18s) Loss: 0.2666(0.2666) \n","\t Epoch: [2][100/248] Elapsed 7m 35s (remain 11m 3s) Loss: 0.1971(0.2443) \n","\t Epoch: [2][200/248] Elapsed 15m 5s (remain 3m 31s) Loss: 0.0819(0.2499) \n","\t Epoch: [2][247/248] Elapsed 18m 28s (remain 0m 0s) Loss: 0.0004(0.2560) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 8m 11s) Loss: 2.9057(2.9057) \n","\t EVAL: [100/119] Elapsed 7m 41s (remain 1m 22s) Loss: 12.8868(15.2292) \n","\t EVAL: [118/119] Elapsed 9m 4s (remain 0m 0s) Loss: 0.0483(15.0628) \n","\t epoch:2, avg train loss:0.2560, avg valid loss:15.0628, score:0.1259(th=0.1) ::: time:3290.11s\n","\t Epoch 2 - Save Best Score: 0.1259. Model is saved.\n","\t === epoch: 3: training ===\n","\t Epoch: [3][0/248] Elapsed 0m 4s (remain 18m 39s) Loss: 0.0760(0.0760) \n","\t Epoch: [3][100/248] Elapsed 7m 32s (remain 10m 58s) Loss: 0.1016(0.1916) \n","\t Epoch: [3][200/248] Elapsed 14m 52s (remain 3m 28s) Loss: 0.2641(0.2089) \n","\t Epoch: [3][247/248] Elapsed 18m 20s (remain 0m 0s) Loss: 0.0000(0.2056) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 8m 5s) Loss: 9.0936(9.0936) \n","\t EVAL: [100/119] Elapsed 7m 40s (remain 1m 22s) Loss: 0.0743(7.3208) \n","\t EVAL: [118/119] Elapsed 9m 3s (remain 0m 0s) Loss: 0.0324(6.9802) \n","\t epoch:3, avg train loss:0.2056, avg valid loss:6.9802, score:0.1867(th=0.1) ::: time:4934.93s\n","\t Epoch 3 - Save Best Score: 0.1867. Model is saved.\n","\t === epoch: 4: training ===\n","\t Epoch: [4][0/248] Elapsed 0m 4s (remain 19m 43s) Loss: 0.1280(0.1280) \n","\t Epoch: [4][100/248] Elapsed 7m 28s (remain 10m 53s) Loss: 0.3558(0.1729) \n","\t Epoch: [4][200/248] Elapsed 14m 53s (remain 3m 28s) Loss: 0.0486(0.1833) \n","\t Epoch: [4][247/248] Elapsed 18m 17s (remain 0m 0s) Loss: 0.0000(0.1784) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 9m 47s) Loss: 7.4126(7.4126) \n","\t EVAL: [100/119] Elapsed 7m 46s (remain 1m 23s) Loss: 2.4855(8.4258) \n","\t EVAL: [118/119] Elapsed 9m 5s (remain 0m 0s) Loss: 19.8740(8.3815) \n","\t epoch:4, avg train loss:0.1784, avg valid loss:8.3815, score:0.2121(th=0.1) ::: time:6578.01s\n","\t Epoch 4 - Save Best Score: 0.2121. Model is saved.\n","\t === epoch: 5: training ===\n","\t Epoch: [5][0/248] Elapsed 0m 4s (remain 18m 5s) Loss: 0.1237(0.1237) \n","\t Epoch: [5][100/248] Elapsed 7m 30s (remain 10m 54s) Loss: 0.0845(0.1639) \n","\t Epoch: [5][200/248] Elapsed 14m 59s (remain 3m 30s) Loss: 0.0948(0.1739) \n","\t Epoch: [5][247/248] Elapsed 18m 19s (remain 0m 0s) Loss: 0.0001(0.1664) \n","\t EVAL: [0/119] Elapsed 0m 3s (remain 7m 48s) Loss: 0.7526(0.7526) \n","\t EVAL: [100/119] Elapsed 7m 44s (remain 1m 22s) Loss: 16.0562(11.7827) \n","\t EVAL: [118/119] Elapsed 9m 5s (remain 0m 0s) Loss: 0.0140(11.6342) \n","\t epoch:5, avg train loss:0.1664, avg valid loss:11.6342, score:0.2116(th=0.1) ::: time:8223.11s\n","\t === epoch: 6: training ===\n","\t Epoch: [6][0/248] Elapsed 0m 4s (remain 18m 56s) Loss: 0.1677(0.1677) \n","\t Epoch: [6][100/248] Elapsed 7m 28s (remain 10m 53s) Loss: 0.1234(0.1492) \n","\t Epoch: [6][200/248] Elapsed 14m 52s (remain 3m 28s) Loss: 0.0785(0.1473) \n","\t Epoch: [6][247/248] Elapsed 18m 23s (remain 0m 0s) Loss: 0.0005(0.1436) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 9m 26s) Loss: 7.5794(7.5794) \n","\t EVAL: [100/119] Elapsed 7m 46s (remain 1m 23s) Loss: 0.2271(4.7171) \n","\t EVAL: [118/119] Elapsed 9m 3s (remain 0m 0s) Loss: 2.2833(4.8540) \n","\t epoch:6, avg train loss:0.1436, avg valid loss:4.8540, score:0.2227(th=0.1) ::: time:9870.12s\n","\t Epoch 6 - Save Best Score: 0.2227. Model is saved.\n","\t === epoch: 7: training ===\n","\t Epoch: [7][0/248] Elapsed 0m 4s (remain 20m 10s) Loss: 0.1521(0.1521) \n","\t Epoch: [7][100/248] Elapsed 7m 33s (remain 11m 0s) Loss: 0.1210(0.1360) \n","\t Epoch: [7][200/248] Elapsed 15m 5s (remain 3m 31s) Loss: 0.3286(0.1310) \n","\t Epoch: [7][247/248] Elapsed 18m 29s (remain 0m 0s) Loss: 0.0001(0.1331) \n","\t EVAL: [0/119] Elapsed 0m 5s (remain 10m 18s) Loss: 10.4020(10.4020) \n","\t EVAL: [100/119] Elapsed 7m 52s (remain 1m 24s) Loss: 5.2561(6.5248) \n","\t EVAL: [118/119] Elapsed 9m 14s (remain 0m 0s) Loss: 0.0041(6.7925) \n","\t epoch:7, avg train loss:0.1331, avg valid loss:6.7925, score:0.1169(th=0.1) ::: time:11535.14s\n","\t === epoch: 8: training ===\n","\t Epoch: [8][0/248] Elapsed 0m 4s (remain 19m 50s) Loss: 0.4167(0.4167) \n","\t Epoch: [8][100/248] Elapsed 7m 28s (remain 10m 53s) Loss: 0.1695(0.1230) \n","\t Epoch: [8][200/248] Elapsed 14m 54s (remain 3m 29s) Loss: 0.1149(0.1249) \n","\t Epoch: [8][247/248] Elapsed 18m 24s (remain 0m 0s) Loss: 0.0003(0.1225) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 8m 39s) Loss: 0.5111(0.5111) \n","\t EVAL: [100/119] Elapsed 7m 44s (remain 1m 22s) Loss: 6.9164(2.8120) \n","\t EVAL: [118/119] Elapsed 9m 7s (remain 0m 0s) Loss: 0.2931(2.8200) \n","\t epoch:8, avg train loss:0.1225, avg valid loss:2.8200, score:0.2157(th=0.1) ::: time:13186.88s\n","\t === epoch: 9: training ===\n","\t Epoch: [9][0/248] Elapsed 0m 5s (remain 22m 30s) Loss: 0.0879(0.0879) \n","\t Epoch: [9][100/248] Elapsed 7m 32s (remain 10m 58s) Loss: 0.0845(0.1446) \n","\t Epoch: [9][200/248] Elapsed 15m 2s (remain 3m 31s) Loss: 0.0996(0.1227) \n","\t Epoch: [9][247/248] Elapsed 18m 26s (remain 0m 0s) Loss: 0.0000(0.1236) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 7m 52s) Loss: 0.9043(0.9043) \n","\t EVAL: [100/119] Elapsed 7m 55s (remain 1m 24s) Loss: 5.3407(4.8949) \n","\t EVAL: [118/119] Elapsed 9m 16s (remain 0m 0s) Loss: 0.0786(5.7818) \n","\t epoch:9, avg train loss:0.1236, avg valid loss:5.7818, score:0.1626(th=0.1) ::: time:14849.98s\n","\t === epoch: 10: training ===\n","\t Epoch: [10][0/248] Elapsed 0m 4s (remain 17m 31s) Loss: 0.0222(0.0222) \n","\t Epoch: [10][100/248] Elapsed 7m 31s (remain 10m 56s) Loss: 0.0572(0.1085) \n","\t Epoch: [10][200/248] Elapsed 14m 59s (remain 3m 30s) Loss: 0.2340(0.1190) \n","\t Epoch: [10][247/248] Elapsed 18m 25s (remain 0m 0s) Loss: 0.0000(0.1233) \n","\t EVAL: [0/119] Elapsed 0m 4s (remain 8m 36s) Loss: 0.4238(0.4238) \n","\t EVAL: [100/119] Elapsed 7m 43s (remain 1m 22s) Loss: 1.2203(4.8689) \n","\t EVAL: [118/119] Elapsed 9m 6s (remain 0m 0s) Loss: 11.8765(5.0296) \n","\t epoch:10, avg train loss:0.1233, avg valid loss:5.0296, score:0.1506(th=0.1) ::: time:16502.71s\n","score = 0.3279946168246537, thr=0.1\n","tn=3843709, fp=259, fn=237, tp=121\n","score = 0.15358717930861462, thr=0.5\n","tn=3843843, fp=125, fn=321, tp=37\n","score = 0.06369629392181213, thr=0.9\n","tn=3843881, fp=87, fn=346, tp=12\n"]}],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)\n","        target_long_df = pd.read_csv(\"/workspace/input/long_distance_3_target.csv\")\n","        score_targetlong_concat(oof_df, target_long_df)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>pred</th>\n","      <th>contact</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58173_003606_0_46183_52475</td>\n","      <td>1.000000e+00</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58173_003606_0_41475_47826</td>\n","      <td>6.958675e-04</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58173_003606_0_41475_46108</td>\n","      <td>5.951001e-08</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58173_003606_0_43330_52475</td>\n","      <td>2.926890e-11</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58173_003606_0_43330_46151</td>\n","      <td>4.977981e-02</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1889</th>\n","      <td>58173_003606_129_38642_43330</td>\n","      <td>1.035543e-01</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1890</th>\n","      <td>58173_003606_129_43345_47864</td>\n","      <td>5.032648e-06</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1891</th>\n","      <td>58173_003606_129_43345_46108</td>\n","      <td>9.968136e-01</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1892</th>\n","      <td>58173_003606_129_46108_52475</td>\n","      <td>5.532452e-02</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1893</th>\n","      <td>58173_003606_129_46108_47864</td>\n","      <td>1.802101e-02</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1894 rows × 4 columns</p>\n","</div>"],"text/plain":["                        contact_id          pred  contact  fold\n","0       58173_003606_0_46183_52475  1.000000e+00        0     0\n","1       58173_003606_0_41475_47826  6.958675e-04        0     0\n","2       58173_003606_0_41475_46108  5.951001e-08        0     0\n","3       58173_003606_0_43330_52475  2.926890e-11        0     0\n","4       58173_003606_0_43330_46151  4.977981e-02        1     0\n","...                            ...           ...      ...   ...\n","1889  58173_003606_129_38642_43330  1.035543e-01        0     0\n","1890  58173_003606_129_43345_47864  5.032648e-06        0     0\n","1891  58173_003606_129_43345_46108  9.968136e-01        0     0\n","1892  58173_003606_129_46108_52475  5.532452e-02        1     0\n","1893  58173_003606_129_46108_47864  1.802101e-02        1     0\n","\n","[1894 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    pass\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["<AxesSubplot:>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["oof_df[\"pred\"].hist(bins=100)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
