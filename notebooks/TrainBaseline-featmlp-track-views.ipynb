{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline\n","- create target_df (distance in tracking_df is lower than threshold=3)\n","https://www.kaggle.com/code/stgkrtua/nfl-creatatraindataset-targetdf\n","- create dataset save frames in target_df\n","https://www.kaggle.com/code/stgkrtua/nfl-createdataset-saveframes\n","- check saved images\n","https://www.kaggle.com/code/stgkrtua/nfl-checkdataset-plotsavedimage"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-12T13:13:40.452326Z","iopub.status.busy":"2023-01-12T13:13:40.451849Z","iopub.status.idle":"2023-01-12T13:13:45.308224Z","shell.execute_reply":"2023-01-12T13:13:45.30694Z","shell.execute_reply.started":"2023-01-12T13:13:40.452239Z"},"trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix\n","\n","import mlflow\n","import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:16:51.73369Z","iopub.status.busy":"2023-01-12T13:16:51.733164Z","iopub.status.idle":"2023-01-12T13:16:51.751338Z","shell.execute_reply":"2023-01-12T13:16:51.750203Z","shell.execute_reply.started":"2023-01-12T13:16:51.733656Z"},"trusted":true},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : True,\n","        # model config\n","        \"model_name\" : \"swin_s3_tiny_224\",\n","        \"out_features\" : 20,\n","        \"inp_channels\": 3*2,\n","        \"pretrained\" : True,\n","        \"features\" : ['x_position_1', 'y_position_1', 'x_position_2', 'y_position_2', \n","                      'speed_1', 'distance_1', 'direction_1', 'orientation_1','acceleration_1', 'sa_1', \n","                      'speed_2', 'distance_2', 'direction_2', 'orientation_2', 'acceleration_2', 'sa_2',\n","                      'players_dis', 'is_ground'],\n","        \"track_features_x_1\" : ['x_position_shift-6_1','x_position_shift-5_1', 'x_position_shift-4_1',\n","                                'x_position_shift-3_1','x_position_shift-2_1', 'x_position_shift-1_1', \n","                                'x_position_shift0_1','x_position_shift1_1', 'x_position_shift2_1', \n","                                'x_position_shift3_1','x_position_shift4_1', 'x_position_shift5_1'],    \n","        \"track_features_y_1\" : ['y_position_shift-6_1','y_position_shift-5_1', 'y_position_shift-4_1',\n","                                'y_position_shift-3_1','y_position_shift-2_1', 'y_position_shift-1_1',\n","                                'y_position_shift0_1','y_position_shift1_1', 'y_position_shift2_1',\n","                                'y_position_shift3_1','y_position_shift4_1', 'y_position_shift5_1'],\n","        \"track_features_x_2\" : ['x_position_shift-6_2','x_position_shift-5_2', 'x_position_shift-4_2',\n","                                'x_position_shift-3_2','x_position_shift-2_2', 'x_position_shift-1_2',\n","                                'x_position_shift0_2','x_position_shift1_2', 'x_position_shift2_2',\n","                                'x_position_shift3_2','x_position_shift4_2', 'x_position_shift5_2'],\n","        \"track_features_y_2\" : ['y_position_shift-6_2','y_position_shift-5_2', 'y_position_shift-4_2',\n","                                'y_position_shift-3_2','y_position_shift-2_2', 'y_position_shift-1_2',\n","                                'y_position_shift0_2','y_position_shift1_2', 'y_position_shift2_2',\n","                                'y_position_shift3_2','y_position_shift4_2', 'y_position_shift5_2'],\n","        # learning config\n","        \"n_epoch\" : 10,\n","        \"lr\" : 1e-4,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 1000,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"img_size\" : (224, 224),\n","        \"batch_size\" : 32,\n","        \"num_workers\" : 8,\n","        \"masksize_helmet_ratio\" : 4, # helmetサイズにこの係数をかけたサイズだけ色を残して後は黒塗りする\n","        \"TRAIN_VIDEO_NUM\" : 100,\n","        \"VALID_VIDEO_NUM\" : 10,\n","        \"sample_num\" : -1, \n","\n","        \"EXP_CATEGORY\" : \"make_baseline\",\n","        \"EXP_NAME\" : \"baseline021fmlp1d_views\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_CATEGORY\"] = \"DEBUG\"\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 2\n","    CFG[\"sample_num\"] = 1000\n","    CFG[\"batch_size\"] = 32\n","\n","if CFG[\"kaggle\"]:\n","    CFG[\"INPUT_DIR\"] = \"/kaggle/input/\"\n","    CFG[\"OUTPUT_DIR\"] = \"/kaggle/working/\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-player-contact-detection\", \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift\", \"saved_frame_target.csv\")\n","    CFG[\"TRAIN_E_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift\", \"train_images\")\n","    CFG[\"TRAIN_S_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"nfl-createdataset-saveframes-shift-sview\", \"train_images\")\n","    CFG[\"MODEL_DIR\"] = CFG[\"OUTPUT_DIR\"]\n","else:\n","    CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","    CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","    CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","    CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","    CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","    CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","    CFG[\"TARGET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"target_fillna0_shift_2.csv\")\n","    CFG[\"TRAIN_E_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_frames\")\n","    CFG[\"TRAIN_S_IMG_DIR\"] = CFG[\"TRAIN_E_IMG_DIR\"]\n","    CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:16:53.971823Z","iopub.status.busy":"2023-01-12T13:16:53.97147Z","iopub.status.idle":"2023-01-12T13:17:04.295971Z","shell.execute_reply":"2023-01-12T13:17:04.294952Z","shell.execute_reply.started":"2023-01-12T13:16:53.971794Z"},"trusted":true},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"])\n","\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{"_kg_hide-input":true},"source":["# Utils"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:37.399379Z","iopub.status.busy":"2023-01-12T13:17:37.398389Z","iopub.status.idle":"2023-01-12T13:17:37.410925Z","shell.execute_reply":"2023-01-12T13:17:37.409743Z","shell.execute_reply.started":"2023-01-12T13:17:37.399324Z"},"trusted":true},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best):\n","    if CFG[\"kaggle\"]:\n","        wandb.log({\"loss avg\":{f\"train/fold{fold}\": train_loss_avg,\n","                                f\"valid/fold{fold}\": valid_loss_avg}}, step=epoch)\n","        wandb.log({\"Metircs\" : {f\"score/fold{fold}\":score,\n","                                f\"score threshold/fold{fold}\":threshold,\n","                                f\"tn/fold{fold}\":tn_best,\n","                                f\"fp/fold{fold}\":fp_best,\n","                                f\"fn/fold{fold}\":fn_best,\n","                                f\"tp/fold{fold}\":tp_best,}}, step=epoch)\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:38.274786Z","iopub.status.busy":"2023-01-12T13:17:38.274058Z","iopub.status.idle":"2023-01-12T13:17:38.348063Z","shell.execute_reply":"2023-01-12T13:17:38.347103Z","shell.execute_reply.started":"2023-01-12T13:17:38.27475Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:39.290371Z","iopub.status.busy":"2023-01-12T13:17:39.289836Z","iopub.status.idle":"2023-01-12T13:17:39.302094Z","shell.execute_reply":"2023-01-12T13:17:39.300969Z","shell.execute_reply.started":"2023-01-12T13:17:39.290338Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{"_kg_hide-input":true},"source":["## Dataset Utils"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:40.310155Z","iopub.status.busy":"2023-01-12T13:17:40.309743Z","iopub.status.idle":"2023-01-12T13:17:40.325929Z","shell.execute_reply":"2023-01-12T13:17:40.324715Z","shell.execute_reply.started":"2023-01-12T13:17:40.310106Z"},"trusted":true},"outputs":[],"source":["def set_inimg_window(crop_pos, mask_size, img_size=(720, 1280)):#crop_pos = [left, top, right, bot]\n","    if mask_size[1] >= img_size[0]:\n","        top, bot = 0, img_size[1]\n","    else:\n","        top=(crop_pos[1] + crop_pos[3])//2 - mask_size[1]//2\n","        bot=(crop_pos[1] + crop_pos[3])//2 + mask_size[1]//2\n","        if top < 0:\n","            bot = bot - top\n","            top = 0\n","        elif bot > img_size[0]:\n","            top = top - (bot-img_size[0])\n","            bot = img_size[0]\n","\n","    if mask_size[0] >= img_size[1]:\n","        left, right = 0, img_size[1]\n","    else:\n","        left = (crop_pos[0] + crop_pos[2])//2 - mask_size[0]//2\n","        right = (crop_pos[0] + crop_pos[2])//2 + mask_size[0]//2\n","        if left < 0:\n","            right = right - left\n","            left = 0\n","        elif right > img_size[1]:\n","            left = left - (right - img_size[1])\n","            right = img_size[1]\n","    crop_area = np.array([left, top, right, bot]).astype(np.int)\n","    return crop_area"]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:40.753614Z","iopub.status.busy":"2023-01-12T13:17:40.753226Z","iopub.status.idle":"2023-01-12T13:17:40.770701Z","shell.execute_reply":"2023-01-12T13:17:40.769469Z","shell.execute_reply.started":"2023-01-12T13:17:40.753571Z"},"trusted":true},"outputs":[],"source":["def get_crop_area(p1_helmet, p2_helmet, input_size=(720, 1280)):#helmet[left, width, top, height]\n","    if (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]==0 and p2_helmet[3]==0):\n","        crop_area = [0, 0, input_size[1], input_size[0]]\n","        # print(\"bose player's helmet is not detected.\")\n","        return crop_area\n","    elif (p2_helmet[1]==0 and p2_helmet[3]==0) and (p1_helmet[1] != 0 and p1_helmet[3]!=0):\n","        # print(\"p1 detected.\")\n","        crop_x_center, crop_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        helmet_base_size = (p1_helmet[1] + p1_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    elif (p1_helmet[1]==0 and p1_helmet[3]==0) and (p2_helmet[1]!=0 and p2_helmet[3]!=0):\n","        # print(\"p2 detected.\")\n","        crop_x_center, crop_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        helmet_base_size = (p2_helmet[1] + p2_helmet[3])*0.5*CFG[\"masksize_helmet_ratio\"]*4\n","        output_size = [helmet_base_size, helmet_base_size]\n","    else:\n","    #     print(\"p1 and p2 detected.\")\n","        p1_x_center, p1_y_center = p1_helmet[0] + (p1_helmet[1])//2, p1_helmet[2] + (p1_helmet[3])//2\n","        p2_x_center, p2_y_center = p2_helmet[0] + (p2_helmet[1])//2, p2_helmet[2] + (p2_helmet[3])//2\n","        crop_x_center, crop_y_center = (p1_x_center + p2_x_center)//2, (p1_y_center + p2_y_center)//2\n","        helmet_base_size = (abs(p1_x_center - p2_x_center) + abs(p1_y_center - p2_y_center))*0.5 \\\n","                            + ((p1_helmet[1] + p2_helmet[1])*0.5 + (p1_helmet[3] + p2_helmet[3])*0.5)*0.5*CFG[\"masksize_helmet_ratio\"]*2\n","        output_size = [helmet_base_size, helmet_base_size]\n","    \n","    # print(\"crop center\", crop_x_center, crop_y_center)\n","    crop_left = crop_x_center - output_size[1]//2\n","    crop_top = crop_y_center - output_size[0]//2\n","    crop_right = crop_x_center + output_size[1]//2\n","    crop_bot = crop_y_center + output_size[0]//2\n","    crop_area = [crop_left, crop_top, crop_right, crop_bot]\n","    crop_area = set_inimg_window(crop_area, output_size)\n","    return crop_area"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-12T13:17:41.268595Z","iopub.status.busy":"2023-01-12T13:17:41.268191Z","iopub.status.idle":"2023-01-12T13:17:41.280556Z","shell.execute_reply":"2023-01-12T13:17:41.27921Z","shell.execute_reply.started":"2023-01-12T13:17:41.268558Z"},"trusted":true},"outputs":[],"source":["def get_playermasked_img(img, helmet_pos, img_size=(720, 1280, 3)):#helmet pos = [left, width, top, height]\n","    if helmet_pos[1] == 0 and helmet_pos[3] == 0:\n","        mask = np.ones_like(img)\n","        return mask\n","    mask_size=(helmet_pos[1]+helmet_pos[3])*0.5*CFG[\"masksize_helmet_ratio\"]# helmetの大きさによってplayerの範囲も変更\n","    helmet_area = [helmet_pos[0], helmet_pos[2], helmet_pos[0]+helmet_pos[1], helmet_pos[2]+helmet_pos[3]]#[left, top, right, bot]\n","    player_area = set_inimg_window(helmet_area, (mask_size,mask_size))\n","    mask = np.zeros(img_size, dtype=np.float)\n","    cv2.rectangle(mask, [player_area[0], player_area[1]], [player_area[2], player_area[3]], (255, 255, 255), -1)\n","    mask = np.clip(mask, 0, 1).astype(np.float)\n","    return mask"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:17:43.406106Z","iopub.status.busy":"2023-01-12T13:17:43.405313Z","iopub.status.idle":"2023-01-12T13:17:48.705344Z","shell.execute_reply":"2023-01-12T13:17:48.704456Z","shell.execute_reply.started":"2023-01-12T13:17:43.406066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1000\n"]},{"data":{"text/plain":["0    899\n","1    101\n","Name: contact, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["target_df = pd.read_csv(CFG[\"TARGET_CSV\"])\n","# target_game_plays = target_df[\"game_play\"].unique()[:50]\n","train_game_plays = target_df[\"game_play\"].unique()[:CFG[\"TRAIN_VIDEO_NUM\"]]\n","valid_game_plays = target_df[\"game_play\"].unique()[-CFG[\"VALID_VIDEO_NUM\"]:]\n","target_game_plays = list(set(train_game_plays) | set(valid_game_plays))\n","CFG[\"target_game_plays\"] = list(target_game_plays)\n","target_df = target_df[target_df[\"game_play\"].isin(target_game_plays)]\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"])\n","\n","target_df[\"is_ground\"] = (target_df[\"nfl_player_id_2\"] == \"G\").astype(np.int)\n","print(len(target_df))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:17:50.672877Z","iopub.status.busy":"2023-01-12T13:17:50.672495Z","iopub.status.idle":"2023-01-12T13:17:50.696833Z","shell.execute_reply":"2023-01-12T13:17:50.695655Z","shell.execute_reply.started":"2023-01-12T13:17:50.672844Z"},"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df, transform=None):\n","        self.target_df = target_df\n","        self.features = target_df[CFG[\"features\"]].values\n","        self.track_features_x_1 = target_df[CFG[\"track_features_x_1\"]].values\n","        self.track_features_y_1 = target_df[CFG[\"track_features_y_1\"]].values\n","        self.track_features_x_2 = target_df[CFG[\"track_features_x_2\"]].values\n","        self.track_features_y_2 = target_df[CFG[\"track_features_y_2\"]].values\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        features = self.features[idx]\n","        track_x_1 = self.track_features_x_1[idx]\n","        track_y_1 = self.track_features_y_1[idx]\n","        track_x_2 = self.track_features_x_2[idx]\n","        track_y_2 = self.track_features_y_2[idx]\n","        track_features = np.concatenate([track_x_1[np.newaxis, :],\n","                                         track_y_1[np.newaxis, :],\n","                                         track_x_2[np.newaxis, :],\n","                                         track_y_2[np.newaxis, :]])\n","\n","        target = target_info.contact\n","        # read frame image\n","        game_play = target_info.game_play\n","        frame = target_info.frame\n","        if CFG[\"kaggle\"]:\n","            file_id = f\"{game_play}_Endzone_{frame:05}.png\"\n","        else:\n","            file_id = f\"{game_play}_Endzone_{frame:04}.jpg\"\n","        filename = os.path.join(CFG[\"TRAIN_E_IMG_DIR\"], file_id)\n","        input_img = None\n","        img = cv2.imread(filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            # player highlight mask\n","            player1 = target_info.nfl_player_id_1\n","            player2 = target_info.nfl_player_id_2\n","            p1_helmet = np.array([target_info.E_left_1, target_info.E_width_1,\n","                                target_info.E_top_1, target_info.E_height_1]).astype(np.int)\n","            p2_helmet = np.array([target_info.E_left_2, target_info.E_width_2,\n","                                target_info.E_top_2, target_info.E_height_2]).astype(np.int)\n","            mask1 = get_playermasked_img(img, p1_helmet)# helmet=[left, width, top, height]\n","            mask2 = get_playermasked_img(img, p2_helmet)\n","            mask = np.clip(mask1 + mask2, 0, 1).astype(np.float)\n","            img = mask*img\n","            # crop players area\n","            crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","\n","            img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","            img = cv2.resize(img, dsize=CFG[\"img_size\"])\n","            img = img / 255. # convert to 0-1\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = img\n","        # sideline_vies\n","        if CFG[\"kaggle\"]:\n","            file_id = f\"{game_play}_Sideline_{frame:05}.png\"\n","        else:\n","            file_id = f\"{game_play}_Sideline_{frame:04}.jpg\"\n","        filename = os.path.join(CFG[\"TRAIN_S_IMG_DIR\"], file_id)\n","        img = cv2.imread(filename)\n","        if img is None:\n","            img = np.zeros((224, 224, 3))\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        else:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            # player highlight mask\n","            player1 = target_info.nfl_player_id_1\n","            player2 = target_info.nfl_player_id_2\n","            p1_helmet = np.array([target_info.S_left_1, target_info.S_width_1,\n","                                target_info.S_top_1, target_info.S_height_1]).astype(np.int)\n","            p2_helmet = np.array([target_info.S_left_2, target_info.S_width_2,\n","                                target_info.S_top_2, target_info.S_height_2]).astype(np.int)\n","            mask1 = get_playermasked_img(img, p1_helmet)# helmet=[left, width, top, height]\n","            mask2 = get_playermasked_img(img, p2_helmet)\n","            mask = np.clip(mask1 + mask2, 0, 1).astype(np.float)\n","            img = mask*img\n","            # crop players area\n","            crop_area = get_crop_area(p1_helmet, p2_helmet)# crop_area=[left, top, right, bot]\n","            img = img[crop_area[1]:crop_area[3], crop_area[0]:crop_area[2], :]\n","            img = cv2.resize(img, dsize=CFG[\"img_size\"])\n","            img = img / 255. # convert to 0-1\n","            img = np.transpose(img, (2, 0, 1)).astype(np.float)\n","            img = torch.tensor(img, dtype=torch.float)\n","        input_img = np.concatenate([input_img, img], axis=0)\n","        target = torch.tensor(target, dtype=torch.float)\n","        features = torch.tensor(features, dtype=torch.float)\n","        track_features = torch.tensor(track_features, dtype=torch.float)\n","        return input_img, features, track_features, target"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:23.295097Z","iopub.status.busy":"2023-01-12T13:19:23.294477Z","iopub.status.idle":"2023-01-12T13:19:34.65224Z","shell.execute_reply":"2023-01-12T13:19:34.651214Z","shell.execute_reply.started":"2023-01-12T13:19:23.29504Z"},"trusted":true},"outputs":[],"source":["# show_img_num = 4\n","\n","# pick_df = target_df[target_df[\"contact\"]==1]\n","# train_dataset = NFLDataset(pick_df)\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","# for batch_idx, (images, features, track_features, targets) in enumerate(train_loader):\n","#     fig = plt.figure(figsize=(12, 25))\n","#     print(images.shape)\n","#     print(\"features shape =\",features.shape)\n","#     print(\"track features shape =\",track_features.shape)\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()\n","#         img = img.transpose((1,2,0))\n","#         img = img[:, :, 0:3]\n","#         fig.add_subplot(1,show_img_num ,idx+1)\n","#         plt.imshow(img)\n","#         plt.title(targets[idx].numpy())\n","#     plt.show()\n","    \n","#     fig = plt.figure(figsize=(12, 25))\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()\n","#         img = img.transpose((1,2,0))\n","#         img = img[:, :, 3:6]\n","#         fig.add_subplot(1,show_img_num ,idx+1)\n","#         plt.imshow(img)\n","#         plt.title(targets[idx].numpy())\n","#     plt.show()\n","#     break\n","# del train_loader, train_dataset\n","\n","# pick_df = target_df[target_df[\"contact\"]!=1]\n","# train_dataset = NFLDataset(pick_df)\n","# train_loader = DataLoader(\n","#     train_dataset,\n","#     batch_size = show_img_num,\n","#     shuffle = True,\n","#     num_workers = CFG[\"num_workers\"],\n","#     pin_memory = True\n","# )\n","# for batch_idx, (images, features, track_features, targets) in enumerate(train_loader):\n","#     fig = plt.figure(figsize=(12, 25))\n","#     for idx in range(show_img_num):\n","#         img = images[idx].numpy()\n","#         img = img.transpose((1,2,0))\n","#         fig.add_subplot(1,show_img_num ,idx+1)\n","#         plt.imshow(img)\n","#         plt.title(targets[idx].numpy())\n","#     plt.show()\n","#     break\n","# del train_loader, train_dataset"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:41.556247Z","iopub.status.busy":"2023-01-12T13:19:41.55582Z","iopub.status.idle":"2023-01-12T13:19:41.572228Z","shell.execute_reply":"2023-01-12T13:19:41.567231Z","shell.execute_reply.started":"2023-01-12T13:19:41.556208Z"},"trusted":true},"outputs":[],"source":["# without meta\n","class NFLNet(nn.Module):\n","    def __init__(\n","        self,\n","        model_name = CFG[\"model_name\"],\n","        out_features = CFG[\"out_features\"],\n","        inp_channels= CFG[\"inp_channels\"],\n","        pretrained = CFG[\"pretrained\"]\n","    ):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes=out_features)\n","        self.mlp = nn.Sequential(\n","                        nn.Linear(len(CFG[\"features\"]), 32),\n","                        nn.LayerNorm(32),\n","                        nn.ReLU(),\n","                        nn.Dropout(0.2),\n","                    )\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(4, 1, 5),\n","                        nn.Linear(len(CFG[\"track_features_y_2\"])-4, 32),\n","                        nn.ReLU(),\n","                    )\n","        self.fc = nn.Linear(out_features+32+32, 1)\n","\n","    def forward(self, image, features, track_features):\n","        output = self.model(image)\n","        features = self.mlp(features)\n","        track_features = self.conv1(track_features)\n","        output = self.fc(torch.cat([output, features, torch.squeeze(track_features)], dim=1))\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:43.624048Z","iopub.status.busy":"2023-01-12T13:19:43.623519Z","iopub.status.idle":"2023-01-12T13:19:43.637172Z","shell.execute_reply":"2023-01-12T13:19:43.635834Z","shell.execute_reply.started":"2023-01-12T13:19:43.624014Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, features, track_features, targets) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)      \n","        features = features.to(device, non_blocking = True).float()\n","        track_features = track_features.to(device, non_blocking = True).float()\n","        preds = model(images, features, track_features)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, features, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:44.63674Z","iopub.status.busy":"2023-01-12T13:19:44.636333Z","iopub.status.idle":"2023-01-12T13:19:44.652475Z","shell.execute_reply":"2023-01-12T13:19:44.651439Z","shell.execute_reply.started":"2023-01-12T13:19:44.636707Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, features, track_features, targets) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        features = features.to(device, non_blocking = True).float()\n","        track_features = track_features.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds = model(images, features, track_features)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, features, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:45.480541Z","iopub.status.busy":"2023-01-12T13:19:45.480175Z","iopub.status.idle":"2023-01-12T13:19:45.49986Z","shell.execute_reply":"2023-01-12T13:19:45.498729Z","shell.execute_reply.started":"2023-01-12T13:19:45.48051Z"},"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    # set model & learning fn\n","    model = NFLNet()\n","    model = model.to(device)\n","    if CFG[\"kaggle\"]:\n","        wandb.watch(model)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","    oof_df = pd.DataFrame()\n","    fold = 0\n","    # separate train/valid data \n","    train_df = target_df[target_df[\"game_play\"].isin(train_game_plays)]\n","    valid_df = target_df[target_df[\"game_play\"].isin(valid_game_plays)]\n","    train_dataset = NFLDataset(train_df)\n","    valid_dataset = NFLDataset(valid_df)\n","    train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","    valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","    # training\n","    best_score = -np.inf\n","    start_time = end = time.time()\n","    for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","        print(f'\\t === epoch: {epoch}: training ===')\n","        train_loss_avg = train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler)\n","        valid_targets, valid_preds, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","        valid_score = -np.inf\n","        valid_threshold = 0\n","        tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","        for idx in range(1, 10, 1):\n","            thr = idx*0.1\n","            valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","            valid_binary_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","            score_tmp = matthews_corrcoef(valid_targets, valid_binary_preds)\n","            cm = confusion_matrix(valid_targets, valid_binary_preds)\n","            tn, fp, fn, tp = cm.flatten()\n","            if score_tmp > valid_score:\n","                valid_score = score_tmp \n","                valid_threshold = thr\n","                tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","        elapsed = time.time() - start_time\n","        print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}, score:{valid_score:.4f}(th={valid_threshold}) ::: time:{elapsed:.2f}s')\n","        scheduler.step()\n","        # validationスコアがbestを更新したらモデルを保存する\n","        if valid_score > best_score:\n","            best_score = valid_score\n","            model_name = CFG[\"model_name\"]\n","            torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/{model_name}_fold{fold}.pth')\n","            print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","            contact_id = valid_df[\"contact_id\"].values\n","            _oof_df = pd.DataFrame({\n","                \"contact_id\" : contact_id,\n","                \"pred\" : valid_preds,\n","                \"contact\" : valid_targets,\n","                \"fold\" : fold,\n","            })\n","        logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best)\n","\n","    del train_loader, train_dataset, valid_loader, valid_dataset\n","    oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","    del _oof_df\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:19:46.439104Z","iopub.status.busy":"2023-01-12T13:19:46.438256Z","iopub.status.idle":"2023-01-12T13:24:20.988127Z","shell.execute_reply":"2023-01-12T13:24:20.987039Z","shell.execute_reply.started":"2023-01-12T13:19:46.439066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\t === epoch: 1: training ===\n","\t Epoch: [1][0/29] Elapsed 0m 6s (remain 3m 4s) Loss: 0.5637(0.5637) \n","\t Epoch: [1][28/29] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1115(0.3060) \n","\t EVAL: [0/3] Elapsed 0m 3s (remain 0m 7s) Loss: 0.4271(0.4271) \n","\t EVAL: [2/3] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0558(0.2845) \n","\t epoch:1, avg train loss:0.3060, avg valid loss:0.2845, score:0.2750(th=0.2) ::: time:25.92s\n","\t Epoch 1 - Save Best Score: 0.2750. Model is saved.\n","\t === epoch: 2: training ===\n","\t Epoch: [2][0/29] Elapsed 0m 5s (remain 2m 39s) Loss: 0.3452(0.3452) \n","\t Epoch: [2][28/29] Elapsed 0m 21s (remain 0m 0s) Loss: 0.3233(0.2604) \n","\t EVAL: [0/3] Elapsed 0m 3s (remain 0m 7s) Loss: 0.2656(0.2656) \n","\t EVAL: [2/3] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0743(0.2870) \n","\t epoch:2, avg train loss:0.2604, avg valid loss:0.2870, score:0.3140(th=0.5) ::: time:51.57s\n","\t Epoch 2 - Save Best Score: 0.3140. Model is saved.\n"]}],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","    wandb.finish()\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-01-12T13:24:26.220003Z","iopub.status.busy":"2023-01-12T13:24:26.21963Z","iopub.status.idle":"2023-01-12T13:24:26.243802Z","shell.execute_reply":"2023-01-12T13:24:26.242868Z","shell.execute_reply.started":"2023-01-12T13:24:26.219971Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contact_id</th>\n","      <th>pred</th>\n","      <th>contact</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58574_002922_5_43384_44886</td>\n","      <td>0.032905</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58575_003081_37_43422_G</td>\n","      <td>0.016368</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58582_003121_37_48220_G</td>\n","      <td>0.023200</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58582_003121_14_41332_G</td>\n","      <td>0.013971</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58581_000040_29_42460_G</td>\n","      <td>0.001359</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>58580_003294_53_43478_G</td>\n","      <td>0.067048</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>58573_000445_10_40171_47801</td>\n","      <td>0.089239</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>58582_003121_36_46284_G</td>\n","      <td>0.216370</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>58580_001136_10_46135_G</td>\n","      <td>0.006421</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>58573_000445_23_46131_47976</td>\n","      <td>0.018747</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>72 rows × 4 columns</p>\n","</div>"],"text/plain":["                     contact_id      pred  contact  fold\n","0    58574_002922_5_43384_44886  0.032905        0     0\n","1       58575_003081_37_43422_G  0.016368        0     0\n","2       58582_003121_37_48220_G  0.023200        0     0\n","3       58582_003121_14_41332_G  0.013971        0     0\n","4       58581_000040_29_42460_G  0.001359        0     0\n","..                          ...       ...      ...   ...\n","67      58580_003294_53_43478_G  0.067048        0     0\n","68  58573_000445_10_40171_47801  0.089239        0     0\n","69      58582_003121_36_46284_G  0.216370        0     0\n","70      58580_001136_10_46135_G  0.006421        0     0\n","71  58573_000445_23_46131_47976  0.018747        0     0\n","\n","[72 rows x 4 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
