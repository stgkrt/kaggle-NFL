{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NFL Baseline\n","- create target_df (distance in tracking_df is lower than threshold=3)\n","https://www.kaggle.com/code/stgkrtua/nfl-creatatraindataset-targetdf\n","- create dataset save frames in target_df\n","https://www.kaggle.com/code/stgkrtua/nfl-createdataset-saveframes\n","- check saved images\n","https://www.kaggle.com/code/stgkrtua/nfl-checkdataset-plotsavedimage"]},{"cell_type":"markdown","metadata":{},"source":["# import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-19T12:15:11.586666Z","iopub.status.busy":"2023-01-19T12:15:11.585912Z","iopub.status.idle":"2023-01-19T12:15:13.779848Z","shell.execute_reply":"2023-01-19T12:15:13.778792Z","shell.execute_reply.started":"2023-01-19T12:15:11.586576Z"},"trusted":true},"outputs":[],"source":["# general\n","import os\n","import gc\n","import pickle\n","import glob\n","import random\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import math\n","\n","import sys\n","sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","\n","# deep learning\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from sklearn.model_selection import GroupKFold\n","\n","# loss metrics\n","from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_auc_score\n","\n","# import cudf\n","import polars as pl\n","\n","import mlflow\n","# import wandb\n","# warningの表示方法の設定\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Set Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.783214Z","iopub.status.busy":"2023-01-19T12:15:13.782224Z","iopub.status.idle":"2023-01-19T12:15:13.801082Z","shell.execute_reply":"2023-01-19T12:15:13.800004Z","shell.execute_reply.started":"2023-01-19T12:15:13.783176Z"},"trusted":true},"outputs":[],"source":["CFG = {\n","        \"kaggle\" : False,\n","        \"DEBUG\" : False,\n","        # model config\n","        \"num_track_features\" : 5,\n","\n","        \"features\" : ['x_position_1', 'y_position_1', 'x_position_2', 'y_position_2', \n","                      'speed_1', 'distance_1', 'direction_1', 'orientation_1','acceleration_1', 'sa_2', \n","                      'speed_2', 'distance_2', 'direction_2', 'orientation_2', 'acceleration_2', 'sa_2',\n","                      'players_dis', #'is_ground'\n","                    #   'speed_diff', 'distance_diff', 'direction_diff', 'orientation_diff','acceleration_diff', 'sa_diff', # diff-feature\n","                    #   'x_move_distance_2', 'y_move_distance_1', 'x_move_distance_2', 'y_move_distance_2',\n","                    #   'x_position_diff_rollsum','y_position_diff_rollsum', \n","                    #   'speed_diff_rollsum','distance_diff_rollsum', 'direction_diff_rollsum','orientation_diff_rollsum', \n","                    #   'acceleration_diff_rollsum', 'sa_diff_rollsum','players_dis_rollsum', \n","                      ],\n","        \"SHIFT_COLS\" : [\"x_position\", \"y_position\", 'speed', 'distance', 'direction', 'orientation', 'acceleration', 'sa',],\n","        \"SHIFT_NUM\" : range(-6,6,1),\n","                \n","        \"xpos_1\" : ['x_position_shift-6_1', 'x_position_shift-5_1', 'x_position_shift-4_1', 'x_position_shift-3_1', 'x_position_shift-2_1', 'x_position_shift-1_1',\n","                 'x_position_shift0_1', 'x_position_shift1_1', 'x_position_shift2_1', 'x_position_shift3_1', 'x_position_shift4_1', 'x_position_shift5_1'],\n","        \"ypos_1\" : ['y_position_shift-6_1', 'y_position_shift-5_1', 'y_position_shift-4_1', 'y_position_shift-3_1', 'y_position_shift-2_1', 'y_position_shift-1_1', \n","                 'y_position_shift0_1', 'y_position_shift1_1', 'y_position_shift2_1', 'y_position_shift3_1', 'y_position_shift4_1', 'y_position_shift5_1'],\n","        \"speed_1\" : ['speed_shift-6_1', 'speed_shift-5_1', 'speed_shift-4_1', 'speed_shift-3_1', 'speed_shift-2_1', 'speed_shift-1_1', \n","                 'speed_shift0_1', 'speed_shift1_1', 'speed_shift2_1', 'speed_shift3_1', 'speed_shift4_1', 'speed_shift5_1'],\n","        \"dire_1\" : ['direction_shift-6_1', 'direction_shift-5_1', 'direction_shift-4_1', 'direction_shift-3_1', 'direction_shift-2_1', 'direction_shift-1_1',\n","                 'direction_shift0_1', 'direction_shift1_1', 'direction_shift2_1', 'direction_shift3_1', 'direction_shift4_1', 'direction_shift5_1'],\n","        \"orie_1\" : ['orientation_shift-6_1', 'orientation_shift-5_1', 'orientation_shift-4_1', 'orientation_shift-3_1', 'orientation_shift-2_1', 'orientation_shift-1_1',\n","                 'orientation_shift0_1', 'orientation_shift1_1', 'orientation_shift2_1', 'orientation_shift3_1', 'orientation_shift4_1', 'orientation_shift5_1'],\n","        \"acc_1\" : ['acceleration_shift-6_1', 'acceleration_shift-5_1', 'acceleration_shift-4_1', 'acceleration_shift-3_1', 'acceleration_shift-2_1', 'acceleration_shift-1_1',\n","                 'acceleration_shift0_1', 'acceleration_shift1_1', 'acceleration_shift2_1', 'acceleration_shift3_1', 'acceleration_shift4_1', 'acceleration_shift5_1'],\n","        \"sa_1\" : ['sa_shift-6_1', 'sa_shift-5_1', 'sa_shift-4_1', 'sa_shift-3_1', 'sa_shift-2_1', 'sa_shift-1_1', \n","                 'sa_shift0_1', 'sa_shift1_1', 'sa_shift2_1', 'sa_shift3_1', 'sa_shift4_1', 'sa_shift5_1'],\n","        \"xpos_2\" : ['x_position_shift-6_2', 'x_position_shift-5_2', 'x_position_shift-4_2', 'x_position_shift-3_2', 'x_position_shift-2_2', 'x_position_shift-1_2',\n","                  'x_position_shift0_2', 'x_position_shift1_2', 'x_position_shift2_2', 'x_position_shift3_2', 'x_position_shift4_2', 'x_position_shift5_2'],\n","        \"ypos_2\" : ['y_position_shift-6_2', 'y_position_shift-5_2', 'y_position_shift-4_2', 'y_position_shift-3_2', 'y_position_shift-2_2', 'y_position_shift-1_2',\n","                 'y_position_shift0_2', 'y_position_shift1_2', 'y_position_shift2_2', 'y_position_shift3_2', 'y_position_shift4_2', 'y_position_shift5_2'],\n","        \"speed_2\" : ['speed_shift-6_2', 'speed_shift-5_2', 'speed_shift-4_2', 'speed_shift-3_2', 'speed_shift-2_2', 'speed_shift-1_2', \n","                 'speed_shift0_2', 'speed_shift1_2', 'speed_shift2_2', 'speed_shift3_2', 'speed_shift4_2', 'speed_shift5_2'],\n","        \"dire_2\" : ['direction_shift-6_2', 'direction_shift-5_2', 'direction_shift-4_2', 'direction_shift-3_2', 'direction_shift-2_2', 'direction_shift-1_2',\n","                 'direction_shift0_2', 'direction_shift1_2', 'direction_shift2_2', 'direction_shift3_2', 'direction_shift4_2', 'direction_shift5_2'],\n","        \"orie_2\" : ['orientation_shift-6_2', 'orientation_shift-5_2', 'orientation_shift-4_2', 'orientation_shift-3_2', 'orientation_shift-2_2', 'orientation_shift-1_2',\n","                 'orientation_shift0_2', 'orientation_shift1_2', 'orientation_shift2_2', 'orientation_shift3_2', 'orientation_shift4_2', 'orientation_shift5_2'],\n","        \"acc_2\" : ['acceleration_shift-6_2', 'acceleration_shift-5_2', 'acceleration_shift-4_2', 'acceleration_shift-3_2', 'acceleration_shift-2_2', 'acceleration_shift-1_2',\n","                 'acceleration_shift0_2', 'acceleration_shift1_2', 'acceleration_shift2_2', 'acceleration_shift3_2', 'acceleration_shift4_2', 'acceleration_shift5_2'],\n","        \"sa_2\" : ['sa_shift-6_2', 'sa_shift-5_2', 'sa_shift-4_2', 'sa_shift-3_2', 'sa_shift-2_2', 'sa_shift-1_2',\n","                 'sa_shift0_2', 'sa_shift1_2', 'sa_shift2_2', 'sa_shift3_2', 'sa_shift4_2', 'sa_shift5_2'],\n","        \"dis\" : ['distance_shift-6_1', 'distance_shift-5_1', 'distance_shift-4_1', 'distance_shift-3_1', 'distance_shift-2_1', 'distance_shift-1_1',\n","                 'distance_shift0_1', 'distance_shift1_1', 'distance_shift2_1', 'distance_shift3_1', 'distance_shift4_1', 'distance_shift5_1'],\n","                \n","                \n","                \n","        # learning config\n","        \"n_epoch\" : 10,\n","        \"n_folds\": 3,\n","        \"train_folds\" : [0,1,2],\n","        \"lr\" : 1e-3,\n","        \"T_max\" : 10,\n","        \"min_lr\" : 1e-8,\n","        \"weight_decay\" : 1e-6,\n","\n","        # etc\n","        \"print_freq\" : 1000,\n","        \"random_seed\" : 21,\n","\n","        # data config    \n","        \"batch_size\" : 256,\n","        \"num_workers\" : 2,\n","        \"sample_num\" : -1,\n","\n","        \"EXP_CATEGORY\" : \"exps_conv1d\",\n","        \"EXP_NAME\" : \"expP001_Trackshift1D\",\n","}\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"EXP_CATEGORY\"] = \"DEBUG\"\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    CFG[\"n_epoch\"] = 2\n","    CFG[\"sample_num\"] = 1000\n","    CFG[\"batch_size\"] = 32\n","    CFG[\"train_folds\"] : [0,1]\n","\n","\n","CFG[\"INPUT_DIR\"] = \"/workspace/input\"\n","CFG[\"OUTPUT_DIR\"] = \"/workspace/output\"\n","CFG[\"TRAIN_HELMET_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_baseline_helmets.csv\")\n","CFG[\"TRAIN_TRACKING_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_player_tracking.csv\")\n","CFG[\"TRAIN_VIDEO_META_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_video_metadata.csv\")\n","CFG[\"TRAIN_LABEL_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"train_labels.csv\")\n","CFG[\"SAVED_CONTACT_CSV\"] = os.path.join(CFG[\"INPUT_DIR\"], \"Saved_contact_frames.csv\")\n","CFG[\"CONTACT_IMG_DIR\"] = os.path.join(CFG[\"INPUT_DIR\"], \"contact_images\")\n","CFG[\"MODEL_DIR\"] = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"] ,\"model\")\n","    \n","if not CFG[\"kaggle\"] and not CFG[\"DEBUG\"]:\n","    os.mkdir(os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"]))\n","    os.mkdir(CFG[\"MODEL_DIR\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:13.802877Z","iopub.status.busy":"2023-01-19T12:15:13.802383Z","iopub.status.idle":"2023-01-19T12:15:24.348525Z","shell.execute_reply":"2023-01-19T12:15:24.34747Z","shell.execute_reply.started":"2023-01-19T12:15:13.802838Z"},"trusted":true},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    WANDB_CONFIG = {'competition': 'NFL', '_wandb_kernel': 'taro'}\n","    # Secrets\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value_0 = user_secrets.get_secret(\"wandb\")\n","\n","    !wandb login $secret_value_0\n","    #! TODO : logger settings\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"])\n","\n","else:\n","    mlflow.set_tracking_uri(\"/workspace/mlruns\")\n","    experiment = mlflow.get_experiment_by_name(CFG[\"EXP_CATEGORY\"])\n","    if experiment is None:  # 当該Experiment存在しないとき、新たに作成\n","        experiment_id = mlflow.create_experiment(name=CFG[\"EXP_CATEGORY\"])\n","    else: # 当該Experiment存在するとき、IDを取得\n","        experiment_id = experiment.experiment_id"]},{"cell_type":"markdown","metadata":{"_kg_hide-input":true},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.352268Z","iopub.status.busy":"2023-01-19T12:15:24.35167Z","iopub.status.idle":"2023-01-19T12:15:24.3647Z","shell.execute_reply":"2023-01-19T12:15:24.363754Z","shell.execute_reply.started":"2023-01-19T12:15:24.352219Z"},"trusted":true},"outputs":[],"source":["def logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, score, threshold, tn_best, fp_best, fn_best, tp_best, auc_score):\n","    if CFG[\"kaggle\"]:\n","        wandb.log({\"loss avg\":{f\"train/fold{fold}\": train_loss_avg,\n","                                f\"valid/fold{fold}\": valid_loss_avg}}, step=epoch)\n","        wandb.log({\"Metircs\" : {f\"score/fold{fold}\":score,\n","                                f\"score threshold/fold{fold}\":threshold,\n","                                f\"tn/fold{fold}\":tn_best,\n","                                f\"fp/fold{fold}\":fp_best,\n","                                f\"fn/fold{fold}\":fn_best,\n","                                f\"tp/fold{fold}\":tp_best,\n","                                f\"auc/fold{fold}\":auc_score,\n","                               }}, step=epoch)\n","    else:\n","        mlflow.log_metric(f\"fold{fold} train loss avg\", train_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} valid loss avg\", valid_loss_avg, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score\", score, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} score threshold\", threshold, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tn\", tn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fp\", fp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} fn\", fn_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} tp\", tp_best, step=epoch)\n","        mlflow.log_metric(f\"fold{fold} auc\", auc_score, step=epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.366999Z","iopub.status.busy":"2023-01-19T12:15:24.366307Z","iopub.status.idle":"2023-01-19T12:15:24.418709Z","shell.execute_reply":"2023-01-19T12:15:24.417791Z","shell.execute_reply.started":"2023-01-19T12:15:24.366946Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-01-19T12:15:24.425285Z","iopub.status.busy":"2023-01-19T12:15:24.423016Z","iopub.status.idle":"2023-01-19T12:15:24.437655Z","shell.execute_reply":"2023-01-19T12:15:24.436601Z","shell.execute_reply.started":"2023-01-19T12:15:24.425246Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def add_feature_cols(df_, FEATURE_COLS,remove_col_list):\n","    additional_cols = list(df_.columns)\n","    additional_cols = [col for col in additional_cols if not col in remove_col_list]\n","    FEATURE_COLS.extend(additional_cols)\n","    return FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## target df func"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def create_trackmerged_ftr(target_df, FEATURE_COLS,\n","                           diff_cols = ['x_position', 'y_position', 'speed', 'distance',\n","                                        'direction', 'orientation', 'acceleration', 'sa']):\n","    target_df = target_df.with_column((np.sqrt(np.square(pl.col(\"x_position_1\")-pl.col(\"x_position_2\")) \\\n","                                              + np.square(pl.col(\"y_position_1\")-pl.col(\"y_position_2\"))) \\\n","                                      ).alias(\"players_dis\"))\n","    target_df = target_df.with_column(pl.col(\"players_dis\").fill_null(0))\n","    \n","    # players distance sum(in shift range time : default(-6~6 frames not step))\n","    players_distance_sum = 0\n","    for idx in range(-6,6,1):\n","        players_distance_sum += np.sqrt((target_df[f\"x_position_shift{idx}_1\"] - target_df[f\"x_position_shift{idx}_2\"])**2 \\\n","                                       + (target_df[f\"y_position_shift{idx}_1\"] - target_df[f\"y_position_shift{idx}_2\"])**2)\n","    target_df = target_df.with_column(pl.Series(\"players_distance_sum\", players_distance_sum))\n","    target_df = target_df.with_column(pl.col(\"players_distance_sum\").fill_null(0))\n","    FEATURE_COLS.append(\"players_distance_sum\")\n","\n","    # players each axis distance sum(in shift range time : default(-6~6 frames not step))\n","    for axis in [\"x\", \"y\"]:\n","        axis_distance_1 = 0\n","        axis_distance_2 = 0\n","        for idx in range(-6, 5, 1):\n","            axis_distance_1 += abs(target_df[f\"{axis}_position_shift{idx}_1\"] - target_df[f\"{axis}_position_shift{idx+1}_1\"])\n","            axis_distance_2 += abs(target_df[f\"{axis}_position_shift{idx}_2\"] - target_df[f\"{axis}_position_shift{idx+1}_2\"])\n","        target_df = target_df.with_column(pl.Series(f\"{axis}_move_distance_1\", axis_distance_1))\n","        target_df = target_df.with_column(pl.col(f\"{axis}_move_distance_1\").fill_null(0))\n","        target_df = target_df.with_column(pl.Series(f\"{axis}_move_distance_2\", axis_distance_2))\n","        target_df = target_df.with_column(pl.col(f\"{axis}_move_distance_2\").fill_null(0))\n","        FEATURE_COLS.extend([f\"{axis}_move_distance_1\", f\"{axis}_move_distance_2\"])\n","\n","    # players difference ftr (in each step)\n","    for col in diff_cols:\n","        colname = f\"{col}_diff\"\n","        target_df = target_df.with_column((abs(pl.col(f\"{col}_1\") - pl.col(f\"{col}_2\"))).alias(colname))\n","        target_df = target_df.with_column(pl.col(colname).fill_null(0))\n","        FEATURE_COLS.append(colname)\n","        \n","    return target_df, FEATURE_COLS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# polars groupby rolling (groupby_dynamics)\n","# https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.groupby_dynamic.html\n","# -------------------------------\n","def create_roll_ftr(target_df, FEATURE_COLS_,\n","                    key_cols = [\"contact_id\", \"game_play\", \"nfl_player_id_1\", \n","                                \"nfl_player_id_2\", \"datetime\", \"step\"]):\n","    roll_df = target_df.select(roll_cols+key_cols)\n","\n","    roll_df = roll_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                 pl.col(\"nfl_player_id_1\"),\n","                                                 pl.col(\"nfl_player_id_2\"),\n","                                                ], sep='_').alias('key'))\n","    # cast datetime\n","    roll_df = roll_df.with_column(pl.col('datetime').str.strptime(pl.Datetime,\n","                                                                          fmt=\"%+\",\n","                                                                          strict=False\n","                                                                         ).alias('datetime'))\n","    # groupby rolling\n","    roll_df = roll_df.groupby_dynamic(\"step\", every=\"1i\", period=\"6i\", by=\"key\", closed=\"both\").agg([pl.col(roll_cols).sum().suffix(\"_rollsum\"), pl.col(\"contact_id\")])\n","    roll_df = roll_df.with_column(pl.col(\"contact_id\").apply(lambda x:x[0]))\n","    roll_df = roll_df.drop([\"key\", \"step\"])\n","    target_df = target_df.join(roll_df, on=\"contact_id\", how=\"left\")\n","    additional_cols = [col+\"_rollsum\" for col in roll_cols]\n","    FEATURE_COLS_.extend(additional_cols)\n","    return target_df, FEATURE_COLS_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def create_helmetmerged_ftr(target_df, FEATURE_COLS_):\n","    # helmet center distance feature\n","    for view in [\"Endzone\", \"Sideline\"]:\n","        for p_id in [\"1\", \"2\"]: \n","            # get helmet center\n","            target_df = target_df.with_column((pl.col(f\"{view[0]}_left_{p_id}\") + (pl.col(f\"{view[0]}_width_{p_id}\")//2)).alias(f\"{view[0]}_Wcenter_{p_id}\"))\n","            target_df = target_df.with_column((pl.col(f\"{view[0]}_top_{p_id}\") + (pl.col(f\"{view[0]}_height_{p_id}\")//2)).alias(f\"{view[0]}_Hcenter_{p_id}\"))\n","        # helmet center distance\n","        target_df = target_df.with_column((np.sqrt(np.square(pl.col(f\"{view[0]}_Wcenter_1\") - pl.col(f\"{view[0]}_Wcenter_2\")) \\\n","                                                  + np.square(pl.col(f\"{view[0]}_Hcenter_1\") - pl.col(f\"{view[0]}_Hcenter_2\")))\n","                                          ).alias(f\"{view[0]}_helmet_dis\"))\n","\n","        # GがNanになるので0にしておく\n","        target_df = target_df.with_column(pl.col(f\"{view[0]}_helmet_dis\").fill_null(0))\n","        FEATURE_COLS_.append(f\"{view[0]}_helmet_dis\")\n","    \n","    # helmet cols fillna(0) after get helmet distance \n","    helmet_cols = ['E_left_1', 'E_width_1', 'E_top_1', 'E_height_1',\n","                   'E_left_2', 'E_width_2', 'E_top_2', 'E_height_2', \n","                   'S_left_1','S_width_1', 'S_top_1', 'S_height_1', \n","                   'S_left_2', 'S_width_2', 'S_top_2', 'S_height_2']\n","    target_df = target_df.with_column(pl.col(helmet_cols).fill_null(0))\n","\n","    return target_df, FEATURE_COLS_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def get_categorical_ftr(target_df, FEATURE_COLS_):\n","    target_df = target_df.with_column((pl.col(\"nfl_player_id_2\")== \"G\").cast(int).alias(\"is_ground\"))\n","    \n","#     target_df[\"nfl_player_id_2\"] = target_df[\"nfl_player_id_2\"].replace(\"G\", \"99999\").astype(np.int64) # when inference this is after cnn pred\n","    target_df = target_df.with_column((1 - ((pl.col(\"E_width_1\")==0) & (pl.col(\"E_width_2\")==0) \\\n","                                          & (pl.col(\"S_width_1\")==0) & (pl.col(\"S_width_2\")==0)).cast(int)).alias(\"is_helmet\"))\n","    target_df = target_df.with_column((1 - ((pl.col(\"E_width_1\")==0) & (pl.col(\"E_width_2\")==0)).cast(int)).alias(\"is_E_helmet\"))\n","    target_df = target_df.with_column((1 - ((pl.col(\"S_width_1\")==0) & (pl.col(\"S_width_2\")==0)).cast(int)).alias(\"is_S_helmet\"))\n","    target_df = target_df.with_column(((pl.col(\"is_E_helmet\")==1) & (pl.col(\"is_S_helmet\")==1)).cast(int).alias(\"both_helmet\"))\n","    # set team \n","    target_df = target_df.with_column(((pl.col(\"team_1\")==\"home\").cast(int)).alias(\"team_1\"))\n","    target_df = target_df.with_column(((pl.col(\"team_2\")==\"home\").cast(int)).alias(\"team_2\"))\n","    \n","    target_df = target_df.fill_null(0)\n","    target_df = target_df.fill_nan(0)\n","    FEATURE_COLS_.extend([\"is_ground\", \"is_helmet\"])\n","    return target_df, FEATURE_COLS_"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## tracking df func"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def get_tracking_shift(tracking_df_, shift_cols=CFG[\"SHIFT_COLS\"], shift_nums=CFG[\"SHIFT_NUM\"]):\n","    # get shift key\n","    #     tracking_df = tracking_df.with_column((pl.col('step')/10*59.94+5*59.94 + 5000).alias('frame_add'))\n","    tracking_df_ = tracking_df_.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                         pl.col(\"nfl_player_id\"),\n","                                                        ], sep='_').alias('shift_key'))\n","    # get shift features\n","    SHIFT_COLS_ = []\n","    for num in shift_nums:\n","        tracking_df_ = tracking_df_.with_columns(\n","                            pl.col(shift_cols).shift(periods=num).over(\"shift_key\").suffix(f\"_shift{num}\"))\n","    for col in shift_cols:\n","        colname = [f\"{col}_shift{idx}\" for idx in shift_nums]\n","        SHIFT_COLS_.extend(colname)\n","                    \n","    return tracking_df_, SHIFT_COLS_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def target_merge_tracking(target_df, tracking_df, FEATURE_COLS_, SHIFT_COLS_,\n","                          TRACKING_COLS_ = [\"game_play\", \"nfl_player_id\", \"step\", \n","                                           \"x_position\", \"y_position\", \"datetime\",\n","                                           \"speed\",\"distance\",\"direction\",\"orientation\",\n","                                           \"acceleration\",\"sa\", \"team\", \"jersey_number\"]):\n","    target_df = target_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                     pl.col(\"step\").cast(str),\n","                                                     pl.col(\"nfl_player_id_1\"),\n","                                                    ], sep='_').alias('game_step_player_1'))\n","    target_df = target_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                     pl.col(\"step\").cast(str),\n","                                                     pl.col(\"nfl_player_id_2\"),\n","                                                    ], sep='_').alias('game_step_player_2'))\n","\n","    TRACKING_COLS_.extend(SHIFT_COLS_)\n","    # print(TRACKING_COLS_)\n","    tracking_df = tracking_df.select(TRACKING_COLS_)\n","    tracking_df = tracking_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                         pl.col(\"step\").cast(str),\n","                                                         pl.col(\"nfl_player_id\"),\n","                                                        ], sep='_').alias('game_step_player'))\n","\n","    tracking_df = tracking_df.drop([\"game_play\", \"step\", \"nfl_player_id\", \"datetime\"])\n","\n","    # merge tracking to target\n","    for player_id in [1,2]:\n","        tracking_player = tracking_df.select([pl.all().suffix(f\"_{player_id}\")])\n","        target_df = target_df.join(tracking_player, on=[f\"game_step_player_{player_id}\"], how=\"left\")\n","        # add features col\n","        FEATURE_COLS_ = add_feature_cols(tracking_player, FEATURE_COLS_,\n","                                        [f\"game_step_player_{player_id}\", f\"frame_{player_id}\", f\"datetime_{player_id}\"])\n","    # drop col\n","    target_df = target_df.drop([\"game_step_player_1\", \"game_step_player_2\"])\n","    print(len(target_df.columns))\n","    print(\"original length\", len(target_df))\n","    return target_df, FEATURE_COLS_"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## helmet df func"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","def target_merge_helmet(target_df, helmet_df, FEATURE_COLS):\n","    print(\"original length\", len(target_df))\n","    # set merge-key (game_frame_player_1,2) to merge helmet_df\n","    target_df = target_df.with_column(((pl.col(\"step\")/10*59.94+5*59.94).cast(int)+1).alias(\"frame\"))\n","    target_df = target_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                     pl.col(\"frame\").cast(str),\n","                                                     pl.col(\"nfl_player_id_1\"),\n","                                                    ], sep='_').alias('game_frame_player_1'))\n","    target_df = target_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                     pl.col(\"frame\").cast(str),\n","                                                     pl.col(\"nfl_player_id_2\"),\n","                                                    ], sep='_').alias('game_frame_player_2'))\n","    # set merge key\n","    helmet_df = helmet_df.with_column(pl.concat_str([pl.col(\"game_play\"),\n","                                                     pl.col(\"frame\").cast(str),\n","                                                     pl.col(\"nfl_player_id\"),\n","                                                    ], sep='_').alias('game_frame_player'))\n","\n","    # merge target df & helmet_df\n","    player_views = [[1, \"Endzone\"],[2, \"Endzone\"], [1, \"Sideline\"],[2, \"Sideline\"]]\n","    for player_id, view in player_views:\n","        helmet_view = helmet_df.filter(pl.col(\"view\")==view)\n","        helmet_view = helmet_view[[\"game_frame_player\", \"left\", \"width\", \"top\", \"height\"]]\n","        helmet_view = helmet_view.select(pl.all().suffix(f\"_{player_id}\"))\n","        helmet_view = helmet_view.select([pl.col(helmet_view.columns[0]), pl.col(helmet_view.columns[1:]).prefix(f\"{view[0]}_\")])\n","        target_df = target_df.join(helmet_view, on=f\"game_frame_player_{player_id}\", how=\"left\")  \n","        # add features col\n","        FEATURE_COLS = add_feature_cols(helmet_view, FEATURE_COLS, [f\"game_frame_player_{player_id}\"])\n","\n","    print(len(target_df.columns))\n","    print(\"original length\", len(target_df))\n","    return target_df, FEATURE_COLS"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Load Target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_dtypes = {'contact_id':str, \n","                'game_play':str,\n","                'datetime':str,\n","                'step':int,\n","                'nfl_player_id_1':str,\n","                'nfl_player_id_2':str,\n","                'contact':int,\n","                }\n","target_df = pl.read_csv(CFG[\"TRAIN_LABEL_CSV\"], dtypes=target_dtypes)    \n","\n","FEATURE_COLS = [\"nfl_player_id_1\", \"nfl_player_id_2\", \"step\"]\n","# display(target_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Merge tracking_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -------------------------------\n","# replace polars\n","# -------------------------------\n","tracking_df = pl.read_csv(CFG[\"TRAIN_TRACKING_CSV\"])\n","tracking_df, SHIFT_COLS = get_tracking_shift(tracking_df)\n","target_df, FEATURE_COLS = target_merge_tracking(target_df, tracking_df, FEATURE_COLS, SHIFT_COLS)\n","# display(tracking_df.filter((pl.col(\"game_play\")==\"58580_001136\") & (pl.col(\"nfl_player_id\").cast(str)==\"44830\")))# ちゃんとshiftできてそう\n","del tracking_df\n","\n","target_df, FEATURE_COLS = create_trackmerged_ftr(target_df, FEATURE_COLS)\n","\n","SHIFT_FEATURES = []\n","for col in SHIFT_COLS:\n","    SHIFT_FEATURES.append(f\"{col}_1\")\n","for col in SHIFT_COLS:\n","    SHIFT_FEATURES.append(f\"{col}_2\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Exclude distance 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(target_df))\n","target_df = target_df.filter(pl.col(\"players_dis\") <= 2)\n","print(len(target_df))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Merge helmet df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["helmet_df = pl.read_csv(CFG[\"TRAIN_HELMET_CSV\"])\n","target_df, FEATURE_COLS = target_merge_helmet(target_df, helmet_df, FEATURE_COLS)\n","target_df, FEATURE_COLS = create_helmetmerged_ftr(target_df, FEATURE_COLS)\n","target_df, FEATURE_COLS = get_categorical_ftr(target_df, FEATURE_COLS)\n","print(len(target_df))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Reduce Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_df = target_df.to_pandas()\n","\n","if CFG[\"DEBUG\"]:\n","    target_df = target_df.sample(CFG[\"sample_num\"]).reset_index(drop=True)\n","elif CFG[\"sample_num\"] != -1:\n","    target_df = target_df.sample(CFG[\"sample_num\"]).reset_index(drop=True)\n","\n","print(len(target_df))\n","print(len(target_df[\"game_play\"].unique()))\n","display(target_df[\"contact\"].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_df[SHIFT_FEATURES]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.940381Z","iopub.status.busy":"2023-01-19T12:15:30.938161Z","iopub.status.idle":"2023-01-19T12:15:30.959628Z","shell.execute_reply":"2023-01-19T12:15:30.958635Z","shell.execute_reply.started":"2023-01-19T12:15:30.940343Z"},"trusted":true},"outputs":[],"source":["train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.3, 0.3), p=0.5),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:30.966042Z","iopub.status.busy":"2023-01-19T12:15:30.963888Z","iopub.status.idle":"2023-01-19T12:15:31.022098Z","shell.execute_reply":"2023-01-19T12:15:31.020913Z","shell.execute_reply.started":"2023-01-19T12:15:30.966004Z"},"trusted":true},"outputs":[],"source":["class NFLDataset(Dataset):\n","    def __init__(self, target_df):\n","        self.target_df = target_df\n","        self.xpos_1 = target_df[CFG[\"xpos_1\"]].values\n","        self.ypos_1 = target_df[CFG[\"ypos_1\"]].values\n","        self.speed_1 = target_df[CFG[\"speed_1\"]].values\n","        self.dire_1 = target_df[CFG[\"dire_1\"]].values\n","        self.orie_1 = target_df[CFG[\"orie_1\"]].values\n","        self.acc_1 = target_df[CFG[\"acc_1\"]].values\n","        self.sa_1 = target_df[CFG[\"sa_1\"]].values\n","\n","        self.xpos_2 = target_df[CFG[\"xpos_2\"]].values\n","        self.ypos_2 = target_df[CFG[\"ypos_2\"]].values\n","        self.speed_2 = target_df[CFG[\"speed_2\"]].values\n","        self.dire_2 = target_df[CFG[\"dire_2\"]].values\n","        self.orie_2 = target_df[CFG[\"orie_2\"]].values\n","        self.acc_2 = target_df[CFG[\"acc_2\"]].values\n","        self.sa_2 = target_df[CFG[\"sa_2\"]].values\n","        \n","        self.dis = target_df[CFG[\"dis\"]].values\n","\n","    def __len__(self):\n","        return len(self.target_df)\n","\n","    def __getitem__(self, idx):\n","        target_info = self.target_df.iloc[idx]\n","        target = target_info.contact\n","        # player 1\n","        xpos_1 = self.xpos_1[idx]\n","        ypos_1 = self.ypos_1[idx]\n","        speed_1 = self.speed_1[idx]\n","        dire_1 = self.dire_1[idx]\n","        orie_1 = self.orie_1[idx]\n","        acc_1 = self.acc_1[idx]\n","        sa_1 = self.sa_1[idx]\n","        # player 2\n","        xpos_2 = self.xpos_2[idx]\n","        ypos_2 = self.ypos_2[idx]\n","        speed_2 = self.speed_2[idx]\n","        dire_2 = self.dire_2[idx]\n","        orie_2 = self.orie_2[idx]\n","        acc_2 = self.acc_2[idx]\n","        sa_2 = self.sa_2[idx]\n","        # distance\n","        dis = self.dis[idx]\n","        \n","        \n","        shift_features = np.concatenate([xpos_1[np.newaxis, :], ypos_1[np.newaxis, :], speed_1[np.newaxis, :], dire_1[np.newaxis, :],\n","                                        orie_1[np.newaxis, :], acc_1[np.newaxis, :], sa_1[np.newaxis, :],\n","                                        xpos_2[np.newaxis, :], ypos_2[np.newaxis, :], speed_2[np.newaxis, :], dire_2[np.newaxis, :],\n","                                        orie_2[np.newaxis, :], acc_2[np.newaxis, :], sa_2[np.newaxis, :],\n","                                        dis[np.newaxis, :],\n","                                        ])\n","        shift_features = torch.tensor(shift_features, dtype=torch.float32)\n","        \n","        return shift_features, target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CFG[\"DEBUG\"]:\n","    check_batch = 4\n","    pick_df = target_df.copy()\n","    train_dataset = NFLDataset(pick_df)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size = check_batch,\n","        shuffle = False,\n","        num_workers = CFG[\"num_workers\"],\n","        pin_memory = True\n","    )\n","    for batch_idx, (track_features, targets) in enumerate(train_loader):\n","        print(\"track features shape =\",track_features.shape)\n","        print(\"target shape\", targets.shape)\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.050926Z","iopub.status.busy":"2023-01-19T12:15:31.047836Z","iopub.status.idle":"2023-01-19T12:15:31.08031Z","shell.execute_reply":"2023-01-19T12:15:31.07901Z","shell.execute_reply.started":"2023-01-19T12:15:31.050888Z"},"trusted":true},"outputs":[],"source":["class NFLTrackNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","                        nn.Conv1d(len(CFG[\"SHIFT_COLS\"])*2 - 1, 1, 5), #distance は一つでいいので-1\n","                        nn.Linear(len(CFG[\"SHIFT_NUM\"])-4, CFG[\"num_track_features\"]),\n","                        nn.ReLU(),\n","                    )\n","        self.fc = nn.Linear(CFG[\"num_track_features\"], 1)\n","\n","    def forward(self, shift_features):\n","        embeddings = self.conv1(shift_features)\n","        output = self.fc(embeddings)\n","        output = output.view(-1, 1)\n","        embeddings = embeddings.view(embeddings.shape[0], 5)\n","        return output, embeddings"]},{"cell_type":"markdown","metadata":{},"source":["# train fn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.089647Z","iopub.status.busy":"2023-01-19T12:15:31.086565Z","iopub.status.idle":"2023-01-19T12:15:31.108085Z","shell.execute_reply":"2023-01-19T12:15:31.106889Z","shell.execute_reply.started":"2023-01-19T12:15:31.089595Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    for batch_idx, (shift_features, targets) in enumerate(train_loader):\n","        shift_features = shift_features.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)      \n","        preds, _ = model(shift_features)\n","        \n","        loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('\\t Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, shift_features, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# valid fn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.124209Z","iopub.status.busy":"2023-01-19T12:15:31.115126Z","iopub.status.idle":"2023-01-19T12:15:31.151039Z","shell.execute_reply":"2023-01-19T12:15:31.150071Z","shell.execute_reply.started":"2023-01-19T12:15:31.124165Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    track_embs = []\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start, end = time.time(), time.time()\n","    view_list = []\n","    for batch_idx, (shift_features, targets) in enumerate(valid_loader):\n","        shift_features = shift_features.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float().view(-1, 1)\n","        with torch.no_grad():\n","            preds, track_emb = model(shift_features)\n","            loss = criterion(preds, targets)\n","        losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        track_emb = track_emb.detach().cpu().numpy()\n","        track_embs.extend(track_emb)\n","\n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = torch.sigmoid(preds).detach().cpu().numpy().ravel().tolist()\n","\n","        test_preds.extend(preds)\n","        test_targets.extend(targets)\n","        # score = matthews_corrcoef(preds, targets)\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1):\n","            print('\\t EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, shift_features, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    test_preds = np.array(test_preds)\n","    test_targets = np.array(test_targets)\n","    return test_targets, test_preds, track_embs, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.158195Z","iopub.status.busy":"2023-01-19T12:15:31.155797Z","iopub.status.idle":"2023-01-19T12:15:31.19266Z","shell.execute_reply":"2023-01-19T12:15:31.191464Z","shell.execute_reply.started":"2023-01-19T12:15:31.158157Z"},"trusted":true},"outputs":[],"source":["def training_loop(target_df):\n","    # set model & learning fn\n","    oof_df = pd.DataFrame()\n","    kf = GroupKFold(n_splits=CFG[\"n_folds\"])\n","    for fold, (idx_train, idx_valid) in enumerate(kf.split(target_df, target_df[\"contact_id\"], target_df[\"game_play\"])):\n","        print(\"---\")\n","        print(f\"fold {fold} start training...\")\n","        model = NFLTrackNet()\n","        model = model.to(device)\n","        criterion = nn.BCEWithLogitsLoss()\n","        optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","\n","        if not fold in CFG[\"train_folds\"]:\n","            print(f\"fold{fold} is skip\")\n","            continue\n","        # separate train/valid data \n","        train_df = target_df.iloc[idx_train]\n","        valid_df = target_df.iloc[idx_valid]\n","        print(\"train target contact\")\n","        print(train_df[\"contact\"].value_counts())\n","        print(\"valid target contact\")\n","        print(valid_df[\"contact\"].value_counts())\n","        # separate train/valid data \n","        train_dataset = NFLDataset(train_df)\n","        valid_dataset = NFLDataset(valid_df)\n","        train_loader = DataLoader(train_dataset,batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","        valid_loader = DataLoader(valid_dataset,batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","        # training\n","        best_score = -np.inf\n","        best_auc = -np.inf\n","        start_time, end = time.time(), time.time()\n","        for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","            print(f'\\t === epoch: {epoch}: training ===')\n","            train_loss_avg = train_fn(train_loader, model, criterion, epoch, optimizer, scheduler)\n","            valid_targets, valid_preds, valid_embs, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","\n","            valid_score = -np.inf\n","            valid_threshold = 0\n","            tn_best, fp_best, fn_best, tp_best = 0, 0, 0, 0\n","            for idx in range(1, 10, 1):\n","                thr = idx*0.1\n","                valid_targets = (np.array(valid_targets) > thr).astype(np.int32)\n","                valid_binary_preds = (np.array(valid_preds) > thr).astype(np.int32)\n","                score_tmp = matthews_corrcoef(valid_targets, valid_binary_preds)\n","                cm = confusion_matrix(valid_targets, valid_binary_preds)\n","                tn, fp, fn, tp = cm.flatten()\n","                if score_tmp > valid_score:\n","                    valid_score = score_tmp \n","                    valid_threshold = thr\n","                    tn_best, fp_best, fn_best, tp_best = tn, fp, fn, tp\n","            elapsed = (time.time() - start_time)/60\n","            auc_score = roc_auc_score(valid_targets, valid_preds)\n","            print(f'\\t epoch:{epoch}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}')\n","            print(f'\\t score:{valid_score:.4f}(th={valid_threshold}) AUC = {auc_score:.4f}=> time:{elapsed:.2f} min')\n","            scheduler.step()\n","            # validationスコアがbestを更新したらモデルを保存する\n","            if valid_score > best_score:\n","                best_score = valid_score\n","                torch.save(model.state_dict(), f'{CFG[\"MODEL_DIR\"]}/track_fold{fold}.pth')\n","                print(f'\\t Epoch {epoch} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                contact_id = valid_df[\"contact_id\"].values\n","                _oof_df = pd.DataFrame({\n","                    \"contact_id\" : contact_id,\n","                    \"pred\" : valid_preds,\n","                    \"contact\" : valid_targets,\n","                    \"fold\" : fold,\n","                })\n","                track_emb_colname = [f\"track_emb_{idx}\" for idx in range(CFG[\"num_track_features\"])]\n","                track_emb_df = pd.DataFrame(valid_embs, columns=track_emb_colname)\n","                _oof_df = pd.concat([_oof_df, track_emb_df], axis=1)\n","            \n","            logging_metrics_epoch(fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, tn_best, fp_best, fn_best, tp_best, auc_score)\n","\n","        del train_loader, train_dataset, valid_loader, valid_dataset\n","        oof_df = pd.concat([oof_df, _oof_df], axis = 0)\n","        del _oof_df\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return oof_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:15:31.200371Z","iopub.status.busy":"2023-01-19T12:15:31.1979Z","iopub.status.idle":"2023-01-19T12:20:32.225707Z","shell.execute_reply":"2023-01-19T12:20:32.2246Z","shell.execute_reply.started":"2023-01-19T12:15:31.200332Z"},"trusted":true},"outputs":[],"source":["if CFG[\"kaggle\"]:\n","    oof_df = training_loop(target_df)\n","    wandb.finish()\n","else:\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=CFG[\"EXP_NAME\"]) as run:\n","        mlflow.log_dict(CFG, \"configuration.yaml\")\n","        mlflow.log_param(\"positive data num\", len(target_df[target_df[\"contact\"]==1]))\n","        mlflow.log_param(\"negative data num\", len(target_df[target_df[\"contact\"]==0]))\n","        oof_df = training_loop(target_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Save oof_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T12:20:32.238761Z","iopub.status.busy":"2023-01-19T12:20:32.238069Z","iopub.status.idle":"2023-01-19T12:20:32.262842Z","shell.execute_reply":"2023-01-19T12:20:32.261886Z","shell.execute_reply.started":"2023-01-19T12:20:32.23872Z"},"trusted":true},"outputs":[],"source":["display(oof_df)\n","if CFG[\"kaggle\"]:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)\n","else:\n","    oof_filename = os.path.join(CFG[\"OUTPUT_DIR\"], CFG[\"EXP_NAME\"], \"oof_df.csv\")\n","    oof_df.to_csv(oof_filename, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx in range(1, 10, 1):\n","    thr = idx*0.1\n","    valid_targets = (np.array(oof_df[\"contact\"]) > thr).astype(np.int32)\n","    valid_binary_preds = (np.array(oof_df[\"pred\"]) > thr).astype(np.int32)\n","    score = matthews_corrcoef(valid_targets, valid_binary_preds)\n","    print(f\"threshold={thr:.3f}, score={score:.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["alldata_df = pd.read_csv(\"/workspace/input/train_labels.csv\")\n","alldata_df = alldata_df.merge(oof_df[[\"contact_id\", \"pred\"]], on=\"contact_id\", how=\"left\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx in range(1, 10, 1):\n","    thr = idx*0.1\n","    valid_targets = (np.array(alldata_df[\"contact\"]) > thr).astype(np.int32)\n","    valid_binary_preds = (np.array(alldata_df[\"pred\"]) > thr).astype(np.int32)\n","    score = matthews_corrcoef(valid_targets, valid_binary_preds)\n","    print(f\"threshold={thr:.3f}, score={score:.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":4}
